<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>161250 Data Analysis - Chapter 7: Models with Multiple Continuous Predictors</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../studyguide/8-anova.html" rel="next">
<link href="../studyguide/6-single.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script src="../site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="../site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">161250 Data Analysis</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../slides.html" rel="" target="">
 <span class="menu-text">Slides</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../studyguide/index.html" rel="" target="" aria-current="page">
 <span class="menu-text">Study Guide</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../workshops/ws01.html" rel="" target="">
 <span class="menu-text">Workshops</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../studyguide/index.html">Study Guide</a></li><li class="breadcrumb-item"><a href="../studyguide/7-multiple.html">Chapter 7: Models with Multiple Continuous Predictors</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../studyguide/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Study Guide</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/1-data-collection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 1: Data Collection and Quality Issues</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/2-eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 2: Exploratory Data Analysis (EDA)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/3-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 3: Probability Concepts and Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/4-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 4: Statistical Inference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/5-tabulated.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 5: Tabulated Counts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/6-single.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 6: Models with a Single Continuous Predictor</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/7-multiple.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Chapter 7: Models with Multiple Continuous Predictors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/8-anova.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 8: Analysis of Variance (ANOVA) and Covariance (ANCOVA)</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#full-regression" id="toc-full-regression" class="nav-link active" data-scroll-target="#full-regression">Full Regression</a></li>
  <li><a href="#measuring-variation-explained-by-predictors" id="toc-measuring-variation-explained-by-predictors" class="nav-link" data-scroll-target="#measuring-variation-explained-by-predictors">Measuring Variation Explained by Predictors</a>
  <ul class="collapse">
  <li><a href="#significance-testing-of-type-i-ss" id="toc-significance-testing-of-type-i-ss" class="nav-link" data-scroll-target="#significance-testing-of-type-i-ss">Significance testing of Type I SS</a></li>
  <li><a href="#other-ss-types" id="toc-other-ss-types" class="nav-link" data-scroll-target="#other-ss-types">Other SS types</a></li>
  </ul></li>
  <li><a href="#regression-fitting-with-fewer-predictors" id="toc-regression-fitting-with-fewer-predictors" class="nav-link" data-scroll-target="#regression-fitting-with-fewer-predictors">Regression Fitting with Fewer Predictors</a>
  <ul class="collapse">
  <li><a href="#best-subsets-selection" id="toc-best-subsets-selection" class="nav-link" data-scroll-target="#best-subsets-selection">Best Subsets Selection</a></li>
  </ul></li>
  <li><a href="#polynomial-models" id="toc-polynomial-models" class="nav-link" data-scroll-target="#polynomial-models">Polynomial Models</a></li>
  <li><a href="#model-structure-and-other-issues" id="toc-model-structure-and-other-issues" class="nav-link" data-scroll-target="#model-structure-and-other-issues">Model structure and other issues</a></li>
  <li><a href="#smoothing-and-regression-modeling-for-time-series" id="toc-smoothing-and-regression-modeling-for-time-series" class="nav-link" data-scroll-target="#smoothing-and-regression-modeling-for-time-series">Smoothing and Regression modeling for Time series</a>
  <ul class="collapse">
  <li><a href="#time-series-regression-with-seasonality-components" id="toc-time-series-regression-with-seasonality-components" class="nav-link" data-scroll-target="#time-series-regression-with-seasonality-components">Time Series Regression with seasonality components</a></li>
  <li><a href="#moving-average-smoothing" id="toc-moving-average-smoothing" class="nav-link" data-scroll-target="#moving-average-smoothing">Moving Average Smoothing</a></li>
  <li><a href="#exponential-smoothing" id="toc-exponential-smoothing" class="nav-link" data-scroll-target="#exponential-smoothing">Exponential Smoothing</a></li>
  <li><a href="#double-exponential-smoothing" id="toc-double-exponential-smoothing" class="nav-link" data-scroll-target="#double-exponential-smoothing">Double Exponential Smoothing</a></li>
  <li><a href="#triple-exponential-smoothing" id="toc-triple-exponential-smoothing" class="nav-link" data-scroll-target="#triple-exponential-smoothing">Triple Exponential Smoothing</a></li>
  <li><a href="#assessment-of-fit" id="toc-assessment-of-fit" class="nav-link" data-scroll-target="#assessment-of-fit">Assessment of Fit:</a></li>
  <li><a href="#intro-to-autoregressive-modelling" id="toc-intro-to-autoregressive-modelling" class="nav-link" data-scroll-target="#intro-to-autoregressive-modelling">Intro to Autoregressive Modelling</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="7-multiple.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Chapter 7: Models with Multiple Continuous Predictors</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>In this chapter, we consider <strong>multiple regression</strong> and other models in which there are more than one predictor (or <span class="math inline">\(X\)</span>) variable. Once again our focus is on finding the estimates of coefficients or parameters in multiple linear regression models by the method of <strong>least squares</strong>. For this we assume that</p>
<ol type="1">
<li><p>The predictor (or explanatory or controlled or covariate) variables <span class="math inline">\(X_i\)</span> <span class="math inline">\((i=1,2,...,p)\)</span> are known without error.</p></li>
<li><p>The mean or expected value of the dependent (or response) variable <span class="math inline">\(Y\)</span> is related to the <span class="math inline">\(X_i\)</span> <span class="math inline">\((i=1,2,...,p)\)</span> according to a linear expression</p>
<p><span class="math inline">\(E(y\mid x)=a+ b_1 x_l + b_2 x_2 + ....+ b_p x_p\)</span></p>
<p>i.e.&nbsp;a straight line (for one <span class="math inline">\(X\)</span> variable), a plane (for two <span class="math inline">\(X\)</span> variables) or a hyperplane (for more than two <span class="math inline">\(X\)</span> variables). This means that the fitted model can be written as</p>
<p><em>fit</em> = <span class="math inline">\(a+ b_1 x_l + b_2 x_2 + ....+ b_p x_p\)</span>.</p></li>
<li><p>There is random (unpredictable, unexplained) variability of <span class="math inline">\(Y\)</span> about the fitted model. That is,</p>
<p><span class="math inline">\(y\)</span> = fit + residual.</p></li>
<li><p>In order to apply statistical inferences to a model, a number of assumptions need to be made. To be able to form <span class="math inline">\(t\)</span> and <span class="math inline">\(F\)</span> statistics, we assume that</p></li>
<li><p>The variability in <span class="math inline">\(Y\)</span> about the line (plane etc) is constant and independent of the <span class="math inline">\(X\)</span> variables.</p></li>
<li><p>The variability of <span class="math inline">\(Y\)</span> follows a Normal distribution. That is, the distribution of <span class="math inline">\(Y\)</span> (given certain values of the <span class="math inline">\(X_i\)</span> variables) is Normal.</p></li>
<li><p>Given (different) outcomes of the <span class="math inline">\(X\)</span> variables, the corresponding <span class="math inline">\(Y\)</span> variables are independent of one another.</p></li>
</ol>
<p>We will continue to use the data set <strong>horsehearts</strong> of the weights of horses’ hearts and other related measurements.</p>
<section id="full-regression" class="level1">
<h1>Full Regression</h1>
<p>With one explanatory variable scatterplots and correlation coefficients provided good starting points for exploring relationships between the explanatory and response variables. This is even more relevant with two or more explanatory variables. For the horses’ hearts data, there are six potential explanatory variables; namely <code>EXTDIA</code>, <code>EXTSYS</code>, <code>INNERDIA</code>, <code>INNERSYS</code>, <code>OUTERDIA</code> and <code>OUTERSYS</code>. These measurements of heart width are made of the exterior width, inner wall and outer wall at two different phases, the diastole phase and the systole phase. So a matrix of scatter plots (or matrix plot) of these variables will be useful for exploratory analysis.</p>
<p>It is also a good idea to form the simple correlation coefficients between each pair of explanatory variables and between each explanatory variable and the response variable <span class="math inline">\(Y\)</span>, the weight of the horse’s heart. These correlation coefficients can be displayed in a <strong>correlation matrix</strong> as shown in <a href="#fig-multggally">Figure&nbsp;1</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_minimal</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">url =</span> <span class="st">"http://www.massey.ac.nz/~anhsmith/data/horsehearts.RData"</span>,</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">destfile =</span> <span class="st">"horsehearts.RData"</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"horsehearts.RData"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-mesasge="false">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Registered S3 method overwritten by 'GGally':
  method from   
  +.gg   ggplot2</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggpairs</span>(horsehearts)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-multggally" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-multggally-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Scatter plot and correlation matrix</figcaption>
</figure>
</div>
</div>
</div>
<p>It is also possible to obtain the <span class="math inline">\(p\)</span>-values for all the simple correlation coefficients displayed above and test whether these are significantly different from zero.</p>
<p>A number of facts about the data emerge from our EDA. All of the correlation coefficients are positive and reasonably large which indicates that with large hearts all the lengths increase in a fairly uniform manner. The predictor variables are also highly inter-correlated. <strong>This suggests that not all of these variables are needed but only a subset of them</strong>.</p>
<p>The usual <code>tidy()</code> function output of multiple regression weight on all of the available (six) predictors is shown in <a href="#tbl-fullregtidy">Table&nbsp;1</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>full.reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(full.reg) <span class="co"># or summary(full.reg) </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-fullregtidy" class="anchored">

<table data-quarto-disable-processing="true" class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;"><caption>Table&nbsp;1:  <p>Full Regression tidy() output</p> </caption>
 <thead>
  <tr>
   <th style="text-align:left;"> term </th>
   <th style="text-align:right;"> estimate </th>
   <th style="text-align:right;"> std.error </th>
   <th style="text-align:right;"> statistic </th>
   <th style="text-align:right;"> p.value </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> (Intercept) </td>
   <td style="text-align:right;"> -1.631 </td>
   <td style="text-align:right;"> 0.488 </td>
   <td style="text-align:right;"> -3.343 </td>
   <td style="text-align:right;"> 0.002 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> INNERSYS </td>
   <td style="text-align:right;"> 0.232 </td>
   <td style="text-align:right;"> 0.308 </td>
   <td style="text-align:right;"> 0.753 </td>
   <td style="text-align:right;"> 0.456 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> INNERDIA </td>
   <td style="text-align:right;"> 0.520 </td>
   <td style="text-align:right;"> 0.395 </td>
   <td style="text-align:right;"> 1.314 </td>
   <td style="text-align:right;"> 0.197 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> OUTERSYS </td>
   <td style="text-align:right;"> 0.711 </td>
   <td style="text-align:right;"> 0.329 </td>
   <td style="text-align:right;"> 2.164 </td>
   <td style="text-align:right;"> 0.037 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> OUTERDIA </td>
   <td style="text-align:right;"> -0.557 </td>
   <td style="text-align:right;"> 0.451 </td>
   <td style="text-align:right;"> -1.236 </td>
   <td style="text-align:right;"> 0.224 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> EXTSYS </td>
   <td style="text-align:right;"> -0.300 </td>
   <td style="text-align:right;"> 0.135 </td>
   <td style="text-align:right;"> -2.227 </td>
   <td style="text-align:right;"> 0.032 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> EXTDIA </td>
   <td style="text-align:right;"> 0.339 </td>
   <td style="text-align:right;"> 0.148 </td>
   <td style="text-align:right;"> 2.296 </td>
   <td style="text-align:right;"> 0.027 </td>
  </tr>
</tbody>
</table>

</div>
</div>
</div>
<p>This regression model is known as the <strong>full regression</strong> because we have included all the predictors in our model. The <code>R</code> syntax <code>~.</code> means that we are placing all variables in the dataframe except the one selected as the response variable. We note that the slope coefficients of the predictors <code>INNERDIA</code>, <code>INNERSYS</code>, and <code>OUTERDIA</code> are not significant at 5% level. This confirms that we do not need to place all six predictors in the model but only a subset of them.</p>
<p>The highly correlated predictor <code>INNERDIA</code> (see <a href="#fig-multggally">Figure&nbsp;1</a>) is also found to have a insignificant coefficient in <a href="#tbl-fullregtidy">Table&nbsp;1</a>. This is somewhat surprising and casts doubts on the suitability of the full regression fit. If two or more explanatory variables are very highly correlated (i.e.&nbsp;almost collinear), then we deal with <strong>multicollinearity</strong>. The estimated standard errors of the regression coefficients will be inflated in the presence of multicollinearity. As result, the <span class="math inline">\(t\)</span>-value will become small leading to a model with many insignificant coefficients. Multicollinearity does not affect the residual standard error much. The obvious remedy for multicollinearity is that one or more of the highly correlated variables can be dropped. Measures such as the Variance Inflation factor (<strong>VIF</strong>) are available to study the effect of multicollinearity. A VIF factor of more than 5 for a coefficient means that its variance is artificially inflated by the high correlation among the predictors. For the full regression model, the VIF factors are obtained using the <code>car</code> package function <code>vif()</code> and shown as <a href="#tbl-fullregvif">Table&nbsp;2</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">vif</span>(full.reg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-fullregvif" class="anchored">

<table data-quarto-disable-processing="true" class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;"><caption>Table&nbsp;2:  <p>Variance Inflation Factors</p> </caption>
 <thead>
  <tr>
   <th style="text-align:left;">   </th>
   <th style="text-align:right;"> x </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> INNERSYS </td>
   <td style="text-align:right;"> 8.77 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> INNERDIA </td>
   <td style="text-align:right;"> 8.60 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> OUTERSYS </td>
   <td style="text-align:right;"> 7.71 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> OUTERDIA </td>
   <td style="text-align:right;"> 6.66 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> EXTSYS </td>
   <td style="text-align:right;"> 16.05 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> EXTDIA </td>
   <td style="text-align:right;"> 22.00 </td>
  </tr>
</tbody>
</table>

</div>
</div>
</div>
<p>All the VIF values are over 5, and hence the full regression model must be simplified dropping one or more predictors.</p>
<p>Let us now compare the fit and summary measures of the simple regression <code>lm(WEIGHT ~ INNERDIA, data=horsehearts)</code> with the full regression <code>lm(WEIGHT ~ ., data=horsehearts)</code>. <a href="#fig-modcomp">Figure&nbsp;2</a> compares the actual and fitted <span class="math inline">\(Y\)</span> values for these two models.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(modelr)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>full.reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>simple.reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> INNERDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>hhpred <span class="ot">&lt;-</span> horsehearts <span class="sc">|&gt;</span> </span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather_predictions</span>(full.reg, simple.reg) <span class="sc">|&gt;</span> </span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">residuals=</span>WEIGHT<span class="sc">-</span>pred)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>hhpred <span class="sc">|&gt;</span> </span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x=</span>WEIGHT, <span class="at">y=</span>pred, <span class="at">colour=</span>model) <span class="sc">+</span> </span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">alpha=</span>.<span class="dv">5</span>) <span class="sc">+</span> </span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">aspect.ratio =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Predicted WEIGHT"</span>) <span class="sc">+</span> </span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Comparison of model predictions"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-modcomp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-modcomp-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Comparison of Multiple Regression and Simple Regression</figcaption>
</figure>
</div>
</div>
</div>
<p>Both the simple and full regression models give similar predictions when the horses heart weight is below 2.5 kg, but the simple regression residuals are bit bigger for larger hearts.</p>
<p>We are rather hesitant to make unique claims about any particular subset of predictors based on the correlation matrix or based on the significance of the coefficients from the multiple regression output. In forthcoming sections, methods to decide on a subset of these variables will be explained, but first we look at the issues involved when predictor variables are correlated to each other.</p>
</section>
<section id="measuring-variation-explained-by-predictors" class="level1">
<h1>Measuring Variation Explained by Predictors</h1>
<p>The variation in a variable can be measured by its sum of squares. In this section, we illustrate this variation by the area of a circle. For brevity, we denote the <strong>T</strong>otal <strong>S</strong>um of <strong>S</strong>quares, the <strong>R</strong>egression <strong>S</strong>um of <strong>S</strong>quares and the <strong>E</strong>rror or residual <strong>S</strong>um of <strong>S</strong>quares by <strong>SST</strong>, <strong>SSR</strong> and <strong>SSE</strong> respectively. In <a href="#fig-f5-3">Figure&nbsp;3</a>, the circle is labelled <span class="math inline">\(y\)</span> and represents the Sum of Squares for all the <span class="math inline">\(y\)</span> observations, that is, SST.</p>
<div id="fig-f5-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/5-3.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Effect of predictor correlation with the response</figcaption>
</figure>
</div>
<p>For the full regression of horse heart weight, we obtain the ANOVA output using the command</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(full.reg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Let’s take a look at the sums of squares table.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>SS <span class="ot">&lt;-</span> <span class="fu">anova</span>(full.reg) <span class="sc">|&gt;</span> </span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term<span class="sc">:</span>sumsq) <span class="sc">|&gt;</span> </span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">adorn_totals</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-SS" class="anchored">

<table data-quarto-disable-processing="true" class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;"><caption>Table&nbsp;3:  <p>Sums of squares for the full regression of horsehearts data</p> </caption>
 <thead>
  <tr>
   <th style="text-align:left;"> term </th>
   <th style="text-align:right;"> df </th>
   <th style="text-align:right;"> sumsq </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> INNERSYS </td>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:right;"> 34.40 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> INNERDIA </td>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:right;"> 3.53 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> OUTERSYS </td>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:right;"> 2.76 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> OUTERDIA </td>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:right;"> 0.13 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> EXTSYS </td>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:right;"> 0.06 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> EXTDIA </td>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:right;"> 1.90 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Residuals </td>
   <td style="text-align:right;"> 39 </td>
   <td style="text-align:right;"> 14.07 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Total </td>
   <td style="text-align:right;"> 45 </td>
   <td style="text-align:right;"> 56.85 </td>
  </tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Now let’s calculate the Sums of Squares Total (SST), Error (SSE), and Regression (SSR).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">SST =</span> SS <span class="sc">|&gt;</span> <span class="fu">filter</span>(term<span class="sc">==</span><span class="st">"Total"</span>) <span class="sc">|&gt;</span> <span class="fu">pull</span>(sumsq),</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">SSE =</span> SS <span class="sc">|&gt;</span> <span class="fu">filter</span>(term<span class="sc">==</span><span class="st">"Residuals"</span>) <span class="sc">|&gt;</span> <span class="fu">pull</span>(sumsq),</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">SSR =</span> SST <span class="sc">-</span> SSE</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 3
    SST   SSE   SSR
  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1  56.8  14.1  42.8</code></pre>
</div>
</div>
<p>In <a href="#fig-f5-3">Figure&nbsp;3</a>(a), SST = SSR + SSE = 32.731 + 24.115 = 56.845. Consider now the straight line relationship between <span class="math inline">\(y\)</span> and one response variable <span class="math inline">\(x\)</span>. This situation is illustrated in <a href="#fig-f5-3">Figure&nbsp;3</a>(b). The shaded overlap of the two circles illustrates the variation in <span class="math inline">\(y\)</span> about the mean explained by the variable <span class="math inline">\(x\)</span>, and this shaded area represents the regression sum of squares SSR. The remaining area of the circle for <span class="math inline">\(y\)</span> represents the unexplained variation in <span class="math inline">\(y\)</span> or the residual sum of squares SSE. Note that the circle or Venn diagrams represent SS only qualitatively (not to scale). The variation in <span class="math inline">\(y\)</span> is thus separated into two parts, namely <strong>SST = SSR + SSE</strong>.</p>
<p>Notice that we are not very interested in the unshaded area of the circle representing the explanatory variable, <span class="math inline">\(x\)</span>; <em>it is the variation in the response variable,</em> <span class="math inline">\(y\)</span>, which is important. Also notice that the overlapping circles indicate that the two variables are correlated, that is the correlation coefficient, <span class="math inline">\(r_{xy}\)</span>, is not zero. The shaded area is related to</p>
<p><span class="math inline">\(R^2\)</span> = proportion of the variation of <span class="math inline">\(y\)</span> explained by <span class="math inline">\(x\)</span> = SSR/SST = 32.731/56.845 = 0.576 = <span class="math inline">\(r_{xy}^2\)</span>.</p>
<p>Note from <a href="#fig-multggally">Figure&nbsp;1</a> that the correlation between <code>WEIGHT</code> and <code>EXTDIA</code> is 0.759 and 0.759 squared equals 0.576.</p>
<p>The situation becomes more interesting when a second explanatory variable is added to the model as illustrated by <a href="#fig-f5-4">Figure&nbsp;4</a>.</p>
<div id="fig-f5-4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/5-4.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Effect of adding two predictors</figcaption>
</figure>
</div>
<p>In the following discussion, the variable <code>EXTDIA</code> is denoted by <span class="math inline">\(x_1\)</span> and <code>OUTERDIA</code> as <span class="math inline">\(x_2\)</span>. The total overlap of (<span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>) and <span class="math inline">\(y\)</span> will depend on the relationship of <span class="math inline">\(y\)</span> with <span class="math inline">\(x_1\)</span>, <span class="math inline">\(y\)</span> with <span class="math inline">\(x_2\)</span>, and the correlation of <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2.\)</span></p>
<p>In <a href="#fig-f5-4">Figure&nbsp;4</a>(a), as the circles for <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> do not overlap, this represents a correlation coefficient between these two variables of zero. In this special case, <span class="math display">\[R^{2} =\frac{\text {SSR}(x_1)+\text {SSR} (x_2)}{\text {SST}} =r_{x_{1} y}^{2} +r_{x_{2} y}^{2}.\]</span></p>
<p>Here, SSR(<span class="math inline">\(x_1\)</span>) represents the Regression SS when <span class="math inline">\(y\)</span> is regressed on <span class="math inline">\(x_1\)</span> only. SSR(<span class="math inline">\(x_2\)</span>) represents the Regression SS when <span class="math inline">\(y\)</span> is regressed on <span class="math inline">\(x_2\)</span> only. The unshaded area of <span class="math inline">\(y\)</span> represents SSE, the residual sum of squares, which is the sum of squares of <span class="math inline">\(y\)</span> <strong>unexplained</strong> by <span class="math inline">\(x_1\)</span> or <span class="math inline">\(x_2\)</span>. The <strong>special case</strong> of <strong>uncorrelated</strong> explanatory variables is in many ways ideal but it usually only occurs when <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are constructed to have zero correlation (which means that the situation, known as orthogonality, is usually confined to experimental designs). There is an added bonus when <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> have zero correlation. In this situation the fitted model is</p>
<p><span class="math display">\[\hat{y} = a + b_1 x_1 + b_2x_2\]</span></p>
<p>where <span class="math inline">\(b_1\)</span> and <span class="math inline">\(b_2\)</span> take the same values as in the separate straight line models <span class="math inline">\(\hat{y} = a + b_1x_1\)</span> and <span class="math inline">\(\hat{y} =a + b_2x_2.\)</span></p>
<p>However in observational studies the correlations between predictor variables will usually be nonzero. The circle diagram shown in <a href="#fig-f5-4">Figure&nbsp;4</a>(b) illustrates the case when <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are correlated. In this case <span class="math display">\[R^{2} &lt;\frac{\text {SSR}(x_1) + \text {SSR}(x_2) } {\text {SST}}\]</span> and the slope coefficients for both <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> change when both these variables are included in the regression model.</p>
<p><a href="#fig-f5-4">Figure&nbsp;4</a>(c) gives the extreme case when <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> have nearly perfect correlation. If the correlation between <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> is perfect, then the two variables will be said to be collinear. If two or more explanatory variables are very highly correlated (i.e.&nbsp;almost collinear), then we deal with <strong>multicollinearity</strong>.</p>
<p>From <a href="#fig-f5-3">Figure&nbsp;3</a> and <a href="#fig-f5-4">Figure&nbsp;4</a>, it is clear that for correlated variables, the variation (SS) explained by a particular predictor cannot be independently extracted (due to the commonly shared variation). Hence, we consider how much a predictor explains <strong>additionally</strong> given that there are already certain predictors are in the model. The additional overlap due to <span class="math inline">\(x_{2}\)</span> with <span class="math inline">\(y\)</span> <strong>after</strong> <span class="math inline">\(x_{1}\)</span>, known as the <strong>additional SSR</strong> or <strong>Sequential SS</strong> is an important idea in model building. The additional SSR is known as <strong>Type I sums of squares</strong> in the statistical literature.</p>
<p>Note that we can also define the additional variation in <span class="math inline">\(y\)</span> explained by <span class="math inline">\(x_{1}\)</span> after <span class="math inline">\(x_{2}\)</span>. It is important to note that in general the additional SSR depends on the <strong>order</strong> of placing the predictors. <strong>This order does not have any effect on the coefficient estimation, standard errors etc.</strong></p>
<section id="significance-testing-of-type-i-ss" class="level2">
<h2 class="anchored" data-anchor-id="significance-testing-of-type-i-ss">Significance testing of Type I SS</h2>
<p>The significance of the additional variation explained by a predictor can be tested using a <span class="math inline">\(t\)</span> or <span class="math inline">\(F\)</span> statistic. Consider the simple regression model of <code>WEIGHT</code> on <code>EXTDIA</code>. Suppose we decided to add the explanatory variable <code>OUTERDIA</code> to the model, i.e.&nbsp;regress <code>WEIGHT</code> on two explanatory variables <code>EXTDIA</code> and <code>OUTERDIA</code>. Is this new model a significant improvement on the existing one? For testing the null hypothesis that the true slope coefficient of <code>OUTERDIA</code> in this model is zero, the <span class="math inline">\(t\)</span>-statistic is 1.531 (see output below).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>twovar.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> EXTDIA<span class="sc">+</span>OUTERDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>twovar.model <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 5
  term        estimate std.error statistic  p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)   -1.97     0.551      -3.57 0.000885
2 EXTDIA         0.226    0.0614      3.68 0.000637
3 OUTERDIA       0.522    0.341       1.53 0.133   </code></pre>
</div>
</div>
<p>The <span class="math inline">\(t\)</span> and <span class="math inline">\(F\)</span> distributions are related by the equation <span class="math inline">\(t^{2} =F\)</span> when the numerator df is just one for the <span class="math inline">\(F\)</span> statistic. Hence 1.532 = 2.34 is the <span class="math inline">\(F\)</span> value for testing the significance of the additional SSR due to <code>OUTERDIA</code>. In other words, the addition of <code>OUTERDIA</code> to the simple regression model does not result in a significant improvement in the sense that the reduction in residual SS (= 1.247) as measured by the <span class="math inline">\(F\)</span> value of 2.34 is not significant (<span class="math inline">\(p\)</span>-value being 0.133).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>onevar.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>twovar.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> EXTDIA<span class="sc">+</span>OUTERDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(onevar.model, twovar.model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: WEIGHT ~ EXTDIA
Model 2: WEIGHT ~ EXTDIA + OUTERDIA
  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
1     44 24.115                           
2     43 22.867  1    1.2472 2.3453  0.133</code></pre>
</div>
</div>
<p>Although <code>OUTERDIA</code> is correlated with <code>WEIGHT</code>, it also has high correlation with <code>EXTDIA</code>. In other words, the correlation matrix gives us some indication of how many variables might be needed in a multiple regression model, although by itself it cannot tell us what combination of predictor variables is good or best.</p>
<div id="fig-f5-5" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/5-5.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;5: Issues with multiple predictors</figcaption>
</figure>
</div>
<div id="fig-f5-7" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/5-7.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;6: Effect of multiple predictors on model summaries</figcaption>
</figure>
</div>
<p><a href="#fig-f5-5">Figure&nbsp;5</a> and <a href="#fig-f5-7">Figure&nbsp;6</a> summarise the following facts:</p>
<ol type="1">
<li><p>When there is only <strong>one</strong> explanatory variable, <span class="math inline">\(R^2\)</span> = SSR/SST equals the square of the correlation coefficient between that variable and the dependent variable. Therefore if only one variable is to be chosen, it should have the highest correlation with the response variable, <span class="math inline">\(Y\)</span>.</p></li>
<li><p>When variables are added to a model, the regression sum of squares SSR will increase and the residual or error sum of squares SSE will reduce. The opposite is true if variables are dropped from the model. This fact follows from <a href="#fig-f5-7">Figure&nbsp;6</a>.</p></li>
<li><p>The other side of the coin to the above remark is that as additional variables are added, the Sums of Squares for residuals, SSE, will decrease towards zero as also shown in <a href="#fig-f5-7">Figure&nbsp;6</a>(c).</p></li>
<li><p>The overlap of circles in suggests that these changes in both SSR and SST will lessen as more variables are added, see <a href="#fig-f5-5">Figure&nbsp;5</a>(b).</p></li>
<li><p>Following on from the last two notes, as <span class="math inline">\(R^2\)</span> = SSR/SST, <span class="math inline">\(R^2\)</span> will increase monotonically towards 1 as additional variables are added to the model. (monotonically increasing means that it never decreases although it could remain the same). This is indicated by <a href="#fig-f5-7">Figure&nbsp;6</a>(a). If variables are dropped, then <span class="math inline">\(R^2\)</span> will monotonically decrease.</p></li>
<li><p>Against the above trends, the graph of residual mean square in <a href="#fig-f5-7">Figure&nbsp;6</a>(b) reduces to a <em>minimum</em> but may eventually start to increase if enough variables are added. The residual sum of squares SSE decreases as variables are added to the model (see <a href="#fig-f5-5">Figure&nbsp;5</a>(b)). However, the associated df values also decrease so that the residual standard deviation decreases at first and then starts to increase as shown in <a href="#fig-f5-7">Figure&nbsp;6</a>(b). (Note that the residual standard error <span class="math inline">\(s_{e}\)</span> is the square root of the residual mean square</p>
<p><span class="math display">\[s_{e}^{2} =\frac{{\text {SSE}}}{{\text {error degrees of freedom}}},\]</span></p>
<p>denoted as MSE in <a href="#fig-f5-5">Figure&nbsp;5</a>(b)). After a number of variables have been entered, the additional amount of variation explained by them slows down but the degrees of freedom continues to change by 1 for every variable added, resulting in the eventual increase in residual mean square. Note that the graphs in <a href="#fig-f5-5">Figure&nbsp;5</a> are idealised ones. For some data sets, the behaviour of residual mean square may not be monotone.</p></li>
<li><p>Notice that the above trends will occur even if the variables added are <strong>garbage</strong>. For example, you could generate a column of random data or a column of birthdays of your friends, and this would improve the <span class="math inline">\(R^2\)</span> <strong>but not the adjusted</strong> <span class="math inline">\(R^2\)</span>. The adjusted <span class="math inline">\(R^2\)</span> makes adjustment for the degrees of freedom for the SSR and SSE, and hence reliable when compared to the unadjusted or multiple <span class="math inline">\(R^2\)</span>. The residual mean square error also partly adjusts for the drop in the degrees of freedom for the SSE and hence becomes an important measure. The addition of unimportant variables will not improve the adjusted <span class="math inline">\(R^2\)</span> and the mean square error <span class="math inline">\(s_{e}^{2}\)</span>.</p></li>
</ol>
</section>
<section id="other-ss-types" class="level2">
<h2 class="anchored" data-anchor-id="other-ss-types">Other SS types</h2>
<p>The <code>R</code> anova function anova() calculates sequential or Type-I SS values.</p>
<p>Type-II sums of squares is based on the principle of marginality. Type II SS correspond to the <code>R</code> convention in which each variable effect is adjusted for all other <em>appropriate</em> effects.</p>
<p>Type-III sums of squares is the SS added to the regression SS after ALL other predictors including an intercept term. This SS however creates theoretical issues such as violation of marginality principle and we should avoid using this SS type for hypothesis tests.</p>
<p>The <code>R</code> package <code>car</code> has the function <code>Anova()</code> to compute the Type II and III sums of squares. Try-</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(full.model)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="fu">Anova</span>(full.model, <span class="at">type=</span><span class="dv">2</span>)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="fu">Anova</span>(full.model, <span class="at">type=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>For the <strong>horsehearts</strong> data, a comparison of the Type I and II sums squares is given below:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>anova1 <span class="ot">&lt;-</span> full.model <span class="sc">|&gt;</span> </span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">anova</span>() <span class="sc">|&gt;</span> </span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term, <span class="st">"Type I SS"</span> <span class="ot">=</span> sumsq)  </span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>anova2 <span class="ot">&lt;-</span> full.model <span class="sc">|&gt;</span> </span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">Anova</span>(<span class="at">type=</span><span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term, <span class="st">"Type II SS"</span> <span class="ot">=</span> sumsq) </span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>type1and2 <span class="ot">&lt;-</span> <span class="fu">full_join</span>(anova1, anova2, <span class="at">by=</span><span class="st">"term"</span>)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>type1and2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">

<table data-quarto-disable-processing="true" class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> term </th>
   <th style="text-align:right;"> Type I SS </th>
   <th style="text-align:right;"> Type II SS </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> INNERSYS </td>
   <td style="text-align:right;"> 34.40 </td>
   <td style="text-align:right;"> 0.20 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> INNERDIA </td>
   <td style="text-align:right;"> 3.53 </td>
   <td style="text-align:right;"> 0.62 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> OUTERSYS </td>
   <td style="text-align:right;"> 2.76 </td>
   <td style="text-align:right;"> 1.69 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> OUTERDIA </td>
   <td style="text-align:right;"> 0.13 </td>
   <td style="text-align:right;"> 0.55 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> EXTSYS </td>
   <td style="text-align:right;"> 0.06 </td>
   <td style="text-align:right;"> 1.79 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> EXTDIA </td>
   <td style="text-align:right;"> 1.90 </td>
   <td style="text-align:right;"> 1.90 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Residuals </td>
   <td style="text-align:right;"> 14.07 </td>
   <td style="text-align:right;"> 14.07 </td>
  </tr>
</tbody>
</table>

</div>
</div>
<p>When predictor variables are correlated, it is difficult to assess their absolute importance and the importance of a variable can be assessed only relatively. This is not an issue with the most highly correlated predictor in general.</p>
</section>
</section>
<section id="regression-fitting-with-fewer-predictors" class="level1">
<h1>Regression Fitting with Fewer Predictors</h1>
<p>The first step before selection of the best subset of predictors is to study the correlation matrix. For horses’ heart data, the explanatory variable which is most highly correlated with <span class="math inline">\(y\)</span> (<code>WEIGHT</code>) is <span class="math inline">\(x_2\)</span> (<code>INNERDIA</code>) having a correlation coefficient of 0.811 (see <a href="#fig-multggally">Figure&nbsp;1</a>). This means that <code>INNERDIA</code> should be the single best predictor. We may guess that the next best variable to join <code>INNERDIA</code>. This would be <span class="math inline">\(x_3\)</span> (<code>OUTERSYS</code>) but the correlations between <span class="math inline">\(x_3\)</span> and the other explanatory variables clouds the issue. In other words, the significance or otherwise of a variable in a multiple regression model depends on the other variables in the model.</p>
<p>Consider the regression of horses’ heart <code>WEIGHT</code> on <code>INNERDIA</code>, <code>OUTERSYS</code>, and <code>EXTSYS</code>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>threevar.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> INNERDIA <span class="sc">+</span> OUTERSYS <span class="sc">+</span> EXTSYS,</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data=</span>horsehearts)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>threevar.model <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">

<table data-quarto-disable-processing="true" class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> term </th>
   <th style="text-align:right;"> estimate </th>
   <th style="text-align:right;"> std.error </th>
   <th style="text-align:right;"> statistic </th>
   <th style="text-align:right;"> p.value </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> (Intercept) </td>
   <td style="text-align:right;"> -1.341 </td>
   <td style="text-align:right;"> 0.474 </td>
   <td style="text-align:right;"> -2.828 </td>
   <td style="text-align:right;"> 0.007 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> INNERDIA </td>
   <td style="text-align:right;"> 0.958 </td>
   <td style="text-align:right;"> 0.262 </td>
   <td style="text-align:right;"> 3.649 </td>
   <td style="text-align:right;"> 0.001 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> OUTERSYS </td>
   <td style="text-align:right;"> 0.597 </td>
   <td style="text-align:right;"> 0.203 </td>
   <td style="text-align:right;"> 2.940 </td>
   <td style="text-align:right;"> 0.005 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> EXTSYS </td>
   <td style="text-align:right;"> -0.034 </td>
   <td style="text-align:right;"> 0.063 </td>
   <td style="text-align:right;"> -0.534 </td>
   <td style="text-align:right;"> 0.596 </td>
  </tr>
</tbody>
</table>

</div>
</div>
<p>The coefficient of <code>EXTSYS</code> is not significant at 5% level. However coefficient of <code>EXTSYS</code> was found to be significant in the full regression. The significance of <code>INNERDIA</code> coefficient has also changed. This example shows that <em>we cannot fully rely on the</em> <span class="math inline">\(t\)</span>-test and discard a variable because its coefficient is insignificant.</p>
<p>There are various search methods for finding the best subset of explanatory variables. We will consider <strong>stepwise procedures</strong>, namely algorithms that follow a series of steps to find a good set of predictors. At each step, the current regression model is compared with competing models in which one variable has either been added (<em>forward selection</em> procedures) or removed (<em>backward elimination</em> procedures). Some measure of goodness is required so that the variable selection procedure can decide whether to switch to one of the competing models or to stop at the current best model. Of the two procedures, backward elimination has two advantages. One is computational: step 2 of the forward selection requires calculation of a large number of competing models whereas step 2 of the backward elimination only requires one. The other is statistical and more subtle. Consider two predictor variables <span class="math inline">\(x_{i}\)</span> and <span class="math inline">\(x_{j}\)</span> and suppose that the forward selection procedure does not add either because their individual importance is low. It may be that their joint influence is important, but the forwards procedure has not been able to detect this. In contrast, the backward elimination procedure starts with all variables included and so is able to delete one and keep the other.</p>
<p>A stepwise regression algorithm can also combine <em>both</em> the backward elimination and forward selection procedures. The procedure is the same as forward selection, but immediately after each step of the forward selection algorithm, a step of backward elimination is carried out.</p>
<p>Variable selection solely based <span class="math inline">\(p\)</span> values is preferred only for certain applications such as analysis of factorial type experimental data where response surfaces are fitted. The base <code>R</code> does model selection based on <span class="math inline">\(AIC\)</span> which has to be as minimum as possible for a good model. We shall now discuss the concept of <span class="math inline">\(AIC\)</span> and other model selection criteria.</p>
<p>One way to balance model fit with model complexity (number of parameters) is to choose the model with the <strong>minimal</strong> value of Akaike Information Criterion (<strong>AIC</strong> for short, derived by Prof.&nbsp;Hirotugu Akaike as the minimum information theoretic criterion):</p>
<p><span class="math display">\[AIC = n\log \left( \frac{SSE}{n} \right) + 2p\]</span></p>
<p>Here <span class="math inline">\(n\)</span> is the size of the data set and <span class="math inline">\(p\)</span> is the number of variables in the model. A model with more variables (larger value of <span class="math inline">\(p\)</span>) will produce a smaller residual sum of squares SSE but is penalised by the second term.</p>
<p>Bayesian Information Criterion (BIC) (or also called Schwarz’s Bayesian criterion, SBC) places a higher penalty that depends on <span class="math inline">\(n\)</span>, the number of observations. As a result <span class="math inline">\(BIC\)</span> fares well for selecting a model that explains the relationships well while <span class="math inline">\(AIC\)</span> fares well when selecting a model for prediction purposes.</p>
<p>A number of corrections to <span class="math inline">\(AIC\)</span> and <span class="math inline">\(BIC\)</span> have been proposed in the literature depending on the type of model fitted. We will not study them in this course.</p>
<p>An alternative measure called Mallow’s <span class="math inline">\(C_{p}\)</span> index is also available using which we may judge whether the variables at the current step (smaller model) are excessive or short. If unimportant variables are added to the model, then the variance of the fitted values will increase. Similarly if important variables are added, then the bias of the fitted values will decrease. The <span class="math inline">\(C_{p}\)</span> index, which balances the variance and bias, is given by the formula <span class="math display">\[C_{p} = \frac{{\text  {SS Error for Smaller Model}}}{{\text {Mean Square Error for full regression}}} -(n-2p)\]</span> where <span class="math inline">\(p\)</span> = no. of estimated coefficients (including the intercept) in the smaller model and <span class="math inline">\(n\)</span> = total number of observations. The most desired value for the <span class="math inline">\(C_{p}\)</span> index is the number of parameters (including the <span class="math inline">\(y\)</span>-intercept) or just smaller. If <span class="math inline">\(C_p&gt;&gt;p\)</span>, the model is biased. On the other hand, if <span class="math inline">\(C_p&lt;&lt;p\)</span>, the model associated variability is too large. The trade-off between bias and variance is best when <span class="math inline">\(C_{p}=p\)</span>. But the <span class="math inline">\(C_{p}\)</span> index is not useful in judging the adequacy of the full regression model because it requires an assumption on what constitutes the full regression. This is not an issue with the <span class="math inline">\(AIC\)</span> or <span class="math inline">\(BIC\)</span> criterion.</p>
<p>For prediction modelling, the following three measures are popular and the <code>modelr</code> package will extract these prediction accuracy measures and many more.</p>
<p><em>Mean Squared Deviation</em> (MSD):</p>
<p>MSD is the mean of the squared errors (i.e., deviations).</p>
<p><span class="math display">\[MSD = \frac{\sum \left({\text {observation-fit}}\right)^2 }{{\text {number of observations}}},\]</span></p>
<p>MSD is also sometimes called the Mean Squared Error (MSE). Note that while computing the MSE, the divisor will be the degrees of freedom and not the number of observations. The square-root of MSE is abbreviated as <em>RMSE</em>, and commonly employed as a measure of prediction accuracy.</p>
<p><em>Mean Absolute Percentage Error</em> (MAPE):</p>
<p>MAPE is the average percentage relative error per observation. MAPE is defined as</p>
<p><span class="math display">\[MAPE =\frac{\sum \frac{\left|{\text {observation-fit}}\right|}{{\text {observation}}} }{{\text {number of observations}}} {\times100}.\]</span></p>
<p>Note that MAPE is unitless.</p>
<p><em>Mean Absolute Deviation</em> (MAD):</p>
<p>MAD is the average absolute error per observation and also known as MAE (mean absolute error). MAD is defined as</p>
<p><span class="math display">\[MAD =\frac{\sum \left|{\text {observation-fit}}\right| }{{\text {number of observations}}}.\]</span></p>
<p>For the horsehearts data, stepwise selection can be implemented using many R packages including <code>MASS</code>, <code>car</code>, <code>leaps</code> <code>HH</code> <code>caret</code>, and <code>SignifReg</code>. Examples given below are based on the horses hearts data.</p>
<ol type="1">
<li>The <code>step()</code> function performs a combination of both forward and backward regression. This method favours a model with four variables: <code>WEIGHT ~ INNERDIA + OUTERSYS + EXTSYS + EXTDIA</code></li>
</ol>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> ., <span class="at">data =</span> horsehearts)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>stats<span class="sc">::</span><span class="fu">step</span>(full.model) </span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># or MASS::stepAIC(full.model)</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># or step(full.model, trace = FALSE) </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<ol start="2" type="1">
<li>The <code>stepAIC()</code> function from the MASS package can also be used instead of the <code>step()</code> function. Try-</li>
</ol>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS, <span class="at">exclude=</span><span class="st">"select"</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="fu">stepAIC</span>(full.reg, <span class="at">direction=</span><span class="st">"backward"</span>, <span class="at">trace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="fu">stepAIC</span>(full.reg, <span class="at">direction=</span><span class="st">"both"</span>, <span class="at">trace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>null.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> <span class="dv">1</span>, <span class="at">data=</span>horsehearts)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>stats<span class="sc">::</span><span class="fu">step</span>(</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>  full.reg, </span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">scope =</span> <span class="fu">list</span>(</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">lower =</span> null.model,</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">upper =</span> <span class="sc">~</span>INNERSYS<span class="sc">+</span>INNERDIA<span class="sc">+</span>OUTERSYS<span class="sc">+</span>OUTERDIA<span class="sc">+</span>EXTSYS<span class="sc">+</span>EXTDIA</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    ), </span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">direction =</span> <span class="st">"forward"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<ol start="3" type="1">
<li>The <code>SignifReg</code> package allows variable selection under various criteria. Try-</li>
</ol>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(SignifReg)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"backward"</span>, </span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"BIC"</span>,</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"backward"</span>, </span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"r-adj"</span>, </span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"backward"</span>,</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"p-value"</span>, </span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"both"</span>,</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"BIC"</span>,</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"both"</span>,</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"r-adj"</span>,</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"both"</span>, </span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"p-value"</span>,</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The forward selection procedure also picks only just two variables as seen from the following output:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>stmdl <span class="ot">&lt;-</span> <span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>                   <span class="at">direction =</span> <span class="st">"both"</span>,</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>                   <span class="at">criterion =</span> <span class="st">"AIC"</span>,</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>                   <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>stmdl <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">

<table data-quarto-disable-processing="true" class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> term </th>
   <th style="text-align:right;"> estimate </th>
   <th style="text-align:right;"> std.error </th>
   <th style="text-align:right;"> statistic </th>
   <th style="text-align:right;"> p.value </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> (Intercept) </td>
   <td style="text-align:right;"> -1.512 </td>
   <td style="text-align:right;"> 0.468 </td>
   <td style="text-align:right;"> -3.230 </td>
   <td style="text-align:right;"> 0.002 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> INNERDIA </td>
   <td style="text-align:right;"> 0.799 </td>
   <td style="text-align:right;"> 0.267 </td>
   <td style="text-align:right;"> 2.987 </td>
   <td style="text-align:right;"> 0.005 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> OUTERSYS </td>
   <td style="text-align:right;"> 0.493 </td>
   <td style="text-align:right;"> 0.204 </td>
   <td style="text-align:right;"> 2.415 </td>
   <td style="text-align:right;"> 0.020 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> EXTSYS </td>
   <td style="text-align:right;"> -0.236 </td>
   <td style="text-align:right;"> 0.122 </td>
   <td style="text-align:right;"> -1.938 </td>
   <td style="text-align:right;"> 0.059 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> EXTDIA </td>
   <td style="text-align:right;"> 0.250 </td>
   <td style="text-align:right;"> 0.130 </td>
   <td style="text-align:right;"> 1.920 </td>
   <td style="text-align:right;"> 0.062 </td>
  </tr>
</tbody>
</table>

</div>
</div>
<p>For the full regression model, the <span class="math inline">\(AIC\)</span> is -40.5 and it drops to -42.35 for the four variable model. That is, according to the AIC criterion, a further reduction in model size does not compensate for the decline in model fit as measured by the AIC. The <span class="math inline">\(C_{p}\)</span> index also recommends the four variable model because for the <span class="math inline">\(C_{p}\)</span> value of 4.9 is closer to 5, the number of model coefficients.</p>
<ol start="4" type="1">
<li>Step-wise selection of predictors can also be done along with cross validation in each step. The <code>R</code> package <em>caret</em> enables this. For the horses heart data, the following codes perform the backward regression.</li>
</ol>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(leaps)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>fitControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"repeatedcv"</span>, </span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">number =</span> <span class="dv">5</span>, </span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">repeats =</span> <span class="dv">100</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>leapBackwardfit <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>  WEIGHT <span class="sc">~</span> ., </span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> horsehearts,</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> fitControl, </span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"leapBackward"</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(leapBackwardfit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Note that an asterisk in the row means that a particular variable is included in the step. The model in the last step excludes <code>INNERSYS</code> and <code>OUTERDIA.</code> On the other hand, the forward regression includes only two variables namely <code>INNERDIA</code> and <code>OUTERSYS</code>. We can also directly use the <code>leaps</code> package without cross validation.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>fitControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"repeatedcv"</span>, </span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">number =</span> <span class="dv">5</span>, </span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">repeats =</span> <span class="dv">100</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>leapForwardfit <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>  WEIGHT <span class="sc">~</span> ., </span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> horsehearts,</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> fitControl, </span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"leapForward"</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(leapForwardfit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Subset selection object
6 Variables  (and intercept)
         Forced in Forced out
INNERSYS     FALSE      FALSE
INNERDIA     FALSE      FALSE
OUTERSYS     FALSE      FALSE
OUTERDIA     FALSE      FALSE
EXTSYS       FALSE      FALSE
EXTDIA       FALSE      FALSE
1 subsets of each size up to 2
Selection Algorithm: forward
         INNERSYS INNERDIA OUTERSYS OUTERDIA EXTSYS EXTDIA
1  ( 1 ) " "      "*"      " "      " "      " "    " "   
2  ( 1 ) " "      "*"      "*"      " "      " "    " "   </code></pre>
</div>
</div>
<section id="best-subsets-selection" class="level2">
<h2 class="anchored" data-anchor-id="best-subsets-selection">Best Subsets Selection</h2>
<p>An exhaustive screening of all possible regression models (and hence the name <strong>best subsets</strong> regression) can also be done using software. For example, there are 6 predictor variables in the horses’ hearts data. If we fix the number of predictors as 3, then <span class="math inline">\(\small {\left(\begin{array}{c} {6} \\ {3} \end{array}\right)} = 20\)</span> regression models are possible. One may select the ‘best’ 3-variable model based on criteria such as AIC, <span class="math inline">\(C_{p}\)</span>, <span class="math inline">\(R_{adj}^{2}\)</span> etc. Software must be employed to perform the conventional stepwise regression procedures. Software algorithms give one or more best candidate models fixing the number of variables in each step.</p>
<p>On the basis of our analysis on the horses’ hear data, we might decide to recommend the model with predictor variables <code>EXTDIA</code>, <code>EXTSYS</code>, <code>INNERDIA</code> and <code>OUTERSYS</code>. In particular if the model is to be used for describing relationships then we would tend to include more variables. For prediction purposes, however, a simpler feasible model is preferred and in this case we may opt for the smaller model with only <code>INNERDIA</code> and <code>OUTERSYS</code>. See <a href="#tbl-subset11">Table&nbsp;4</a> produced using the following <code>R</code> codes:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(leaps)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(HH)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>b.model <span class="ot">&lt;-</span> <span class="fu">regsubsets</span>(WEIGHT <span class="sc">~</span> ., <span class="at">data =</span> horsehearts) <span class="sc">|&gt;</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summaryHH</span>() </span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>b.model <span class="sc">|&gt;</span> </span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">3</span>) <span class="sc">|&gt;</span> </span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">bootstrap_options =</span> <span class="st">"basic"</span>, <span class="at">full_width =</span> F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="tbl-subset11" class="anchored">
<table class="table table-sm table-striped small" data-quarto-postprocess="true">
<caption>Table&nbsp;4: Subset selection</caption>
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">model</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">p</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">rsq</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">rss</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">adjr2</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">cp</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">bic</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">stderr</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">INNERD</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">0.658</td>
<td style="text-align: right;">19.450</td>
<td style="text-align: right;">0.650</td>
<td style="text-align: right;">11.923</td>
<td style="text-align: right;">-41.677</td>
<td style="text-align: right;">0.665</td>
</tr>
<tr class="even">
<td style="text-align: left;">INNERD-OUTERS</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">0.715</td>
<td style="text-align: right;">16.173</td>
<td style="text-align: right;">0.702</td>
<td style="text-align: right;">4.838</td>
<td style="text-align: right;">-46.335</td>
<td style="text-align: right;">0.613</td>
</tr>
<tr class="odd">
<td style="text-align: left;">INNERD-OUTERS-OUTERD</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">0.718</td>
<td style="text-align: right;">16.043</td>
<td style="text-align: right;">0.698</td>
<td style="text-align: right;">6.477</td>
<td style="text-align: right;">-42.878</td>
<td style="text-align: right;">0.618</td>
</tr>
<tr class="even">
<td style="text-align: left;">INNERD-OUTERS-EXTS-EXTD</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">0.741</td>
<td style="text-align: right;">14.739</td>
<td style="text-align: right;">0.715</td>
<td style="text-align: right;">4.862</td>
<td style="text-align: right;">-42.949</td>
<td style="text-align: right;">0.600</td>
</tr>
<tr class="odd">
<td style="text-align: left;">INNERD-OUTERS-OUTERD-EXTS-EXTD</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">0.749</td>
<td style="text-align: right;">14.272</td>
<td style="text-align: right;">0.718</td>
<td style="text-align: right;">5.566</td>
<td style="text-align: right;">-40.602</td>
<td style="text-align: right;">0.597</td>
</tr>
<tr class="even">
<td style="text-align: left;">INNERS-INNERD-OUTERS-OUTERD-EXTS-EXTD</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">0.753</td>
<td style="text-align: right;">14.067</td>
<td style="text-align: right;">0.714</td>
<td style="text-align: right;">7.000</td>
<td style="text-align: right;">-37.437</td>
<td style="text-align: right;">0.601</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>Sometimes theory may indicate that a certain explanatory variable should be included in the model (e.g.&nbsp;due to small sample size). If this variable is found to make an insignificant contribution to the model, then one should exclude the variable when the model is to be used for prediction but if the model is to be used for explanation purposes only then the variable should be included. Other considerations such as cost and time may also be taken into account. For every method or algorithm, one could find peculiar data sets where it fouls up. The moral – be alert and don’t automatically accept models thrown up by a program. Note there is <strong>never one right answer</strong> as different methods and different criteria lead to different models.</p>
<p>Variable selection procedures can be a valuable tool in data analysis, particularly in the early stages of building a model. At the same time, they present certain dangers. There are several reasons for this:</p>
<ol type="1">
<li><p>These procedures automatically snoop though many models and may select ones which, by chance, happen to fit well.</p></li>
<li><p>These forward or backward stepwise procedures are <em>heuristic</em> (i.e., shortcut) algorithms, which often work very well but which may not always select the best model for a given number of predictors (here best may refer to adjusted <span class="math inline">\(R^2\)</span>-values, or AIC or some other criterion).</p></li>
<li><p>Automatic procedures cannot take into account special knowledge the analyst may have about the data. Therefore, the model selected may not be the best (or make sense) from a practical point of view.</p></li>
<li><p>Methods are available that <em>shrink</em> coefficients towards zero. The least squares approach minimises the residual sums of squares or RSS without placing any constraint on the coefficients. The shrinkage methods, which place a constraint on the coefficients, work well when there are large numbers of predictors. A <em>ridge regression</em> shrinks the coefficients towards zero but in relation each other. On the other hand, (Least Absolute Selection and Shrinkage Operator) <em>lasso</em> regression shrinks some of coefficients to zero which means these predictors can be dropped. Note that the ridge regression does not completely remove predictors. By shrinking large coefficients, we obtain a model with higher bias but lower variance. This process is known as <em>regularisation</em> in the literature (not covered in this course).</p></li>
</ol>
</section>
</section>
<section id="polynomial-models" class="level1">
<h1>Polynomial Models</h1>
<p>Consider the <strong>pinetree</strong> data set which contains the circumference measurements of pine trees at four positions. The simple regression of the top circumference on the first (bottom) circumference, the fit is <span class="math inline">\({\text {Top = -6.33 + 0.763 First}}\)</span>. This fit is satisfactory on many counts (highly significant <span class="math inline">\(t\)</span> and <span class="math inline">\(F\)</span> values, high <span class="math inline">\(R^{2}\)</span> etc); see <a href="#tbl-poly1tidy">Table&nbsp;5</a> and <a href="#tbl-poly1glance">Table&nbsp;6</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">url =</span> <span class="st">"http://www.massey.ac.nz/~anhsmith/data/pinetree.RData"</span>, </span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">destfile =</span> <span class="st">"pinetree.RData"</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"pinetree.RData"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>pine1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Top <span class="sc">~</span> First, <span class="at">data =</span> pinetree) </span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>pine1 <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 5
  term        estimate std.error statistic  p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)   -6.33     0.765      -8.28 2.10e-11
2 First          0.763    0.0240     31.8  2.20e-38</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-poly1tidy" class="anchored">

<table data-quarto-disable-processing="true" class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;"><caption>Table&nbsp;5:  <p>tidy() output of lm(Top~First, data=pinetree)</p> </caption>
 <thead>
  <tr>
   <th style="text-align:left;"> term </th>
   <th style="text-align:right;"> estimate </th>
   <th style="text-align:right;"> std.error </th>
   <th style="text-align:right;"> statistic </th>
   <th style="text-align:right;"> p.value </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> (Intercept) </td>
   <td style="text-align:right;"> -6.334 </td>
   <td style="text-align:right;"> 0.765 </td>
   <td style="text-align:right;"> -8.278 </td>
   <td style="text-align:right;"> 0 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> First </td>
   <td style="text-align:right;"> 0.763 </td>
   <td style="text-align:right;"> 0.024 </td>
   <td style="text-align:right;"> 31.779 </td>
   <td style="text-align:right;"> 0 </td>
  </tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>pine1 <span class="sc">|&gt;</span> </span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(adj.r.squared, sigma, statistic, p.value, AIC, BIC)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-poly1glance" class="anchored">

<table data-quarto-disable-processing="true" class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;"><caption>Table&nbsp;6:  <p>glance() output of lm(Top~First, data=pinetree)</p> </caption>
 <thead>
  <tr>
   <th style="text-align:right;"> adj.r.squared </th>
   <th style="text-align:right;"> sigma </th>
   <th style="text-align:right;"> statistic </th>
   <th style="text-align:right;"> p.value </th>
   <th style="text-align:right;"> AIC </th>
   <th style="text-align:right;"> BIC </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:right;"> 0.945 </td>
   <td style="text-align:right;"> 1.291 </td>
   <td style="text-align:right;"> 1009.896 </td>
   <td style="text-align:right;"> 0 </td>
   <td style="text-align:right;"> 204.85 </td>
   <td style="text-align:right;"> 211.133 </td>
  </tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The residual plot, shown as <a href="#fig-pine1">Figure&nbsp;7</a>, still provides an important clue that we should try a polynomial (cubic) model.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggfortify)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Registered S3 method overwritten by 'ggfortify':
  method          from   
  autoplot.glmnet parsnip</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(pine1, <span class="at">which=</span><span class="dv">1</span>, <span class="at">ncol=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-pine1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-pine1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;7: Residuals vs fits plot</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>pine3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Top <span class="sc">~</span> <span class="fu">poly</span>(First, <span class="dv">3</span>, <span class="at">raw=</span><span class="cn">TRUE</span>), </span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> pinetree)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><a href="#tbl-poly3tidy">Table&nbsp;7</a> shows the significance results for the polynomial model <span class="math inline">\({\text Top=44.1 - 3.97First+0.142}\left({\text First}\right)^{2} - 0.00135\left(\text {First}\right)^{3}\)</span>. This model has achieved a good reduction in the residual standard error and improved AIC and BIC (see <a href="#tbl-poly3glance">Table&nbsp;8</a>). The residual diagnostic plots are somewhat satisfactory. The Scale-Location plot suggests that there may be a subgrouping variable. The fitted model can be further improved using the Area categorical factor. This topic, known as the analysis of covariance will be covered later on. Note that both models are satisfactory in terms of Cook’s distance. A few leverage or <span class="math inline">\(h_{ii}\)</span> values cause concern seen in <a href="#fig-pinelev">Figure&nbsp;8</a> but we will ignore them given the size of the data set.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>pine3 <span class="sc">|&gt;</span> <span class="fu">tidy</span>() </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-poly3tidy" class="anchored">

<table data-quarto-disable-processing="true" class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;"><caption>Table&nbsp;7:  <p>tidy() output of lm(Top~poly(First, 3, raw=TRUE), data=pinetree)</p> </caption>
 <thead>
  <tr>
   <th style="text-align:left;"> term </th>
   <th style="text-align:right;"> estimate </th>
   <th style="text-align:right;"> std.error </th>
   <th style="text-align:right;"> statistic </th>
   <th style="text-align:right;"> p.value </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> (Intercept) </td>
   <td style="text-align:right;"> 44.1213 </td>
   <td style="text-align:right;"> 7.0391 </td>
   <td style="text-align:right;"> 6.2680 </td>
   <td style="text-align:right;"> 0 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> poly(First, 3, raw = TRUE)1 </td>
   <td style="text-align:right;"> -3.9716 </td>
   <td style="text-align:right;"> 0.6951 </td>
   <td style="text-align:right;"> -5.7141 </td>
   <td style="text-align:right;"> 0 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> poly(First, 3, raw = TRUE)2 </td>
   <td style="text-align:right;"> 0.1416 </td>
   <td style="text-align:right;"> 0.0221 </td>
   <td style="text-align:right;"> 6.3939 </td>
   <td style="text-align:right;"> 0 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> poly(First, 3, raw = TRUE)3 </td>
   <td style="text-align:right;"> -0.0014 </td>
   <td style="text-align:right;"> 0.0002 </td>
   <td style="text-align:right;"> -5.9510 </td>
   <td style="text-align:right;"> 0 </td>
  </tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>pine3 <span class="sc">|&gt;</span> </span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(adj.r.squared, sigma, statistic, p.value, AIC, BIC) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-poly3glance" class="anchored">

<table data-quarto-disable-processing="true" class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;"><caption>Table&nbsp;8:  <p>glance() output of lm(Top~poly(First,3, raw=TRUE), data=pinetree)</p> </caption>
 <thead>
  <tr>
   <th style="text-align:right;"> adj.r.squared </th>
   <th style="text-align:right;"> sigma </th>
   <th style="text-align:right;"> statistic </th>
   <th style="text-align:right;"> p.value </th>
   <th style="text-align:right;"> AIC </th>
   <th style="text-align:right;"> BIC </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:right;"> 0.97 </td>
   <td style="text-align:right;"> 0.89 </td>
   <td style="text-align:right;"> 725.98 </td>
   <td style="text-align:right;"> 0 </td>
   <td style="text-align:right;"> 162.46 </td>
   <td style="text-align:right;"> 172.93 </td>
  </tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(pine3, <span class="at">which=</span><span class="dv">5</span>, <span class="at">ncol=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-pinelev" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-pinelev-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;8: Residual vs Leverage plot</figcaption>
</figure>
</div>
</div>
</div>
<p>How quadratic and quartic models fare compared to the cubic fit is also of interest. Try the <code>R</code> code given below and compare the outputs:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(WEIGHT <span class="sc">~</span> OUTERDIA, <span class="at">data =</span> horsehearts))</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(WEIGHT <span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">2</span>, <span class="at">raw=</span>T), <span class="at">data =</span> horsehearts))</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(WEIGHT <span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">3</span>, <span class="at">raw=</span>T), <span class="at">data =</span> horsehearts))</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(WEIGHT <span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">4</span>, <span class="at">raw=</span>T), <span class="at">data =</span> horsehearts))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The key model summary measures of the four polynomial models are shown in <a href="#tbl-polysummary">Table&nbsp;9</a>. As expected, the <span class="math inline">\(R^2\)</span> value increases, although not by much in this case, as polynomial terms are added. Note that the multicollinearity among the polynomial terms renders all the coefficients of the quadratic regression insignificant at 5% level. For the cubic regression model, all the coefficients are significant. It is usual to keep adding the higher order terms until there is no significant increase in the additional variation explained (measured by the <span class="math inline">\(t\)</span> or <span class="math inline">\(F\)</span> statistic). Alternatively we may use the AIC criterion. In the above example, when the quartic term <code>OUTERDIA</code><span class="math inline">\(^4\)</span> is added, the AIC slightly increases to 114.99 (from 114.65) suggesting that we may stop with the cubic regression.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>modstats <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">straight.line =</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> OUTERDIA, </span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data =</span> horsehearts), </span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">quadratic =</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">2</span>,<span class="at">raw=</span>T),</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data=</span>horsehearts), </span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">cubic =</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">3</span>, <span class="at">raw=</span>T), </span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>             <span class="at">data=</span>horsehearts), </span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">quartic =</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">4</span>, <span class="at">raw=</span>T),</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>               <span class="at">data=</span>horsehearts)</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span> </span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">enframe</span>(</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">"model"</span>,</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">value =</span> <span class="st">"fit"</span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span> </span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">glanced =</span> <span class="fu">map</span>(fit, glance)) <span class="sc">|&gt;</span> </span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(glanced) <span class="sc">|&gt;</span> </span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(model, r.squared, adj.r.squared, sigma, </span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>         statistic, AIC, BIC)</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>modstats</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-polysummary" class="anchored">

<table data-quarto-disable-processing="true" class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;"><caption>Table&nbsp;9:  <p>Glancing Polynomial models</p> </caption>
 <thead>
  <tr>
   <th style="text-align:left;"> model </th>
   <th style="text-align:right;"> r.squared </th>
   <th style="text-align:right;"> adj.r.squared </th>
   <th style="text-align:right;"> sigma </th>
   <th style="text-align:right;"> statistic </th>
   <th style="text-align:right;"> AIC </th>
   <th style="text-align:right;"> BIC </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> straight.line </td>
   <td style="text-align:right;"> 0.47 </td>
   <td style="text-align:right;"> 0.46 </td>
   <td style="text-align:right;"> 0.83 </td>
   <td style="text-align:right;"> 39.13 </td>
   <td style="text-align:right;"> 117.01 </td>
   <td style="text-align:right;"> 122.50 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> quadratic </td>
   <td style="text-align:right;"> 0.48 </td>
   <td style="text-align:right;"> 0.46 </td>
   <td style="text-align:right;"> 0.83 </td>
   <td style="text-align:right;"> 19.87 </td>
   <td style="text-align:right;"> 118.17 </td>
   <td style="text-align:right;"> 125.49 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> cubic </td>
   <td style="text-align:right;"> 0.54 </td>
   <td style="text-align:right;"> 0.51 </td>
   <td style="text-align:right;"> 0.79 </td>
   <td style="text-align:right;"> 16.38 </td>
   <td style="text-align:right;"> 114.65 </td>
   <td style="text-align:right;"> 123.79 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> quartic </td>
   <td style="text-align:right;"> 0.56 </td>
   <td style="text-align:right;"> 0.51 </td>
   <td style="text-align:right;"> 0.79 </td>
   <td style="text-align:right;"> 12.81 </td>
   <td style="text-align:right;"> 114.99 </td>
   <td style="text-align:right;"> 125.96 </td>
  </tr>
</tbody>
</table>

</div>
</div>
</div>
<p>It is desirable to keep the coefficients the same when higher order polynomial terms are added. This can be done using orthogonal polynomial coefficients (we will skip the theory) for which we will avoid the argument <code>raw</code> within the function <code>poly()</code>. Try-</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Top <span class="sc">~</span> <span class="fu">poly</span>(First,<span class="dv">1</span>), <span class="at">data=</span>pinetree)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Top <span class="sc">~</span> <span class="fu">poly</span>(First,<span class="dv">2</span>), <span class="at">data=</span>pinetree)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Top <span class="sc">~</span> <span class="fu">poly</span>(First,<span class="dv">3</span>), <span class="at">data=</span>pinetree)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Stepwise methods are not employed for developing polynomial models as it would not be appropriate (say) to have the linear and cubic terms but drop the quadratic one. The coefficient terms for the higher order terms become very small. It is also possible that the coefficient estimation may be incorrect due to ill conditioning of the data matrix which is used obtain the model coefficients. Some authors recommend appropriate rescaling of the polynomial terms (such as subtracting the mean etc) to avoid such problems.</p>
<p>The use of polynomials greater than second-order is discouraged. Higher-order polynomials are known to be extremely volatile; they have high variance, and make bad predictions. If you need a more flexible model, then it is generally better to use some sort of smoother than a high-order polynomial.</p>
<p>In fact, a popular method of smoothing is known as “local polynomial fitting”, or <strong>spline smoothing</strong>. Local polynomials are sometimes preferred to a single polynomial regression model for the whole data set. An example based on the <code>pinetree</code> data is shown in <a href="#fig-spline">Figure&nbsp;9</a> which uses the <code>bs()</code> function from the <em>splines</em> package.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>pinetree <span class="sc">|&gt;</span> </span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(First, Top) <span class="sc">+</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> lm, </span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">formula =</span> y <span class="sc">~</span> splines<span class="sc">::</span><span class="fu">bs</span>(x, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-spline" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-spline-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;9: Polynomial Spline smoothing</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="model-structure-and-other-issues" class="level1">
<h1>Model structure and other issues</h1>
<p>The difficult task in statistical modelling is the assessment of the underlying model structure or alternatively knowing the true form of the relationship. For example, the true relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> variables may be nonlinear. If we incorrectly assume a multiple linear relationship instead, a good model may not result. The interaction between the explanatory variables is also important and this topic is covered in a different section. We may also fit a robust linear model in order to validate the ordinary least squares fit. For the horses heart data, OUTERSYS and EXTDIA were short-listed as the predictors of WEIGHT using the AIC criterion. This least squares regression model can be compared to the robust versions as shown in <a href="#fig-mcompare1">Figure&nbsp;10</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>hh_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> OUTERSYS <span class="sc">+</span> EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>hh_rlm <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">rlm</span>(WEIGHT <span class="sc">~</span> OUTERSYS <span class="sc">+</span> EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>hh_lmrob <span class="ot">&lt;-</span> robustbase<span class="sc">::</span><span class="fu">lmrob</span>(WEIGHT <span class="sc">~</span> OUTERSYS <span class="sc">+</span> EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>horsehearts <span class="sc">|&gt;</span> </span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather_predictions</span>(hh_lm, hh_rlm, hh_lmrob) <span class="sc">%&gt;%</span> </span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>WEIGHT, <span class="at">y=</span>pred, <span class="at">colour=</span>model)) <span class="sc">+</span> </span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>) <span class="sc">+</span> </span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Predicted WEIGHT"</span>) <span class="sc">+</span> <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Comparison of model predictions"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-mcompare1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-mcompare1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;10: Comparison of predictions</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-mcompare1">Figure&nbsp;10</a> shows that the scatter plot of predicted versus actual <span class="math inline">\(Y\)</span> values for the three fitted models which confirms that these models perform very similarly. We may also extract measures such as mean absolute percentage error (MAPE) or residual SD or root mean square error (RMSE) for the three models using <code>modelr</code> package; see the code shown below:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">list</span>(<span class="at">hh_lm =</span> hh_lm, </span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">hh_rlm =</span> hh_rlm, </span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">hh_lmrob =</span> hh_lmrob) <span class="sc">|&gt;</span> </span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">enframe</span>(<span class="st">"method"</span>, <span class="st">"fit"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">MAPE =</span> <span class="fu">map_dbl</span>(fit, \(x){<span class="fu">mape</span>(x, horsehearts)}),</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">RMSE =</span> <span class="fu">map_dbl</span>(fit, \(x){<span class="fu">rmse</span>(x, horsehearts)})</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 4
  method   fit      MAPE  RMSE
  &lt;chr&gt;    &lt;list&gt;  &lt;dbl&gt; &lt;dbl&gt;
1 hh_lm    &lt;lm&gt;    0.255 0.648
2 hh_rlm   &lt;rlm&gt;   0.247 0.651
3 hh_lmrob &lt;lmrob&gt; 0.243 0.655</code></pre>
</div>
</div>
<p>Measures such as AIC or BIC need corrections when the normality assumption does not hold but the above summary measures do not require such a distributional assumption to hold.</p>
<p>If a large dataset is in hand, a part of the data (training data) can be used to fit the model and then we can see how well the fitted model works for the remaining data.</p>
</section>
<section id="smoothing-and-regression-modeling-for-time-series" class="level1">
<h1>Smoothing and Regression modeling for Time series</h1>
<p>For time series data, the term <strong>smoothing</strong> means the technique of removing random variation in the data but retaining any trend and cyclic/seasonal type of variations. Two types of smoothing methods are considered in this section. These two methods are basically averaging techniques, which use only the immediate past data (rather than all the observations) with constant and variable weights for each observation.</p>
<section id="time-series-regression-with-seasonality-components" class="level2">
<h2 class="anchored" data-anchor-id="time-series-regression-with-seasonality-components">Time Series Regression with seasonality components</h2>
<p>Indicator variables are used to capture the seasonality such as months and quarters. Time related trends can be picked up with the usual regression. The function <code>tslm()</code> from the <code>forecast</code> package is handy to model the response <span class="math inline">\(Y\)</span> using the time variable and the seasonal indicators. Consider the credit card balance series discussed in Chapter 2. The fitted linear model is shown in <a href="#tbl-cbfit1">Table&nbsp;10</a> and the forecasts made the model for 48 months ahead are shown in <a href="#fig-cbforecast">Figure&nbsp;11</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readxl)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="st">"http://www.massey.ac.nz/~anhsmith/data/hc12_daily_average_balances.xlsx"</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>destfile <span class="ot">&lt;-</span> <span class="st">"hc12.xlsx"</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>curl<span class="sc">::</span><span class="fu">curl_download</span>(url, destfile)</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>credit.balance <span class="ot">&lt;-</span> </span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">read_excel</span>(destfile, <span class="at">na =</span> <span class="st">"-"</span>, <span class="at">skip =</span> <span class="dv">4</span>) <span class="sc">|&gt;</span> </span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(CRCD.MOA20) <span class="sc">|&gt;</span> </span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">na.omit</span>() <span class="sc">|&gt;</span> </span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ts</span>(<span class="at">start=</span><span class="fu">c</span>(<span class="dv">2000</span>,<span class="dv">7</span>), <span class="at">frequency=</span><span class="dv">12</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(forecast)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>cbfit <span class="ot">&lt;-</span> <span class="fu">tslm</span>(credit.balance <span class="sc">~</span> trend <span class="sc">+</span> season)</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>cbfit <span class="sc">|&gt;</span> <span class="fu">forecast</span>(<span class="at">h=</span><span class="dv">48</span>) <span class="sc">|&gt;</span> <span class="fu">autoplot</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-cbforecast" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-cbforecast-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;11: tidy() output of the tslm() fit</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>cbfit <span class="sc">|&gt;</span> <span class="fu">tidy</span>()  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: The `tidy()` method for objects of class `tslm` is not maintained by the broom team, and is only supported through the `lm` tidier method. Please be cautious in interpreting and reporting broom output.

This warning is displayed once per session.</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-cbfit1" class="anchored">

<table data-quarto-disable-processing="true" class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;"><caption>Table&nbsp;10:  <p>tidy() output of the tslm() fit</p> </caption>
 <thead>
  <tr>
   <th style="text-align:left;"> term </th>
   <th style="text-align:right;"> estimate </th>
   <th style="text-align:right;"> std.error </th>
   <th style="text-align:right;"> statistic </th>
   <th style="text-align:right;"> p.value </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> (Intercept) </td>
   <td style="text-align:right;"> 3460.949 </td>
   <td style="text-align:right;"> 122.430 </td>
   <td style="text-align:right;"> 28.269 </td>
   <td style="text-align:right;"> 0.000 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> trend </td>
   <td style="text-align:right;"> 12.771 </td>
   <td style="text-align:right;"> 0.395 </td>
   <td style="text-align:right;"> 32.358 </td>
   <td style="text-align:right;"> 0.000 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> season2 </td>
   <td style="text-align:right;"> -60.206 </td>
   <td style="text-align:right;"> 154.786 </td>
   <td style="text-align:right;"> -0.389 </td>
   <td style="text-align:right;"> 0.698 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> season3 </td>
   <td style="text-align:right;"> -96.978 </td>
   <td style="text-align:right;"> 154.787 </td>
   <td style="text-align:right;"> -0.627 </td>
   <td style="text-align:right;"> 0.532 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> season4 </td>
   <td style="text-align:right;"> -137.532 </td>
   <td style="text-align:right;"> 154.790 </td>
   <td style="text-align:right;"> -0.889 </td>
   <td style="text-align:right;"> 0.375 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> season5 </td>
   <td style="text-align:right;"> -164.651 </td>
   <td style="text-align:right;"> 154.793 </td>
   <td style="text-align:right;"> -1.064 </td>
   <td style="text-align:right;"> 0.288 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> season6 </td>
   <td style="text-align:right;"> -175.292 </td>
   <td style="text-align:right;"> 154.798 </td>
   <td style="text-align:right;"> -1.132 </td>
   <td style="text-align:right;"> 0.258 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> season7 </td>
   <td style="text-align:right;"> -232.007 </td>
   <td style="text-align:right;"> 153.165 </td>
   <td style="text-align:right;"> -1.515 </td>
   <td style="text-align:right;"> 0.131 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> season8 </td>
   <td style="text-align:right;"> -209.839 </td>
   <td style="text-align:right;"> 154.798 </td>
   <td style="text-align:right;"> -1.356 </td>
   <td style="text-align:right;"> 0.176 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> season9 </td>
   <td style="text-align:right;"> -215.827 </td>
   <td style="text-align:right;"> 154.793 </td>
   <td style="text-align:right;"> -1.394 </td>
   <td style="text-align:right;"> 0.164 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> season10 </td>
   <td style="text-align:right;"> -181.642 </td>
   <td style="text-align:right;"> 154.790 </td>
   <td style="text-align:right;"> -1.173 </td>
   <td style="text-align:right;"> 0.242 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> season11 </td>
   <td style="text-align:right;"> -119.718 </td>
   <td style="text-align:right;"> 154.787 </td>
   <td style="text-align:right;"> -0.773 </td>
   <td style="text-align:right;"> 0.440 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> season12 </td>
   <td style="text-align:right;"> 14.728 </td>
   <td style="text-align:right;"> 154.786 </td>
   <td style="text-align:right;"> 0.095 </td>
   <td style="text-align:right;"> 0.924 </td>
  </tr>
</tbody>
</table>

</div>
</div>
</div>
<p><a href="#tbl-cbfit1">Table&nbsp;10</a> shows that the seasonal effects are highly significant. <a href="#fig-cbforecast">Figure&nbsp;11</a> shows that the fitted model is not faring well for the year 2020, which was affected by COVID. The forecasts ahead are also untrustworthy.</p>
<p>Note that the time variable <span class="math inline">\(t\)</span> becomes the predictor in the fitted model but the model is not based on the past or lagged <span class="math inline">\(Y\)</span> data. The smoothing methods discussed below employ such past data.</p>
</section>
<section id="moving-average-smoothing" class="level2">
<h2 class="anchored" data-anchor-id="moving-average-smoothing">Moving Average Smoothing</h2>
<p>Here we compute the mean of successive smaller sets of numbers of immediate past data. The period or length (also called span) of the <strong>moving average</strong> is the number of observations (including the present one) used for averaging. The general expression for the moving average <span class="math inline">\(M_t\)</span> at time <span class="math inline">\(t\)</span> is <span class="math display">\[M_t = [X_t + X_{t-1} + ... + X_{t-N+1}] / N\]</span> where <span class="math inline">\(X_t\)</span> is the observation at time <span class="math inline">\(t\)</span> and <span class="math inline">\(N\)</span> the moving average length. <a href="#fig-MAcntr">Figure&nbsp;12</a> shows the moving average smoothing for the ‘$20 Notes in public hands’ data. It can be noted that the degree of smoothing is directly related to the length of the moving average (i.e., longer the length, greater the smoothing).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>NZnotes20 <span class="ot">&lt;-</span> <span class="fu">read_table</span>(</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">"http://www.massey.ac.nz/~anhsmith/data/20dollar.txt"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(value) <span class="sc">|&gt;</span> </span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ts</span>(<span class="at">start=</span><span class="dv">1968</span>, <span class="at">frequency=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>MA.centred <span class="ot">&lt;-</span> <span class="fu">ma</span>(NZnotes20, <span class="dv">2</span>, <span class="at">centre =</span> <span class="cn">TRUE</span>)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>MA.noncentred <span class="ot">&lt;-</span> <span class="fu">ma</span>(NZnotes20, <span class="dv">2</span>, <span class="at">centre =</span> <span class="cn">FALSE</span>)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(forecast)</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(NZnotes20) <span class="sc">+</span> </span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autolayer</span>(MA.centred, <span class="at">series =</span> <span class="st">"2 y MA centred"</span>) <span class="sc">+</span> </span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autolayer</span>(MA.noncentred, <span class="at">series =</span> <span class="st">"2 y MA noncentred"</span>, <span class="at">linetype=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-MAcntr" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-MAcntr-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;12: Centred and Non-centred Moving Averages</figcaption>
</figure>
</div>
</div>
</div>
<p>When placing the moving averages against time, placing them in the middle time period is more appropriate. Strictly speaking the moving average must fall at <span class="math inline">\(t = 1.5, 2.5, 3.5\)</span> etc when the period of the moving average is an even number. Hence we need to smooth again the moving average smoothed values to place the moving averages at <span class="math inline">\(t = 2, 3, 4\)</span> etc. <a href="#fig-MAcntr">Figure&nbsp;12</a> also compares the centred moving average smoothing and non-centred moving average smoothing (length 2) for the ‘$20 Notes in public hands’ data. It is easy to see that centring has stopped the moving averages from drifting below the original series and ‘lined’ them with the original data.</p>
</section>
<section id="exponential-smoothing" class="level2">
<h2 class="anchored" data-anchor-id="exponential-smoothing">Exponential Smoothing</h2>
<p>In moving average smoothing all past observations are given equal weight. In exponential average smoothing, past observations (i.e.&nbsp;as the observations become older) are given exponentially decreasing weights. That is, recent observations are given relatively more weight than the older observations. Hence the exponential smoothing method becomes a representative method to produce a smoothed time series. The average computed using exponentially decreasing weights is known as the <strong>Exponentially Weighted Moving average</strong> (EWMA). This fitted average is also called <code>level</code> because this method does not allow for trends or seasonality (and everything gets smoothed).</p>
<p>EWMA smoothing begins by setting <span class="math inline">\(S_0\)</span> to <span class="math inline">\(x_1\)</span> (usually), where <span class="math inline">\(S\)</span> stands for smoothed observation (or EWMA), and <span class="math inline">\(x\)</span> for the observation. The subscript in <span class="math inline">\(x\)</span> refers to the time periods <span class="math inline">\(t =1, 2, ... ,n\)</span>. For the second period, <span class="math inline">\(S_2 = \alpha x_2 + (1-\alpha)x_1\)</span> and so on. Here the parameter <span class="math inline">\(\alpha\)</span> is called the smoothing constant, the weight given to the current observation. A general formula is also available to compute the EWMA for any time period <span class="math inline">\(t\)</span>. <a href="#fig-ewma">Figure&nbsp;13</a> shows the single exponential smoothing on the $20 Notes series for <span class="math inline">\(\alpha=0.5\)</span>. Instead of fixing an <span class="math inline">\(\alpha\)</span> value such as 0.5, we may leave it to the software to find an optimum value.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>single.exp <span class="ot">&lt;-</span> NZnotes20 <span class="sc">|&gt;</span> <span class="fu">ses</span>(<span class="at">alpha=</span><span class="fl">0.5</span>) <span class="sc">|&gt;</span> <span class="fu">fitted</span>()</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">autoplot</span>(NZnotes20) <span class="sc">+</span> </span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autolayer</span>(single.exp, <span class="at">series =</span><span class="st">"alpha=0.5"</span>)</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>single.exp1 <span class="ot">&lt;-</span> NZnotes20 <span class="sc">|&gt;</span> <span class="fu">ses</span>() <span class="sc">|&gt;</span> <span class="fu">fitted</span>()</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">autoplot</span>(NZnotes20) <span class="sc">+</span> </span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autolayer</span>(single.exp1, <span class="at">series =</span> <span class="st">"optimised alpha"</span>)</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a>p1<span class="sc">/</span>p2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-ewma" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-ewma-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;13: Single exponential smoothing (fits)</figcaption>
</figure>
</div>
</div>
</div>
<p>The rate at which the effect of older observations on the current EWMA will be dampened depends on <span class="math inline">\(\alpha\)</span>, the smoothing constant. Larger the <span class="math inline">\(\alpha\)</span> value, faster the dampening effect of older observations.</p>
<p>A naive choice for the initial value for <span class="math inline">\(S_0\)</span> (i.e.&nbsp;at the origin) is <span class="math inline">\(x_1\)</span>, the first observation. The other choices include the average of two or more successive observations, estimating using regression methods etc. In this course we will not be concerned with the choice of the initial values very much (and accept the defaults of the <code>R</code> packages).</p>
</section>
<section id="double-exponential-smoothing" class="level2">
<h2 class="anchored" data-anchor-id="double-exponential-smoothing">Double Exponential Smoothing</h2>
<p>Single exponential smoothing is improved to <strong>double exponential smoothing</strong> to account for the trend type of variations. This is achieved by introducing a second smoothing constant say <span class="math inline">\(\beta\)</span>. This weighting constant captures linear trends using the successive differences in the fitted EWMAs. The process of double exponential smoothing is conveniently represented by the following two equations.</p>
<p><span class="math inline">\(S_t = \alpha X_t+(1-\alpha)[S_{t-1} + T_{t-1}]\)</span> (called level equation)</p>
<p>where</p>
<p><span class="math inline">\(T_t =\beta [S_t - S_{t-1}] + (1 -\beta)T_{t-1}\)</span> (called trend equation).</p>
<p>The second equation for the trend EWMA gives a weight of <span class="math inline">\(\beta\)</span> to the current differences in the EWMAs (i.e.&nbsp;<span class="math inline">\(S_t - S_{t-1}\)</span>) and the balance weight <span class="math inline">\((1-\beta)\)</span> to the preceding trend EWMA.</p>
<p>The main or usual EWMA (i.e.&nbsp;<span class="math inline">\(S_t\)</span>) gives a weight of <span class="math inline">\(\alpha\)</span> to the current observation and the balance weight <span class="math inline">\((1-\alpha)\)</span> to the sum of preceding main and trend EWMAs (i.e.&nbsp;<span class="math inline">\(S_{t-1} + T_{t-1}\)</span>). A naive choice for the initial value for <span class="math inline">\(T_0\)</span> (i.e.&nbsp;at the origin) is <span class="math inline">\(x_2-x_1\)</span>, the difference between the first and the second observations. The other choices include the average of two or more successive differences, estimating using regression methods etc. In this course we will not be concerned with the choice of the initial values very much. The smoothing constants <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are obtained by non-linear optimisation methods (such as the Marquardt algorithm). In this course, we will just accept the <code>R</code> outputs as the optimised fits. <a href="#fig-dewma">Figure&nbsp;14</a> shows the double exponential smoothing on the $20 Notes series with optimum <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> (as determined by the <code>forecast</code> package).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>double.exp <span class="ot">&lt;-</span> NZnotes20 <span class="sc">|&gt;</span> <span class="fu">holt</span>() <span class="sc">|&gt;</span> <span class="fu">fitted</span>()</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(NZnotes20) <span class="sc">+</span> </span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autolayer</span>(double.exp, <span class="at">series =</span> <span class="st">"DEWMA-optimised"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-dewma" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-dewma-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;14: Double exponential smoothing</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="triple-exponential-smoothing" class="level2">
<h2 class="anchored" data-anchor-id="triple-exponential-smoothing">Triple Exponential Smoothing</h2>
<p>This approach developed by Holt and Winter (hence the name <strong>Holts-Winter (HW) smoothing</strong>) employs a level equation, a trend equation, and a seasonal equation for smoothing at each time period. Hence three weights, or smoothing parameters are needed.</p>
<p><span class="math inline">\(S_t = \alpha(X_t-P_{t-p}) + (1-\alpha)[S_{t-1}+T_{t-1}]\)</span> (level equation)<br>
<span class="math inline">\(T_t = \beta [S_t-S_{t-1}]+ 1-\beta)T_{t-1}\)</span> (trend equation)<br>
<span class="math inline">\(P_t = \phi (X_t-S_t)+(1-\phi)P_{t-p}\)</span> (seasonal equation of a given period <span class="math inline">\(p\)</span>)</p>
<p>The smoothing parameters <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(\phi\)</span> are constants and are usually estimated minimising the MSE. In order to proceed with the triple exponential smoothing, we need at least one complete season’s data to determine initial estimates of the seasonal indices. For estimating the trend components, it is preferable to have at least two complete season’s data.</p>
<p>The initial trend is usually estimated using the average differences in the corresponding observations in two adjacent seasons. The estimating initial values for seasonal components, we use the averages rather than differences. Regression methods are also employed for estimating the initial values. In this course, we will not study the estimation methods for initial values in any detail but will accept computations and optimisation reported in the <code>forecast</code> R package. <a href="#fig-tewma">Figure&nbsp;15</a> shows the triple exponential smoothing to the outstanding credit card balances series.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(forecast)</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>trp.exp <span class="ot">&lt;-</span> credit.balance <span class="sc">|&gt;</span> <span class="fu">hw</span>() <span class="sc">|&gt;</span> <span class="fu">fitted</span>()</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(credit.balance) <span class="sc">+</span></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autolayer</span>(trp.exp, </span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">series =</span> <span class="st">"Holt-Winter- optimised"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-tewma" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-tewma-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;15: Triple exponential smoothing</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="assessment-of-fit" class="level2">
<h2 class="anchored" data-anchor-id="assessment-of-fit">Assessment of Fit:</h2>
<p>Forecast accuracy measures such as MSE are useful for fixing the smoothing parameters such as the moving average length or the EWMA smoothing constant. We may minimise MSE (say) to fix a value for the EWMA smoothing constant. This can be done by trial and error or by nonlinear optimisation methods (such as Marquardt’s procedure).</p>
<p>By the term <strong>forecasting</strong>, we mean projecting the present time series for future time points. For example, assume that we used an uncentered two period moving average to smooth the ‘$20 Notes’ time series. The moving average value (non-centred) for 1969 is 18.05. A <em>naive</em> approach to forecasting will be to use the smoothed value at time <span class="math inline">\((t-1)\)</span> to forecast for time <span class="math inline">\(t\)</span>. Hence the forecasted value (or simply forecast) of $20 bills for 1970 would be 18.05 as against the actual observed value of 21.76. In the absence of Year 1970 data, the same value 18.05 would be the forecast for 1971 and so on. MAs are not useful for forecasting in general and hence this average is just employed to fit trends or extract trends when seasonal variation is absent.</p>
<p>For EWMA Forecasting, the forecast approach is to add an adjustment for the error that occurred in the last forecast. We again consider ‘$20 Notes’ time series and obtain the EWMA smoothed values for <span class="math inline">\(\alpha = 0.4\)</span>. For the year 1969 (say), the EWMA value is 17.78 as against the actual value 19.41 giving an error of 19.41- 17.78= 2.72. This error is given a weight of 0.4 and added to the 1969 forecast (naive estimate) of 16.69 as <span class="math inline">\(16.69+0.4\times2.72\)</span> giving a forecast value of 17.78 for 1970. The term ‘adjustment error’ will refer to <span class="math inline">\(0.4\times2.72 = 1.088\)</span>. This forecast value is also obtained as</p>
<p>Forecast for <span class="math inline">\(1970 = 0.4\times19.41+0.6\times16.69= 17.78\)</span>.</p>
<p>(from the relationship <span class="math inline">\(S_{t+1}=\alpha x_{t+1}+(1-\alpha)S_t\)</span> where the unavailable value <span class="math inline">\(X_{t+1}\)</span> is replaced by the naive estimate <span class="math inline">\(X_t\)</span>). This forecasting approach is also not useful in the presence of trend etc. Hence only a forecast of one time period ahead is usually done. For forecasting two or more time periods ahead, methods such as double and triple exponential smoothing are more useful.</p>
<p>If we perform the double exponential forecasting for some <span class="math inline">\(m\)</span> periods ahead from a point at time <span class="math inline">\(t\)</span>, the trend part of EWMA, <span class="math inline">\(T_t\)</span>, will be added <span class="math inline">\(m\)</span> times to the naive level estimate <span class="math inline">\(S_t\)</span>. As shown in <a href="#fig-dewmaf">Figure&nbsp;16</a>, the double exponential smoothing approach provides no nonsense forecasts compared to the naive single exponential forecasts in the presence of trends. The fit/forecast quality measures such as the MSE, MAD etc will also be smaller for the double exponential smoothing in the presence of trends.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>holt1 <span class="ot">&lt;-</span> <span class="fu">holt</span>(credit.balance)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>holt2 <span class="ot">&lt;-</span> <span class="fu">hw</span>(credit.balance)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>p0 <span class="ot">&lt;-</span> forecast<span class="sc">::</span><span class="fu">autoplot</span>(<span class="fu">window</span>(credit.balance, <span class="at">start=</span><span class="dv">2012</span>)) <span class="sc">+</span> </span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="dv">2012</span>, <span class="dv">2025</span>) <span class="sc">+</span> <span class="fu">ylim</span>(<span class="dv">4500</span>,<span class="dv">7000</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">""</span>)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> p0 <span class="sc">+</span> <span class="fu">autolayer</span>(holt1, <span class="at">series =</span> <span class="st">"Double exponential"</span>)</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> p0 <span class="sc">+</span> <span class="fu">autolayer</span>(holt2, <span class="at">series =</span> <span class="st">"Triple exponential"</span>)</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>p1<span class="sc">/</span>p2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-dewmaf" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-dewmaf-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;16: Double and triple exponential forecasts for credit balance data</figcaption>
</figure>
</div>
</div>
</div>
<p>The forecast accuracy measures can also be obtained using the accuracy() function in the forecast package. This function also give a few other accuracy measures. For the credit card balances data, we obtain-</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">bind_cols</span>(</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">Method =</span> <span class="fu">c</span>(</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Double exponential smoothing"</span>,</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Triple exponential smoothing"</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">accuracy</span>(holt1)[,<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">5</span>)],</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">accuracy</span>(holt2)[,<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">5</span>)]</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 4
  Method                        RMSE   MAE  MAPE
  &lt;chr&gt;                        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1 Double exponential smoothing  88.5  51.3 0.993
2 Triple exponential smoothing  72.5  33.5 0.680</code></pre>
</div>
</div>
<p>Evidently the triple exponential smoothing fares well for our credit card balances data.</p>
</section>
<section id="intro-to-autoregressive-modelling" class="level2">
<h2 class="anchored" data-anchor-id="intro-to-autoregressive-modelling">Intro to Autoregressive Modelling</h2>
<p>The concept of <strong>stationarity</strong> plays in important role for building time series models. In crude terms, a time series is said to be <strong>stationary</strong> if the mean and variance do not change over time (alternatively the same probability law applies over time). In fact stationarity is defined in a pure mathematical way but we will not worry about this in this course.</p>
<p>A white noise series is defined as a series with a constant mean and variance, and the true mean and variance remain the same for all <span class="math inline">\(t\)</span>. Normal random data is an example of white noise but the normal assumption is not required for a series to be white noise. You can also intuitively guess that a white noise series is stationary.</p>
<p>A quick collection of EDA displays can be obtained using a single function ggtsdisplay() or tsdisplay() in <code>R</code>. This display is shown for the white noise series in <a href="#fig-tsdispwn">Figure&nbsp;17</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>wht.noise <span class="ot">&lt;-</span> <span class="fu">arima.sim</span>(<span class="fu">list</span>(<span class="at">order=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>)),<span class="dv">500</span>)</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggtsdisplay</span>(wht.noise)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-tsdispwn" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-tsdispwn-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;17: A summary plots for white noise</figcaption>
</figure>
</div>
</div>
</div>
<p>Time series modelling is not needed for a series such as this one. The above random series must be distinguished from a series whose autocorrelations are not decaying to zero or becoming significant frequently.</p>
<p>A drifting random walk series is defined as <span class="math display">\[X_t = \delta + X_{t-1} + W_t \]</span></p>
<p>where <span class="math inline">\(\delta\)</span> is the constant drift, and <span class="math inline">\(W_t\)</span> is white noise which induces the random walk for the series. The mean function depends on <span class="math inline">\(t\)</span> for this series and hence not stationary. This is not of concern because we can model the drift and make the residuals stationary. The trick is to model the difference <span class="math inline">\(X_{t} - X_{t-1}\)</span> or just use the first lag <span class="math inline">\(X_{t-1}\)</span> as a predictor in the usual regression.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>rwd <span class="ot">&lt;-</span> <span class="fu">arima.sim</span>(<span class="fu">list</span>(<span class="at">order=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>)),<span class="dv">500</span>)</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggtsdisplay</span>(rwd)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-tsdisprw" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-tsdisprw-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;18: A summary plots for drifting random walk series</figcaption>
</figure>
</div>
</div>
</div>
<p>In <a href="#fig-tsdisprw">Figure&nbsp;18</a>, it should also be noted that the ACFs decay to zero which is a good thing when compared to the case where ACFs are not decaying to zero.</p>
<p><span class="math display">\[X_t=\beta_0+\beta_1(\sin(\frac {2\pi}{12} t)+\beta_1(\cos(\frac {2\pi}{12} t)+\epsilon_t\]</span> The above model introduces a 12-period seasonal pattern using <span class="math inline">\(\sin\)</span> and <span class="math inline">\(\cos\)</span> functions (which are periodic). The time series EDA plots for this function is obtained below:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>t<span class="ot">=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">500</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>Xt<span class="ot">=</span><span class="fu">sin</span>(t<span class="sc">*</span><span class="dv">2</span><span class="sc">*</span>pi<span class="sc">/</span><span class="dv">12</span>)<span class="sc">+</span><span class="fu">cos</span>(t<span class="sc">*</span><span class="dv">2</span><span class="sc">*</span>pi<span class="sc">/</span><span class="dv">12</span>)<span class="sc">+</span><span class="fu">rnorm</span>(<span class="dv">500</span>)</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggtsdisplay</span>(Xt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-tsdisptrig" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-tsdisptrig-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;19: Seasonal series EDA plots</figcaption>
</figure>
</div>
</div>
</div>
<p>Note the periodical patterns in the EDA plots shown in <a href="#fig-tsdisptrig">Figure&nbsp;19</a>. Analysis of a time series using sine and cosine functions is known as <code>frequency domain</code> approach and is popular in meteorology, chemistry and geophysics. Instead of using trigonometric functions, say if indicator variables are used to model seasonality, we stay within the <code>time domain</code>. The autocovariance function in the time domain is analogous to the spectral density function in the frequency domain.</p>
<p>Consider the model <span class="math display">\[X_t=\alpha_1 X_{t-1}+ \alpha_2 X_{t-2}+ \dots + \alpha_p X_{t-p} + \epsilon_t\]</span></p>
<p>This model is called the <em>auto-regressive model</em> of order <span class="math inline">\(p\)</span> and called the <span class="math inline">\(AR(p)\)</span> process. Under this model, we assume that the present value depends linearly on the immediate past values as well as a random error. Note that this model is very similar to the multiple regression model where the predictors are just the past values of the series. This <span class="math inline">\(AR(p)\)</span> series is stationary if the variance of the terms are finite. When <span class="math inline">\(p = 1\)</span> (the first-order process), the model is known as a Markov process. The EDA plots for random data from this process is shown in <a href="#fig-tsdispmk">Figure&nbsp;20</a>. <a href="#fig-tsdispp">Figure&nbsp;21</a> shows the <span class="math inline">\(AR(3)\)</span> process EDA plots. Note that the PACF shows a pattern matching the parameters set <code>ar= c(0.8, -0.7, .3)</code>. The last PACF in an <span class="math inline">\(AR(p)\)</span> model accounts the excess autocorrelation at lag <span class="math inline">\(p\)</span> that is not accounted for by an <span class="math inline">\(AR(p-1)\)</span> model.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>Xt <span class="ot">&lt;-</span> <span class="fu">arima.sim</span>(<span class="fu">list</span>(<span class="at">order=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>), <span class="at">ar=</span>.<span class="dv">6</span>), <span class="at">n=</span><span class="dv">500</span>)</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggtsdisplay</span>(Xt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-tsdispmk" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-tsdispmk-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;20: A typical Markov series EDA plots</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>Xt <span class="ot">&lt;-</span> <span class="fu">arima.sim</span>(<span class="fu">list</span>(<span class="at">order=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">0</span>,<span class="dv">0</span>), <span class="at">ar=</span> <span class="fu">c</span>(<span class="fl">0.8</span>, <span class="sc">-</span><span class="fl">0.7</span>, .<span class="dv">3</span>)), <span class="at">n=</span><span class="dv">500</span>)</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggtsdisplay</span>(Xt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-tsdispp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-tsdispp-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;21: A typical AR(p=3) series EDA plots</figcaption>
</figure>
</div>
</div>
</div>
<p>The <em>moving average process</em> for <code>errors</code> is defined by the following equation. <span class="math display">\[X_t=\beta_0 z_{t}+ \beta_1 z_{t-1}+ \dots + \beta_q z_{t-q}\]</span> Note that <span class="math inline">\(X_t\)</span> is modelled with errors <span class="math inline">\(z_1\)</span>, <span class="math inline">\(z_2\)</span>,…, whose means are assumed to be zero and constant variance. The <span class="math inline">\(\beta\)</span>s are coefficients of the model and <span class="math inline">\(q\)</span> is the order. The mean of this <span class="math inline">\(MA(q)\)</span> process is zero but we can always add some mean <span class="math inline">\(\mu\)</span> which will not affect the properties such as ACFs. The basic idea behind the <span class="math inline">\(MA(q)\)</span> process is that the current value of the response is due to variety of current and past unpredictable random events. It is proved that the moving average process is a stationary process and that the ACFs at lags greater than <span class="math inline">\(q\)</span> are zero. <a href="#fig-tsdispma1">Figure&nbsp;22</a> and <a href="#fig-tsdispma3">Figure&nbsp;23</a> show the basic EDA plots for the <span class="math inline">\(MA(1)\)</span> and <span class="math inline">\(MA(3)\)</span> processes.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>Xt <span class="ot">&lt;-</span> <span class="fu">arima.sim</span>(<span class="fu">list</span>(<span class="at">order=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>), <span class="at">ma=</span>.<span class="dv">6</span>), <span class="at">n=</span><span class="dv">500</span>)</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggtsdisplay</span>(Xt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-tsdispma1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-tsdispma1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;22: EDA plots of a typical MA(1) process</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>Xt <span class="ot">&lt;-</span> <span class="fu">arima.sim</span>(<span class="fu">list</span>(<span class="at">order=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">3</span>), <span class="at">ma=</span><span class="fu">c</span>(.<span class="dv">3</span>, .<span class="dv">1</span>, <span class="sc">-</span>.<span class="dv">4</span>)), <span class="at">n=</span><span class="dv">500</span>)</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggtsdisplay</span>(Xt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-tsdispma3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-tsdispma3-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;23: EDA plots of a typical MA(3) process</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>ARMA Model</strong></p>
<p>The term <span class="math inline">\(ARMA(p, q)\)</span> model refers to the following equation that combines both the <span class="math inline">\(AR(p)\)</span> and <span class="math inline">\(MA(q)\)</span> models.</p>
<p><span class="math display">\[X_t=\alpha_1 X_{t-1}+ \alpha_2 X_{t-2}+ \dots + \alpha_p X_{t-p} + \beta_o z_{t}+ \beta_1 z_{t-1}+ \dots + \beta_q z_{t-q}\]</span> It is easy to see that the term <span class="math inline">\(\epsilon_t\)</span> in the <span class="math inline">\(AR(p)\)</span> model is replaced or expanded with the <span class="math inline">\(MA(q)\)</span> model. You may wonder why to have such a complicated model. In fact the ARMA model requires fewer parameters than using just <span class="math inline">\(MA(q)\)</span> or <span class="math inline">\(AR(p)\)</span> model. <span class="math inline">\(ARMA(p, q)\)</span> model is a stationary model. <a href="#fig-tsdisparima">Figure&nbsp;24</a> shows the EDA plots for the simulated series from the <span class="math inline">\(ARMA(2,2)\)</span> process; note the constants fixed under the <code>ar</code> and <code>ma</code> parts of the <code>arima.sim</code> function and compare the ACF and PACF plots.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>Xt <span class="ot">&lt;-</span> <span class="fu">arima.sim</span>(<span class="fu">list</span>(<span class="at">order=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">2</span>), <span class="at">ar=</span><span class="fu">c</span>(.<span class="dv">5</span>, <span class="sc">-</span>.<span class="dv">3</span>), <span class="at">ma=</span><span class="fu">c</span>(.<span class="dv">3</span>, .<span class="dv">1</span>)), <span class="at">n=</span><span class="dv">500</span>)</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggtsdisplay</span>(Xt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-tsdisparima" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-tsdisparima-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;24: EDA plots of a typical MA(3) process</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>Fitting ARMA model</strong> Fitting an AR model can be done approximately using the multiple regression approach. If we use the sample mean <span class="math inline">\(\bar{X}\)</span> to estimate the mean <span class="math inline">\(\mu\)</span> of the process, the AR model becomes the multiple regression model with lags as predictors. However we cannot take the same approach to fitting ARMA models and we need to employ nonlinear optimisation methods.</p>
<p>After fitting the ARMA model, we perform diagnostics of the fitted model. Here we explore the residuals of the fitted model for randomness and periodicity. In order to avoid <em>over fitting</em>, we will also examine the standard errors of the fitted coefficients. The need for transformations such the logarithm or the square root will also be indicated by the residuals.</p>
<p>If the residuals are found to be nonstationary (often the case), we opt for differencing of the series. We have briefly seen that differencing can bring stationarity to a drifting process. Formally, the first difference <span class="math inline">\(X_t-X_{t-1}\)</span> is denoted as <span class="math inline">\(\bigtriangledown X_t\)</span>. If we perform the differencing of the differences, we obtain <span class="math inline">\(\bigtriangledown^2 X_t\)</span> and so on. In order to bring stationarity to residuals, we may do differencing <span class="math inline">\(d\)</span> times. We then fit the model to <span class="math inline">\(\bigtriangledown^2 X_t\)</span> instead of <span class="math inline">\(X_t\)</span>. This model is known as an autoregressive integrated moving average (ARIMA) model and denoted as <span class="math inline">\(ARIMA(p, d, q)\)</span>. The term “integrated” means that the stationary model that was fitted based on the differenced data has to be summed (or “integrated”) to provide a model for the original data.</p>
<p>The ARIMA model is further generalised to seasonal ARIMA (SARIMA) model. The AR part for seasons (parameter P), differencing part (D) and the MA part (Q) form part of the <span class="math inline">\(SARIMA(p,d,q ,P, D, Q)\)</span>. This topic is covered in higher level courses.</p>
<p>Building good ARIMA models of <span class="citation" data-cites="boxgenkins">Box and Jenkins (<a href="#ref-boxgenkins" role="doc-biblioref">1976</a>)</span> generally requires a reasonable amount of experience compared to building models to cross-section data. <strong>In this course you are expected not to build ARIMA models</strong> (no exam questions). But it should not be too hard to recognise the situations such as seasonality in the data series using EDA tools.</p>
<p>The <code>R</code> package <em>forecast</em> has a convenient function called <code>auto.arima</code> which can quickly fit an ARIMA model. This is just an initial model which must be improved further. For the credit balance data, we obtain the following output:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">auto.arima</span>(credit.balance)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Series: credit.balance 
ARIMA(0,2,4)(0,0,2)[12] 

Coefficients:
          ma1      ma2     ma3     ma4    sma1    sma2
      -0.6271  -0.5941  0.0977  0.1389  0.2602  0.1775
s.e.   0.0608   0.0729  0.0683  0.0636  0.0623  0.0570

sigma^2 = 5817:  log likelihood = -1581.39
AIC=3176.78   AICc=3177.2   BIC=3202.1</code></pre>
</div>
</div>
<p>This package can also generate forecasts easily, see <a href="#fig-creditfcast">Figure&nbsp;25</a>. This plot also shows the confidence bands for the forecasts.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">auto.arima</span>(credit.balance)</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>forecast<span class="sc">::</span><span class="fu">autoplot</span>(<span class="fu">forecast</span>(fit,<span class="at">h=</span><span class="dv">24</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-creditfcast" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-creditfcast-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;25: Forecasts for credit balance series</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<p>Regression methods are the most commonly used of statistics techniques. The main aim is to fit a model by least squares to explain the variation in the response variable <span class="math inline">\(Y\)</span> by using one or more explanatory variables <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, … , <span class="math inline">\(X_k\)</span>. The correlation coefficient <span class="math inline">\(r_{xy}\)</span> measures the strength of the linear relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>; <span class="math inline">\(R^{2}\)</span> measures the strength of the linear relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, … , <span class="math inline">\(X_k\)</span>. When <span class="math inline">\(k\)</span>=1, then <span class="math inline">\(r_{xy}^{2} =R^{2}\)</span>. Scatter plots and correlation coefficients provide important clues to the inter-relationships between the variables.</p>
<p>In building up a model by adding new variables, the correlation (or overlap) with <span class="math inline">\(y\)</span> is important but the correlations between a new explanatory variable and each of the existing explanatory variables also determine how effective the addition of the variable will be.</p>
<p>Stepwise regression procedures identify potentially good regression models by repeatedly comparing an existing model with other models in which an explanatory variable has been either deleted or added, using some criterion such as significance of the deleted or added term (as measured by the <span class="math inline">\(p\)</span>-value of the relevant <span class="math inline">\(t\)</span> or <span class="math inline">\(F\)</span> statistic) or the AIC of the model. Polynomial regression models employ the square, cube etc terms of the original variables as additional predictors.</p>
<p>When at least two explanatory variables are highly correlated, we have multicollinear data. The effect is that the variance of least square estimators will be inflated rendering the coefficients insignificant and hence we may need to discard one or more of the highly correlated variables.</p>
<p>EDA plots of residuals help to answer the question as to whether the fit is good or whether a transformation may help or whether other variables (including square, cubic etc) should be added. If residuals are plotted against fitted <span class="math inline">\(Y\)</span> or <span class="math inline">\(X\)</span> variables no discernible pattern should be observed. Estimated regression coefficients may be affected by leverage points, and hence influence diagnostics are performed.</p>


<!-- -->


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-boxgenkins" class="csl-entry" role="listitem">
Box, G. E. P., and G. M. Jenkins. 1976. <em>Time Series Analysis: Forecasting and Control</em>. Holden-Day, San Francisco.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../studyguide/6-single.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Chapter 6: Models with a Single Continuous Predictor</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../studyguide/8-anova.html" class="pagination-link">
        <span class="nav-page-text">Chapter 8: Analysis of Variance (ANOVA) and Covariance (ANCOVA)</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb69" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Chapter 7: Models with Multiple Continuous Predictors"</span></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>In this chapter, we consider **multiple regression** and other models in which there are more than one predictor (or $X$) variable. Once again our focus is on finding the estimates of coefficients or parameters in multiple linear regression models by the method of **least squares**. For this we assume that</span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>The predictor (or explanatory or controlled or covariate) variables $X_i$ $(i=1,2,...,p)$ are known without error.</span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>The mean or expected value of the dependent (or response) variable $Y$ is related to the $X_i$ $(i=1,2,...,p)$ according to a linear expression</span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a>    $E(y\mid x)=a+ b_1 x_l + b_2 x_2 + ....+ b_p x_p$</span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a>    i.e. a straight line (for one $X$ variable), a plane (for two $X$ variables) or a hyperplane (for more than two $X$ variables). This means that the fitted model can be written as</span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-16"><a href="#cb69-16" aria-hidden="true" tabindex="-1"></a>    *fit* = $a+ b_1 x_l + b_2 x_2 + ....+ b_p x_p$.</span>
<span id="cb69-17"><a href="#cb69-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-18"><a href="#cb69-18" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>There is random (unpredictable, unexplained) variability of $Y$ about the fitted model. That is,</span>
<span id="cb69-19"><a href="#cb69-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-20"><a href="#cb69-20" aria-hidden="true" tabindex="-1"></a>    $y$ = fit + residual.</span>
<span id="cb69-21"><a href="#cb69-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-22"><a href="#cb69-22" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>In order to apply statistical inferences to a model, a number of assumptions need to be made. To be able to form $t$ and $F$ statistics, we assume that</span>
<span id="cb69-23"><a href="#cb69-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-24"><a href="#cb69-24" aria-hidden="true" tabindex="-1"></a><span class="ss">5.  </span>The variability in $Y$ about the line (plane etc) is constant and independent of the $X$ variables.</span>
<span id="cb69-25"><a href="#cb69-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-26"><a href="#cb69-26" aria-hidden="true" tabindex="-1"></a><span class="ss">6.  </span>The variability of $Y$ follows a Normal distribution. That is, the distribution of $Y$ (given certain values of the $X_i$ variables) is Normal.</span>
<span id="cb69-27"><a href="#cb69-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-28"><a href="#cb69-28" aria-hidden="true" tabindex="-1"></a><span class="ss">7.  </span>Given (different) outcomes of the $X$ variables, the corresponding $Y$ variables are independent of one another.</span>
<span id="cb69-29"><a href="#cb69-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-30"><a href="#cb69-30" aria-hidden="true" tabindex="-1"></a>We will continue to use the data set **horsehearts** of the weights of horses' hearts and other related measurements.</span>
<span id="cb69-31"><a href="#cb69-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-32"><a href="#cb69-32" aria-hidden="true" tabindex="-1"></a><span class="fu"># Full Regression</span></span>
<span id="cb69-33"><a href="#cb69-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-34"><a href="#cb69-34" aria-hidden="true" tabindex="-1"></a>With one explanatory variable scatterplots and correlation coefficients provided good starting points for exploring relationships between the explanatory and response variables. This is even more relevant with two or more explanatory variables. For the horses' hearts data, there are six potential explanatory variables; namely <span class="in">`EXTDIA`</span>, <span class="in">`EXTSYS`</span>, <span class="in">`INNERDIA`</span>, <span class="in">`INNERSYS`</span>, <span class="in">`OUTERDIA`</span> and <span class="in">`OUTERSYS`</span>. These measurements of heart width are made of the exterior width, inner wall and outer wall at two different phases, the diastole phase and the systole phase. So a matrix of scatter plots (or matrix plot) of these variables will be useful for exploratory analysis.</span>
<span id="cb69-35"><a href="#cb69-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-36"><a href="#cb69-36" aria-hidden="true" tabindex="-1"></a>It is also a good idea to form the simple correlation coefficients between each pair of explanatory variables and between each explanatory variable and the response variable $Y$, the weight of the horse's heart. These correlation coefficients can be displayed in a **correlation matrix** as shown in @fig-multggally.</span>
<span id="cb69-37"><a href="#cb69-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-40"><a href="#cb69-40" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-41"><a href="#cb69-41" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb69-42"><a href="#cb69-42" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb69-43"><a href="#cb69-43" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb69-44"><a href="#cb69-44" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb69-45"><a href="#cb69-45" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_minimal</span>())</span>
<span id="cb69-46"><a href="#cb69-46" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-47"><a href="#cb69-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-50"><a href="#cb69-50" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-51"><a href="#cb69-51" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(</span>
<span id="cb69-52"><a href="#cb69-52" aria-hidden="true" tabindex="-1"></a>  <span class="at">url =</span> <span class="st">"http://www.massey.ac.nz/~anhsmith/data/horsehearts.RData"</span>,</span>
<span id="cb69-53"><a href="#cb69-53" aria-hidden="true" tabindex="-1"></a>  <span class="at">destfile =</span> <span class="st">"horsehearts.RData"</span>)</span>
<span id="cb69-54"><a href="#cb69-54" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"horsehearts.RData"</span>)</span>
<span id="cb69-55"><a href="#cb69-55" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-56"><a href="#cb69-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-59"><a href="#cb69-59" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-60"><a href="#cb69-60" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-61"><a href="#cb69-61" aria-hidden="true" tabindex="-1"></a><span class="co">#| mesasge: false</span></span>
<span id="cb69-62"><a href="#cb69-62" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-multggally</span></span>
<span id="cb69-63"><a href="#cb69-63" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Scatter plot and correlation matrix'</span></span>
<span id="cb69-64"><a href="#cb69-64" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 7</span></span>
<span id="cb69-65"><a href="#cb69-65" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb69-66"><a href="#cb69-66" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span>
<span id="cb69-67"><a href="#cb69-67" aria-hidden="true" tabindex="-1"></a><span class="fu">ggpairs</span>(horsehearts)</span>
<span id="cb69-68"><a href="#cb69-68" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-69"><a href="#cb69-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-70"><a href="#cb69-70" aria-hidden="true" tabindex="-1"></a>It is also possible to obtain the $p$-values for all the simple correlation coefficients displayed above and test whether these are significantly different from zero.</span>
<span id="cb69-71"><a href="#cb69-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-72"><a href="#cb69-72" aria-hidden="true" tabindex="-1"></a>A number of facts about the data emerge from our EDA. All of the correlation coefficients are positive and reasonably large which indicates that with large hearts all the lengths increase in a fairly uniform manner. The predictor variables are also highly inter-correlated. **This suggests that not all of these variables are needed but only a subset of them**.</span>
<span id="cb69-73"><a href="#cb69-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-74"><a href="#cb69-74" aria-hidden="true" tabindex="-1"></a>The usual <span class="in">`tidy()`</span> function output of multiple regression weight on all of the available (six) predictors is shown in @tbl-fullregtidy.</span>
<span id="cb69-75"><a href="#cb69-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-76"><a href="#cb69-76" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE, results='hide'}</span></span>
<span id="cb69-77"><a href="#cb69-77" aria-hidden="true" tabindex="-1"></a>full.reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb69-78"><a href="#cb69-78" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(full.reg) <span class="co"># or summary(full.reg) </span></span>
<span id="cb69-79"><a href="#cb69-79" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-80"><a href="#cb69-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-81"><a href="#cb69-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-84"><a href="#cb69-84" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-85"><a href="#cb69-85" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb69-86"><a href="#cb69-86" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-fullregtidy</span></span>
<span id="cb69-87"><a href="#cb69-87" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: 'Full Regression tidy() output'</span></span>
<span id="cb69-88"><a href="#cb69-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-89"><a href="#cb69-89" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(knitr<span class="sc">::</span><span class="fu">is_html_output</span>()) {</span>
<span id="cb69-90"><a href="#cb69-90" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-91"><a href="#cb69-91" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>(full.reg) <span class="sc">|&gt;</span> </span>
<span id="cb69-92"><a href="#cb69-92" aria-hidden="true" tabindex="-1"></a>    <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">3</span>,</span>
<span id="cb69-93"><a href="#cb69-93" aria-hidden="true" tabindex="-1"></a>          <span class="at">table.attr =</span> <span class="st">'data-quarto-disable-processing="true"'</span></span>
<span id="cb69-94"><a href="#cb69-94" aria-hidden="true" tabindex="-1"></a>          ) <span class="sc">|&gt;</span>  </span>
<span id="cb69-95"><a href="#cb69-95" aria-hidden="true" tabindex="-1"></a>    <span class="fu">kable_classic</span>(<span class="at">full_width =</span> F) </span>
<span id="cb69-96"><a href="#cb69-96" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-97"><a href="#cb69-97" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb69-98"><a href="#cb69-98" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-99"><a href="#cb69-99" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tidy</span>(full.reg) <span class="sc">|&gt;</span> </span>
<span id="cb69-100"><a href="#cb69-100" aria-hidden="true" tabindex="-1"></a>    <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">3</span>) <span class="sc">|&gt;</span>  </span>
<span id="cb69-101"><a href="#cb69-101" aria-hidden="true" tabindex="-1"></a>    <span class="fu">kable_classic</span>(<span class="at">full_width =</span> F) </span>
<span id="cb69-102"><a href="#cb69-102" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-103"><a href="#cb69-103" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb69-104"><a href="#cb69-104" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-105"><a href="#cb69-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-106"><a href="#cb69-106" aria-hidden="true" tabindex="-1"></a>This regression model is known as the **full regression** because we have included all the predictors in our model. The <span class="in">`R`</span> syntax <span class="in">`~.`</span> means that we are placing all variables in the dataframe except the one selected as the response variable. We note that the slope coefficients of the predictors <span class="in">`INNERDIA`</span>, <span class="in">`INNERSYS`</span>, and <span class="in">`OUTERDIA`</span> are not significant at 5% level. This confirms that we do not need to place all six predictors in the model but only a subset of them.</span>
<span id="cb69-107"><a href="#cb69-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-108"><a href="#cb69-108" aria-hidden="true" tabindex="-1"></a>The highly correlated predictor <span class="in">`INNERDIA`</span> (see @fig-multggally) is also found to have a insignificant coefficient in @tbl-fullregtidy. This is somewhat surprising and casts doubts on the suitability of the full regression fit. If two or more explanatory variables are very highly correlated (i.e. almost collinear), then we deal with **multicollinearity**. The estimated standard errors of the regression coefficients will be inflated in the presence of multicollinearity. As result, the $t$-value will become small leading to a model with many insignificant coefficients. Multicollinearity does not affect the residual standard error much. The obvious remedy for multicollinearity is that one or more of the highly correlated variables can be dropped. Measures such as the Variance Inflation factor (**VIF**) are available to study the effect of multicollinearity. A VIF factor of more than 5 for a coefficient means that its variance is artificially inflated by the high correlation among the predictors. For the full regression model, the VIF factors are obtained using the <span class="in">`car`</span> package function <span class="in">`vif()`</span> and shown as @tbl-fullregvif.</span>
<span id="cb69-109"><a href="#cb69-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-110"><a href="#cb69-110" aria-hidden="true" tabindex="-1"></a><span class="in">```{r , echo=TRUE, results='hide'}</span></span>
<span id="cb69-111"><a href="#cb69-111" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">vif</span>(full.reg)</span>
<span id="cb69-112"><a href="#cb69-112" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-113"><a href="#cb69-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-116"><a href="#cb69-116" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-117"><a href="#cb69-117" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb69-118"><a href="#cb69-118" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-fullregvif</span></span>
<span id="cb69-119"><a href="#cb69-119" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: 'Variance Inflation Factors'</span></span>
<span id="cb69-120"><a href="#cb69-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-121"><a href="#cb69-121" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(knitr<span class="sc">::</span><span class="fu">is_html_output</span>()) {</span>
<span id="cb69-122"><a href="#cb69-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-123"><a href="#cb69-123" aria-hidden="true" tabindex="-1"></a>    car<span class="sc">::</span><span class="fu">vif</span>(full.reg) <span class="sc">|&gt;</span> </span>
<span id="cb69-124"><a href="#cb69-124" aria-hidden="true" tabindex="-1"></a>    <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>,</span>
<span id="cb69-125"><a href="#cb69-125" aria-hidden="true" tabindex="-1"></a>          <span class="at">table.attr =</span> <span class="st">'data-quarto-disable-processing="true"'</span></span>
<span id="cb69-126"><a href="#cb69-126" aria-hidden="true" tabindex="-1"></a>          ) <span class="sc">|&gt;</span> </span>
<span id="cb69-127"><a href="#cb69-127" aria-hidden="true" tabindex="-1"></a>    <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-128"><a href="#cb69-128" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb69-129"><a href="#cb69-129" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb69-130"><a href="#cb69-130" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-131"><a href="#cb69-131" aria-hidden="true" tabindex="-1"></a>    car<span class="sc">::</span><span class="fu">vif</span>(full.reg) <span class="sc">|&gt;</span> </span>
<span id="cb69-132"><a href="#cb69-132" aria-hidden="true" tabindex="-1"></a>    <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-133"><a href="#cb69-133" aria-hidden="true" tabindex="-1"></a>    <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-134"><a href="#cb69-134" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-135"><a href="#cb69-135" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb69-136"><a href="#cb69-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-137"><a href="#cb69-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-138"><a href="#cb69-138" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-139"><a href="#cb69-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-140"><a href="#cb69-140" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-141"><a href="#cb69-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-142"><a href="#cb69-142" aria-hidden="true" tabindex="-1"></a>All the VIF values are over 5, and hence the full regression model must be simplified dropping one or more predictors.</span>
<span id="cb69-143"><a href="#cb69-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-144"><a href="#cb69-144" aria-hidden="true" tabindex="-1"></a>Let us now compare the fit and summary measures of the simple regression <span class="in">`lm(WEIGHT ~ INNERDIA, data=horsehearts)`</span> with the full regression <span class="in">`lm(WEIGHT ~ ., data=horsehearts)`</span>. @fig-modcomp compares the actual and fitted $Y$ values for these two models.</span>
<span id="cb69-145"><a href="#cb69-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-148"><a href="#cb69-148" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-149"><a href="#cb69-149" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-150"><a href="#cb69-150" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb69-151"><a href="#cb69-151" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-modcomp</span></span>
<span id="cb69-152"><a href="#cb69-152" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Comparison of Multiple Regression and Simple Regression'</span></span>
<span id="cb69-153"><a href="#cb69-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-154"><a href="#cb69-154" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(modelr)</span>
<span id="cb69-155"><a href="#cb69-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-156"><a href="#cb69-156" aria-hidden="true" tabindex="-1"></a>full.reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb69-157"><a href="#cb69-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-158"><a href="#cb69-158" aria-hidden="true" tabindex="-1"></a>simple.reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> INNERDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb69-159"><a href="#cb69-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-160"><a href="#cb69-160" aria-hidden="true" tabindex="-1"></a>hhpred <span class="ot">&lt;-</span> horsehearts <span class="sc">|&gt;</span> </span>
<span id="cb69-161"><a href="#cb69-161" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather_predictions</span>(full.reg, simple.reg) <span class="sc">|&gt;</span> </span>
<span id="cb69-162"><a href="#cb69-162" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">residuals=</span>WEIGHT<span class="sc">-</span>pred)</span>
<span id="cb69-163"><a href="#cb69-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-164"><a href="#cb69-164" aria-hidden="true" tabindex="-1"></a>hhpred <span class="sc">|&gt;</span> </span>
<span id="cb69-165"><a href="#cb69-165" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb69-166"><a href="#cb69-166" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x=</span>WEIGHT, <span class="at">y=</span>pred, <span class="at">colour=</span>model) <span class="sc">+</span> </span>
<span id="cb69-167"><a href="#cb69-167" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb69-168"><a href="#cb69-168" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">alpha=</span>.<span class="dv">5</span>) <span class="sc">+</span> </span>
<span id="cb69-169"><a href="#cb69-169" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">aspect.ratio =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb69-170"><a href="#cb69-170" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Predicted WEIGHT"</span>) <span class="sc">+</span> </span>
<span id="cb69-171"><a href="#cb69-171" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Comparison of model predictions"</span>) </span>
<span id="cb69-172"><a href="#cb69-172" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-173"><a href="#cb69-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-174"><a href="#cb69-174" aria-hidden="true" tabindex="-1"></a>Both the simple and full regression models give similar predictions when the horses heart weight is below 2.5 kg, but the simple regression residuals are bit bigger for larger hearts.</span>
<span id="cb69-175"><a href="#cb69-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-176"><a href="#cb69-176" aria-hidden="true" tabindex="-1"></a>We are rather hesitant to make unique claims about any particular subset of predictors based on the correlation matrix or based on the significance of the coefficients from the multiple regression output. In forthcoming sections, methods to decide on a subset of these variables will be explained, but first we look at the issues involved when predictor variables are correlated to each other.</span>
<span id="cb69-177"><a href="#cb69-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-178"><a href="#cb69-178" aria-hidden="true" tabindex="-1"></a><span class="fu"># Measuring Variation Explained by Predictors</span></span>
<span id="cb69-179"><a href="#cb69-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-180"><a href="#cb69-180" aria-hidden="true" tabindex="-1"></a>The variation in a variable can be measured by its sum of squares. In this section, we illustrate this variation by the area of a circle. For brevity, we denote the **T**otal **S**um of **S**quares, the **R**egression **S**um of **S**quares and the **E**rror or residual **S**um of **S**quares by **SST**, **SSR** and **SSE** respectively. In @fig-f5-3, the circle is labelled $y$ and represents the Sum of Squares for all the $y$ observations, that is, SST.</span>
<span id="cb69-181"><a href="#cb69-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-182"><a href="#cb69-182" aria-hidden="true" tabindex="-1"></a><span class="al">![Effect of predictor correlation with the response](images/5-3.png)</span>{#fig-f5-3}</span>
<span id="cb69-183"><a href="#cb69-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-184"><a href="#cb69-184" aria-hidden="true" tabindex="-1"></a>For the full regression of horse heart weight, we obtain the ANOVA output using the command</span>
<span id="cb69-185"><a href="#cb69-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-186"><a href="#cb69-186" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=T, results=FALSE}</span></span>
<span id="cb69-187"><a href="#cb69-187" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(full.reg)</span>
<span id="cb69-188"><a href="#cb69-188" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-189"><a href="#cb69-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-190"><a href="#cb69-190" aria-hidden="true" tabindex="-1"></a>Let's take a look at the sums of squares table.</span>
<span id="cb69-191"><a href="#cb69-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-192"><a href="#cb69-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-195"><a href="#cb69-195" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-196"><a href="#cb69-196" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-197"><a href="#cb69-197" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb69-198"><a href="#cb69-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-199"><a href="#cb69-199" aria-hidden="true" tabindex="-1"></a>SS <span class="ot">&lt;-</span> <span class="fu">anova</span>(full.reg) <span class="sc">|&gt;</span> </span>
<span id="cb69-200"><a href="#cb69-200" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-201"><a href="#cb69-201" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term<span class="sc">:</span>sumsq) <span class="sc">|&gt;</span> </span>
<span id="cb69-202"><a href="#cb69-202" aria-hidden="true" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">adorn_totals</span>()</span>
<span id="cb69-203"><a href="#cb69-203" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-204"><a href="#cb69-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-207"><a href="#cb69-207" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-208"><a href="#cb69-208" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb69-209"><a href="#cb69-209" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-SS</span></span>
<span id="cb69-210"><a href="#cb69-210" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Sums of squares for the full regression of horsehearts data"</span></span>
<span id="cb69-211"><a href="#cb69-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-212"><a href="#cb69-212" aria-hidden="true" tabindex="-1"></a>SS <span class="ot">&lt;-</span> <span class="fu">anova</span>(full.reg) <span class="sc">|&gt;</span> </span>
<span id="cb69-213"><a href="#cb69-213" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-214"><a href="#cb69-214" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term<span class="sc">:</span>sumsq) <span class="sc">|&gt;</span> </span>
<span id="cb69-215"><a href="#cb69-215" aria-hidden="true" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">adorn_totals</span>()</span>
<span id="cb69-216"><a href="#cb69-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-217"><a href="#cb69-217" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(knitr<span class="sc">::</span><span class="fu">is_html_output</span>()) {</span>
<span id="cb69-218"><a href="#cb69-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-219"><a href="#cb69-219" aria-hidden="true" tabindex="-1"></a>  SS <span class="sc">|&gt;</span> <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>,</span>
<span id="cb69-220"><a href="#cb69-220" aria-hidden="true" tabindex="-1"></a>        <span class="at">table.attr =</span> <span class="st">'data-quarto-disable-processing="true"'</span></span>
<span id="cb69-221"><a href="#cb69-221" aria-hidden="true" tabindex="-1"></a>        ) <span class="sc">|&gt;</span>  </span>
<span id="cb69-222"><a href="#cb69-222" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width =</span> F) </span>
<span id="cb69-223"><a href="#cb69-223" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb69-224"><a href="#cb69-224" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb69-225"><a href="#cb69-225" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-226"><a href="#cb69-226" aria-hidden="true" tabindex="-1"></a>  SS <span class="sc">|&gt;</span> <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span> ) <span class="sc">|&gt;</span>  </span>
<span id="cb69-227"><a href="#cb69-227" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width =</span> F) </span>
<span id="cb69-228"><a href="#cb69-228" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-229"><a href="#cb69-229" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb69-230"><a href="#cb69-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-231"><a href="#cb69-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-232"><a href="#cb69-232" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-233"><a href="#cb69-233" aria-hidden="true" tabindex="-1"></a>Now let's calculate the Sums of Squares Total (SST), Error (SSE), and Regression (SSR). </span>
<span id="cb69-234"><a href="#cb69-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-235"><a href="#cb69-235" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE}</span></span>
<span id="cb69-236"><a href="#cb69-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-237"><a href="#cb69-237" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb69-238"><a href="#cb69-238" aria-hidden="true" tabindex="-1"></a>  <span class="at">SST =</span> SS <span class="sc">|&gt;</span> <span class="fu">filter</span>(term<span class="sc">==</span><span class="st">"Total"</span>) <span class="sc">|&gt;</span> <span class="fu">pull</span>(sumsq),</span>
<span id="cb69-239"><a href="#cb69-239" aria-hidden="true" tabindex="-1"></a>  <span class="at">SSE =</span> SS <span class="sc">|&gt;</span> <span class="fu">filter</span>(term<span class="sc">==</span><span class="st">"Residuals"</span>) <span class="sc">|&gt;</span> <span class="fu">pull</span>(sumsq),</span>
<span id="cb69-240"><a href="#cb69-240" aria-hidden="true" tabindex="-1"></a>  <span class="at">SSR =</span> SST <span class="sc">-</span> SSE</span>
<span id="cb69-241"><a href="#cb69-241" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb69-242"><a href="#cb69-242" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-243"><a href="#cb69-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-244"><a href="#cb69-244" aria-hidden="true" tabindex="-1"></a>In @fig-f5-3(a), SST = SSR + SSE = 32.731 + 24.115 = 56.845. Consider now the straight line relationship between $y$ and one response variable $x$. This situation is illustrated in @fig-f5-3(b). The shaded overlap of the two circles illustrates the variation in $y$ about the mean explained by the variable $x$, and this shaded area represents the regression sum of squares SSR. The remaining area of the circle for $y$ represents the unexplained variation in $y$ or the residual sum of squares SSE. Note that the circle or Venn diagrams represent SS only qualitatively (not to scale). The variation in $y$ is thus separated into two parts, namely **SST = SSR + SSE**.</span>
<span id="cb69-245"><a href="#cb69-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-246"><a href="#cb69-246" aria-hidden="true" tabindex="-1"></a>Notice that we are not very interested in the unshaded area of the circle representing the explanatory variable, $x$; *it is the variation in the response variable,* $y$, which is important. Also notice that the overlapping circles indicate that the two variables are correlated, that is the correlation coefficient, $r_{xy}$, is not zero. The shaded area is related to</span>
<span id="cb69-247"><a href="#cb69-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-248"><a href="#cb69-248" aria-hidden="true" tabindex="-1"></a>$R^2$ = proportion of the variation of $y$ explained by $x$ = SSR/SST = 32.731/56.845 = 0.576 = $r_{xy}^2$.</span>
<span id="cb69-249"><a href="#cb69-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-250"><a href="#cb69-250" aria-hidden="true" tabindex="-1"></a>Note from @fig-multggally that the correlation between <span class="in">`WEIGHT`</span> and <span class="in">`EXTDIA`</span> is 0.759 and 0.759 squared equals 0.576.</span>
<span id="cb69-251"><a href="#cb69-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-252"><a href="#cb69-252" aria-hidden="true" tabindex="-1"></a>The situation becomes more interesting when a second explanatory variable is added to the model as illustrated by @fig-f5-4.</span>
<span id="cb69-253"><a href="#cb69-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-254"><a href="#cb69-254" aria-hidden="true" tabindex="-1"></a><span class="al">![Effect of adding two predictors](images/5-4.png)</span>{#fig-f5-4}</span>
<span id="cb69-255"><a href="#cb69-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-256"><a href="#cb69-256" aria-hidden="true" tabindex="-1"></a>In the following discussion, the variable <span class="in">`EXTDIA`</span> is denoted by $x_1$ and <span class="in">`OUTERDIA`</span> as $x_2$. The total overlap of ($x_1$ and $x_2$) and $y$ will depend on the relationship of $y$ with $x_1$, $y$ with $x_2$, and the correlation of $x_1$ and $x_2.$</span>
<span id="cb69-257"><a href="#cb69-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-258"><a href="#cb69-258" aria-hidden="true" tabindex="-1"></a>In @fig-f5-4(a), as the circles for $x_1$ and $x_2$ do not overlap, this represents a correlation coefficient between these two variables of zero. In this special case, $$R^{2} =\frac{\text {SSR}(x_1)+\text {SSR} (x_2)}{\text {SST}} =r_{x_{1} y}^{2} +r_{x_{2} y}^{2}.$$</span>
<span id="cb69-259"><a href="#cb69-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-260"><a href="#cb69-260" aria-hidden="true" tabindex="-1"></a>Here, SSR($x_1$) represents the Regression SS when $y$ is regressed on $x_1$ only. SSR($x_2$) represents the Regression SS when $y$ is regressed on $x_2$ only. The unshaded area of $y$ represents SSE, the residual sum of squares, which is the sum of squares of $y$ **unexplained** by $x_1$ or $x_2$. The **special case** of **uncorrelated** explanatory variables is in many ways ideal but it usually only occurs when $x_1$ and $x_2$ are constructed to have zero correlation (which means that the situation, known as orthogonality, is usually confined to experimental designs). There is an added bonus when $x_1$ and $x_2$ have zero correlation. In this situation the fitted model is</span>
<span id="cb69-261"><a href="#cb69-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-262"><a href="#cb69-262" aria-hidden="true" tabindex="-1"></a>$$\hat{y} = a + b_1 x_1 + b_2x_2$$</span>
<span id="cb69-263"><a href="#cb69-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-264"><a href="#cb69-264" aria-hidden="true" tabindex="-1"></a>where $b_1$ and $b_2$ take the same values as in the separate straight line models $\hat{y} = a + b_1x_1$ and $\hat{y} =a + b_2x_2.$</span>
<span id="cb69-265"><a href="#cb69-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-266"><a href="#cb69-266" aria-hidden="true" tabindex="-1"></a>However in observational studies the correlations between predictor variables will usually be nonzero. The circle diagram shown in @fig-f5-4(b) illustrates the case when $x_1$ and $x_2$ are correlated. In this case $$R^{2} &lt;\frac{\text {SSR}(x_1) + \text {SSR}(x_2) } {\text {SST}}$$ and the slope coefficients for both $x_1$ and $x_2$ change when both these variables are included in the regression model.</span>
<span id="cb69-267"><a href="#cb69-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-268"><a href="#cb69-268" aria-hidden="true" tabindex="-1"></a>@fig-f5-4(c) gives the extreme case when $x_1$ and $x_2$ have nearly perfect correlation. If the correlation between $x_1$ and $x_2$ is perfect, then the two variables will be said to be collinear. If two or more explanatory variables are very highly correlated (i.e. almost collinear), then we deal with **multicollinearity**.</span>
<span id="cb69-269"><a href="#cb69-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-270"><a href="#cb69-270" aria-hidden="true" tabindex="-1"></a>From @fig-f5-3 and @fig-f5-4, it is clear that for correlated variables, the variation (SS) explained by a particular predictor cannot be independently extracted (due to the commonly shared variation). Hence, we consider how much a predictor explains **additionally** given that there are already certain predictors are in the model. The additional overlap due to $x_{2}$ with $y$ **after** $x_{1}$, known as the **additional SSR** or **Sequential SS** is an important idea in model building. The additional SSR is known as **Type I sums of squares** in the statistical literature.</span>
<span id="cb69-271"><a href="#cb69-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-272"><a href="#cb69-272" aria-hidden="true" tabindex="-1"></a>Note that we can also define the additional variation in $y$ explained by $x_{1}$ after $x_{2}$. It is important to note that in general the additional SSR depends on the **order** of placing the predictors. **This order does not have any effect on the coefficient estimation, standard errors etc.**</span>
<span id="cb69-273"><a href="#cb69-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-274"><a href="#cb69-274" aria-hidden="true" tabindex="-1"></a><span class="fu">## Significance testing of Type I SS</span></span>
<span id="cb69-275"><a href="#cb69-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-276"><a href="#cb69-276" aria-hidden="true" tabindex="-1"></a>The significance of the additional variation explained by a predictor can be tested using a $t$ or $F$ statistic. Consider the simple regression model of <span class="in">`WEIGHT`</span> on <span class="in">`EXTDIA`</span>. Suppose we decided to add the explanatory variable <span class="in">`OUTERDIA`</span> to the model, i.e. regress <span class="in">`WEIGHT`</span> on two explanatory variables <span class="in">`EXTDIA`</span> and <span class="in">`OUTERDIA`</span>. Is this new model a significant improvement on the existing one? For testing the null hypothesis that the true slope coefficient of <span class="in">`OUTERDIA`</span> in this model is zero, the $t$-statistic is 1.531 (see output below).</span>
<span id="cb69-277"><a href="#cb69-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-280"><a href="#cb69-280" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-281"><a href="#cb69-281" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-282"><a href="#cb69-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-283"><a href="#cb69-283" aria-hidden="true" tabindex="-1"></a>twovar.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> EXTDIA<span class="sc">+</span>OUTERDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb69-284"><a href="#cb69-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-285"><a href="#cb69-285" aria-hidden="true" tabindex="-1"></a>twovar.model <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span>
<span id="cb69-286"><a href="#cb69-286" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-287"><a href="#cb69-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-288"><a href="#cb69-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-289"><a href="#cb69-289" aria-hidden="true" tabindex="-1"></a>The $t$ and $F$ distributions are related by the equation $t^{2} =F$ when the numerator df is just one for the $F$ statistic. Hence 1.532 = 2.34 is the $F$ value for testing the significance of the additional SSR due to <span class="in">`OUTERDIA`</span>. In other words, the addition of <span class="in">`OUTERDIA`</span> to the simple regression model does not result in a significant improvement in the sense that the reduction in residual SS (= 1.247) as measured by the $F$ value of 2.34 is not significant ($p$-value being 0.133).</span>
<span id="cb69-290"><a href="#cb69-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-291"><a href="#cb69-291" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE}</span></span>
<span id="cb69-292"><a href="#cb69-292" aria-hidden="true" tabindex="-1"></a>onevar.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb69-293"><a href="#cb69-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-294"><a href="#cb69-294" aria-hidden="true" tabindex="-1"></a>twovar.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> EXTDIA<span class="sc">+</span>OUTERDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb69-295"><a href="#cb69-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-296"><a href="#cb69-296" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(onevar.model, twovar.model)</span>
<span id="cb69-297"><a href="#cb69-297" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-298"><a href="#cb69-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-299"><a href="#cb69-299" aria-hidden="true" tabindex="-1"></a>Although <span class="in">`OUTERDIA`</span> is correlated with <span class="in">`WEIGHT`</span>, it also has high correlation with <span class="in">`EXTDIA`</span>. In other words, the correlation matrix gives us some indication of how many variables might be needed in a multiple regression model, although by itself it cannot tell us what combination of predictor variables is good or best.</span>
<span id="cb69-300"><a href="#cb69-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-301"><a href="#cb69-301" aria-hidden="true" tabindex="-1"></a><span class="al">![Issues with multiple predictors](images/5-5.png)</span>{#fig-f5-5}</span>
<span id="cb69-302"><a href="#cb69-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-303"><a href="#cb69-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-304"><a href="#cb69-304" aria-hidden="true" tabindex="-1"></a><span class="al">![Effect of multiple predictors on model summaries](images/5-7.png)</span>{#fig-f5-7}</span>
<span id="cb69-305"><a href="#cb69-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-306"><a href="#cb69-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-307"><a href="#cb69-307" aria-hidden="true" tabindex="-1"></a>@fig-f5-5 and @fig-f5-7 summarise the following facts:</span>
<span id="cb69-308"><a href="#cb69-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-309"><a href="#cb69-309" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>When there is only **one** explanatory variable, $R^2$ = SSR/SST equals the square of the correlation coefficient between that variable and the dependent variable. Therefore if only one variable is to be chosen, it should have the highest correlation with the response variable, $Y$.</span>
<span id="cb69-310"><a href="#cb69-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-311"><a href="#cb69-311" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>When variables are added to a model, the regression sum of squares SSR will increase and the residual or error sum of squares SSE will reduce. The opposite is true if variables are dropped from the model. This fact follows from @fig-f5-7.</span>
<span id="cb69-312"><a href="#cb69-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-313"><a href="#cb69-313" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>The other side of the coin to the above remark is that as additional variables are added, the Sums of Squares for residuals, SSE, will decrease towards zero as also shown in @fig-f5-7(c).</span>
<span id="cb69-314"><a href="#cb69-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-315"><a href="#cb69-315" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>The overlap of circles in suggests that these changes in both SSR and SST will lessen as more variables are added, see @fig-f5-5(b).</span>
<span id="cb69-316"><a href="#cb69-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-317"><a href="#cb69-317" aria-hidden="true" tabindex="-1"></a><span class="ss">5.  </span>Following on from the last two notes, as $R^2$ = SSR/SST, $R^2$ will increase monotonically towards 1 as additional variables are added to the model. (monotonically increasing means that it never decreases although it could remain the same). This is indicated by @fig-f5-7(a). If variables are dropped, then $R^2$ will monotonically decrease.</span>
<span id="cb69-318"><a href="#cb69-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-319"><a href="#cb69-319" aria-hidden="true" tabindex="-1"></a><span class="ss">6.  </span>Against the above trends, the graph of residual mean square in @fig-f5-7(b) reduces to a *minimum* but may eventually start to increase if enough variables are added. The residual sum of squares SSE decreases as variables are added to the model (see @fig-f5-5(b)). However, the associated df values also decrease so that the residual standard deviation decreases at first and then starts to increase as shown in @fig-f5-7(b). (Note that the residual standard error $s_{e}$ is the square root of the residual mean square</span>
<span id="cb69-320"><a href="#cb69-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-321"><a href="#cb69-321" aria-hidden="true" tabindex="-1"></a>    $$s_{e}^{2} =\frac{{\text {SSE}}}{{\text {error degrees of freedom}}},$$</span>
<span id="cb69-322"><a href="#cb69-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-323"><a href="#cb69-323" aria-hidden="true" tabindex="-1"></a>    denoted as MSE in @fig-f5-5(b)). After a number of variables have been entered, the additional amount of variation explained by them slows down but the degrees of freedom continues to change by 1 for every variable added, resulting in the eventual increase in residual mean square. Note that the graphs in @fig-f5-5 are idealised ones. For some data sets, the behaviour of residual mean square may not be monotone.</span>
<span id="cb69-324"><a href="#cb69-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-325"><a href="#cb69-325" aria-hidden="true" tabindex="-1"></a><span class="ss">7.  </span>Notice that the above trends will occur even if the variables added are **garbage**. For example, you could generate a column of random data or a column of birthdays of your friends, and this would improve the $R^2$ **but not the adjusted** $R^2$. The adjusted $R^2$ makes adjustment for the degrees of freedom for the SSR and SSE, and hence reliable when compared to the unadjusted or multiple $R^2$. The residual mean square error also partly adjusts for the drop in the degrees of freedom for the SSE and hence becomes an important measure. The addition of unimportant variables will not improve the adjusted $R^2$ and the mean square error $s_{e}^{2}$.</span>
<span id="cb69-326"><a href="#cb69-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-327"><a href="#cb69-327" aria-hidden="true" tabindex="-1"></a><span class="fu">## Other SS types</span></span>
<span id="cb69-328"><a href="#cb69-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-329"><a href="#cb69-329" aria-hidden="true" tabindex="-1"></a>The <span class="in">`R`</span> anova function anova() calculates sequential or Type-I SS values.</span>
<span id="cb69-330"><a href="#cb69-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-331"><a href="#cb69-331" aria-hidden="true" tabindex="-1"></a>Type-II sums of squares is based on the principle of marginality. Type II SS correspond to the <span class="in">`R`</span> convention in which each variable effect is adjusted for all other *appropriate* effects.</span>
<span id="cb69-332"><a href="#cb69-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-333"><a href="#cb69-333" aria-hidden="true" tabindex="-1"></a>Type-III sums of squares is the SS added to the regression SS after ALL other predictors including an intercept term. This SS however creates theoretical issues such as violation of marginality principle and we should avoid using this SS type for hypothesis tests.</span>
<span id="cb69-334"><a href="#cb69-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-335"><a href="#cb69-335" aria-hidden="true" tabindex="-1"></a>The <span class="in">`R`</span> package <span class="in">`car`</span> has the function <span class="in">`Anova()`</span> to compute the Type II and III sums of squares. Try-</span>
<span id="cb69-336"><a href="#cb69-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-337"><a href="#cb69-337" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE, results=FALSE}</span></span>
<span id="cb69-338"><a href="#cb69-338" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb69-339"><a href="#cb69-339" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb69-340"><a href="#cb69-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-341"><a href="#cb69-341" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(full.model)</span>
<span id="cb69-342"><a href="#cb69-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-343"><a href="#cb69-343" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb69-344"><a href="#cb69-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-345"><a href="#cb69-345" aria-hidden="true" tabindex="-1"></a><span class="fu">Anova</span>(full.model, <span class="at">type=</span><span class="dv">2</span>)</span>
<span id="cb69-346"><a href="#cb69-346" aria-hidden="true" tabindex="-1"></a><span class="fu">Anova</span>(full.model, <span class="at">type=</span><span class="dv">3</span>)</span>
<span id="cb69-347"><a href="#cb69-347" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-348"><a href="#cb69-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-349"><a href="#cb69-349" aria-hidden="true" tabindex="-1"></a>For the **horsehearts** data, a comparison of the Type I and II sums squares is given below:</span>
<span id="cb69-350"><a href="#cb69-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-353"><a href="#cb69-353" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-354"><a href="#cb69-354" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-355"><a href="#cb69-355" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb69-356"><a href="#cb69-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-357"><a href="#cb69-357" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb69-358"><a href="#cb69-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-359"><a href="#cb69-359" aria-hidden="true" tabindex="-1"></a>anova1 <span class="ot">&lt;-</span> full.model <span class="sc">|&gt;</span> </span>
<span id="cb69-360"><a href="#cb69-360" aria-hidden="true" tabindex="-1"></a>  <span class="fu">anova</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-361"><a href="#cb69-361" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-362"><a href="#cb69-362" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term, <span class="st">"Type I SS"</span> <span class="ot">=</span> sumsq)  </span>
<span id="cb69-363"><a href="#cb69-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-364"><a href="#cb69-364" aria-hidden="true" tabindex="-1"></a>anova2 <span class="ot">&lt;-</span> full.model <span class="sc">|&gt;</span> </span>
<span id="cb69-365"><a href="#cb69-365" aria-hidden="true" tabindex="-1"></a>  <span class="fu">Anova</span>(<span class="at">type=</span><span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-366"><a href="#cb69-366" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-367"><a href="#cb69-367" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term, <span class="st">"Type II SS"</span> <span class="ot">=</span> sumsq) </span>
<span id="cb69-368"><a href="#cb69-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-369"><a href="#cb69-369" aria-hidden="true" tabindex="-1"></a>type1and2 <span class="ot">&lt;-</span> <span class="fu">full_join</span>(anova1, anova2, <span class="at">by=</span><span class="st">"term"</span>)</span>
<span id="cb69-370"><a href="#cb69-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-371"><a href="#cb69-371" aria-hidden="true" tabindex="-1"></a>type1and2</span>
<span id="cb69-372"><a href="#cb69-372" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-373"><a href="#cb69-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-374"><a href="#cb69-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-377"><a href="#cb69-377" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-378"><a href="#cb69-378" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb69-379"><a href="#cb69-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-380"><a href="#cb69-380" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(knitr<span class="sc">::</span><span class="fu">is_html_output</span>()) {</span>
<span id="cb69-381"><a href="#cb69-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-382"><a href="#cb69-382" aria-hidden="true" tabindex="-1"></a>  type1and2 <span class="sc">|&gt;</span> </span>
<span id="cb69-383"><a href="#cb69-383" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>,</span>
<span id="cb69-384"><a href="#cb69-384" aria-hidden="true" tabindex="-1"></a>        <span class="at">table.attr =</span> <span class="st">'data-quarto-disable-processing="true"'</span></span>
<span id="cb69-385"><a href="#cb69-385" aria-hidden="true" tabindex="-1"></a>        ) <span class="sc">|&gt;</span> </span>
<span id="cb69-386"><a href="#cb69-386" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-387"><a href="#cb69-387" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb69-388"><a href="#cb69-388" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb69-389"><a href="#cb69-389" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-390"><a href="#cb69-390" aria-hidden="true" tabindex="-1"></a>  type1and2 <span class="sc">|&gt;</span> </span>
<span id="cb69-391"><a href="#cb69-391" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-392"><a href="#cb69-392" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-393"><a href="#cb69-393" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-394"><a href="#cb69-394" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb69-395"><a href="#cb69-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-396"><a href="#cb69-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-397"><a href="#cb69-397" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-398"><a href="#cb69-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-399"><a href="#cb69-399" aria-hidden="true" tabindex="-1"></a>When predictor variables are correlated, it is difficult to assess their absolute importance and the importance of a variable can be assessed only relatively. This is not an issue with the most highly correlated predictor in general.</span>
<span id="cb69-400"><a href="#cb69-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-401"><a href="#cb69-401" aria-hidden="true" tabindex="-1"></a><span class="fu"># Regression Fitting with Fewer Predictors</span></span>
<span id="cb69-402"><a href="#cb69-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-403"><a href="#cb69-403" aria-hidden="true" tabindex="-1"></a>The first step before selection of the best subset of predictors is to study the correlation matrix. For horses' heart data, the explanatory variable which is most highly correlated with $y$ (<span class="in">`WEIGHT`</span>) is $x_2$ (<span class="in">`INNERDIA`</span>) having a correlation coefficient of 0.811 (see @fig-multggally). This means that <span class="in">`INNERDIA`</span> should be the single best predictor. We may guess that the next best variable to join <span class="in">`INNERDIA`</span>. This would be $x_3$ (<span class="in">`OUTERSYS`</span>) but the correlations between $x_3$ and the other explanatory variables clouds the issue. In other words, the significance or otherwise of a variable in a multiple regression model depends on the other variables in the model.</span>
<span id="cb69-404"><a href="#cb69-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-405"><a href="#cb69-405" aria-hidden="true" tabindex="-1"></a>Consider the regression of horses' heart <span class="in">`WEIGHT`</span> on <span class="in">`INNERDIA`</span>, <span class="in">`OUTERSYS`</span>, and <span class="in">`EXTSYS`</span>.</span>
<span id="cb69-406"><a href="#cb69-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-409"><a href="#cb69-409" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-410"><a href="#cb69-410" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-411"><a href="#cb69-411" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb69-412"><a href="#cb69-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-413"><a href="#cb69-413" aria-hidden="true" tabindex="-1"></a>threevar.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> INNERDIA <span class="sc">+</span> OUTERSYS <span class="sc">+</span> EXTSYS,</span>
<span id="cb69-414"><a href="#cb69-414" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data=</span>horsehearts)</span>
<span id="cb69-415"><a href="#cb69-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-416"><a href="#cb69-416" aria-hidden="true" tabindex="-1"></a>threevar.model <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span>
<span id="cb69-417"><a href="#cb69-417" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-418"><a href="#cb69-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-419"><a href="#cb69-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-422"><a href="#cb69-422" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-423"><a href="#cb69-423" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb69-424"><a href="#cb69-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-425"><a href="#cb69-425" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(knitr<span class="sc">::</span><span class="fu">is_html_output</span>()) {</span>
<span id="cb69-426"><a href="#cb69-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-427"><a href="#cb69-427" aria-hidden="true" tabindex="-1"></a>  threevar.model <span class="sc">|&gt;</span> </span>
<span id="cb69-428"><a href="#cb69-428" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-429"><a href="#cb69-429" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">3</span>,</span>
<span id="cb69-430"><a href="#cb69-430" aria-hidden="true" tabindex="-1"></a>        <span class="at">table.attr =</span> <span class="st">'data-quarto-disable-processing="true"'</span></span>
<span id="cb69-431"><a href="#cb69-431" aria-hidden="true" tabindex="-1"></a>        ) <span class="sc">|&gt;</span> </span>
<span id="cb69-432"><a href="#cb69-432" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-433"><a href="#cb69-433" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb69-434"><a href="#cb69-434" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb69-435"><a href="#cb69-435" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-436"><a href="#cb69-436" aria-hidden="true" tabindex="-1"></a>  threevar.model <span class="sc">|&gt;</span> </span>
<span id="cb69-437"><a href="#cb69-437" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-438"><a href="#cb69-438" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">3</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-439"><a href="#cb69-439" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-440"><a href="#cb69-440" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-441"><a href="#cb69-441" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb69-442"><a href="#cb69-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-443"><a href="#cb69-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-444"><a href="#cb69-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-445"><a href="#cb69-445" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-446"><a href="#cb69-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-447"><a href="#cb69-447" aria-hidden="true" tabindex="-1"></a>The coefficient of <span class="in">`EXTSYS`</span> is not significant at 5% level. However coefficient of <span class="in">`EXTSYS`</span> was found to be significant in the full regression. The significance of <span class="in">`INNERDIA`</span> coefficient has also changed. This example shows that *we cannot fully rely on the* $t$-test and discard a variable because its coefficient is insignificant.</span>
<span id="cb69-448"><a href="#cb69-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-449"><a href="#cb69-449" aria-hidden="true" tabindex="-1"></a>There are various search methods for finding the best subset of explanatory variables. We will consider **stepwise procedures**, namely algorithms that follow a series of steps to find a good set of predictors. At each step, the current regression model is compared with competing models in which one variable has either been added (*forward selection* procedures) or removed (*backward elimination* procedures). Some measure of goodness is required so that the variable selection procedure can decide whether to switch to one of the competing models or to stop at the current best model. Of the two procedures, backward elimination has two advantages. One is computational: step 2 of the forward selection requires calculation of a large number of competing models whereas step 2 of the backward elimination only requires one. The other is statistical and more subtle. Consider two predictor variables $x_{i}$ and $x_{j}$ and suppose that the forward selection procedure does not add either because their individual importance is low. It may be that their joint influence is important, but the forwards procedure has not been able to detect this. In contrast, the backward elimination procedure starts with all variables included and so is able to delete one and keep the other.</span>
<span id="cb69-450"><a href="#cb69-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-451"><a href="#cb69-451" aria-hidden="true" tabindex="-1"></a>A stepwise regression algorithm can also combine *both* the backward elimination and forward selection procedures. The procedure is the same as forward selection, but immediately after each step of the forward selection algorithm, a step of backward elimination is carried out.</span>
<span id="cb69-452"><a href="#cb69-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-453"><a href="#cb69-453" aria-hidden="true" tabindex="-1"></a>Variable selection solely based $p$ values is preferred only for certain applications such as analysis of factorial type experimental data where response surfaces are fitted. The base <span class="in">`R`</span> does model selection based on $AIC$ which has to be as minimum as possible for a good model. We shall now discuss the concept of $AIC$ and other model selection criteria.</span>
<span id="cb69-454"><a href="#cb69-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-455"><a href="#cb69-455" aria-hidden="true" tabindex="-1"></a>One way to balance model fit with model complexity (number of parameters) is to choose the model with the **minimal** value of Akaike Information Criterion (**AIC** for short, derived by Prof. Hirotugu Akaike as the minimum information theoretic criterion):</span>
<span id="cb69-456"><a href="#cb69-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-457"><a href="#cb69-457" aria-hidden="true" tabindex="-1"></a>$$AIC = n\log \left( \frac{SSE}{n} \right) + 2p$$</span>
<span id="cb69-458"><a href="#cb69-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-459"><a href="#cb69-459" aria-hidden="true" tabindex="-1"></a>Here $n$ is the size of the data set and $p$ is the number of variables in the model. A model with more variables (larger value of $p$) will produce a smaller residual sum of squares SSE but is penalised by the second term.</span>
<span id="cb69-460"><a href="#cb69-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-461"><a href="#cb69-461" aria-hidden="true" tabindex="-1"></a>Bayesian Information Criterion (BIC) (or also called Schwarz's Bayesian criterion, SBC) places a higher penalty that depends on $n$, the number of observations. As a result $BIC$ fares well for selecting a model that explains the relationships well while $AIC$ fares well when selecting a model for prediction purposes.</span>
<span id="cb69-462"><a href="#cb69-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-463"><a href="#cb69-463" aria-hidden="true" tabindex="-1"></a>A number of corrections to $AIC$ and $BIC$ have been proposed in the literature depending on the type of model fitted. We will not study them in this course.</span>
<span id="cb69-464"><a href="#cb69-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-465"><a href="#cb69-465" aria-hidden="true" tabindex="-1"></a>An alternative measure called Mallow's $C_{p}$ index is also available using which we may judge whether the variables at the current step (smaller model) are excessive or short. If unimportant variables are added to the model, then the variance of the fitted values will increase. Similarly if important variables are added, then the bias of the fitted values will decrease. The $C_{p}$ index, which balances the variance and bias, is given by the formula $$C_{p} = \frac{{\text  {SS Error for Smaller Model}}}{{\text {Mean Square Error for full regression}}} -(n-2p)$$ where $p$ = no. of estimated coefficients (including the intercept) in the smaller model and $n$ = total number of observations. The most desired value for the $C_{p}$ index is the number of parameters (including the $y$-intercept) or just smaller. If $C_p&gt;&gt;p$, the model is biased. On the other hand, if $C_p&lt;&lt;p$, the model associated variability is too large. The trade-off between bias and variance is best when $C_{p}=p$. But the $C_{p}$ index is not useful in judging the adequacy of the full regression model because it requires an assumption on what constitutes the full regression. This is not an issue with the $AIC$ or $BIC$ criterion.</span>
<span id="cb69-466"><a href="#cb69-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-467"><a href="#cb69-467" aria-hidden="true" tabindex="-1"></a>For prediction modelling, the following three measures are popular and the <span class="in">`modelr`</span> package will extract these prediction accuracy measures and many more.</span>
<span id="cb69-468"><a href="#cb69-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-469"><a href="#cb69-469" aria-hidden="true" tabindex="-1"></a>*Mean Squared Deviation* (MSD):</span>
<span id="cb69-470"><a href="#cb69-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-471"><a href="#cb69-471" aria-hidden="true" tabindex="-1"></a>MSD is the mean of the squared errors (i.e., deviations).</span>
<span id="cb69-472"><a href="#cb69-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-473"><a href="#cb69-473" aria-hidden="true" tabindex="-1"></a>$$MSD = \frac{\sum \left({\text {observation-fit}}\right)^2 }{{\text {number of observations}}},$$</span>
<span id="cb69-474"><a href="#cb69-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-475"><a href="#cb69-475" aria-hidden="true" tabindex="-1"></a>MSD is also sometimes called the Mean Squared Error (MSE). Note that while computing the MSE, the divisor will be the degrees of freedom and not the number of observations. The square-root of MSE is abbreviated as *RMSE*, and commonly employed as a measure of prediction accuracy.</span>
<span id="cb69-476"><a href="#cb69-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-477"><a href="#cb69-477" aria-hidden="true" tabindex="-1"></a>*Mean Absolute Percentage Error* (MAPE):</span>
<span id="cb69-478"><a href="#cb69-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-479"><a href="#cb69-479" aria-hidden="true" tabindex="-1"></a>MAPE is the average percentage relative error per observation. MAPE is defined as</span>
<span id="cb69-480"><a href="#cb69-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-481"><a href="#cb69-481" aria-hidden="true" tabindex="-1"></a>$$MAPE =\frac{\sum \frac{\left|{\text {observation-fit}}\right|}{{\text {observation}}} }{{\text {number of observations}}} {\times100}.$$</span>
<span id="cb69-482"><a href="#cb69-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-483"><a href="#cb69-483" aria-hidden="true" tabindex="-1"></a>Note that MAPE is unitless.</span>
<span id="cb69-484"><a href="#cb69-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-485"><a href="#cb69-485" aria-hidden="true" tabindex="-1"></a>*Mean Absolute Deviation* (MAD):</span>
<span id="cb69-486"><a href="#cb69-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-487"><a href="#cb69-487" aria-hidden="true" tabindex="-1"></a>MAD is the average absolute error per observation and also known as MAE (mean absolute error). MAD is defined as</span>
<span id="cb69-488"><a href="#cb69-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-489"><a href="#cb69-489" aria-hidden="true" tabindex="-1"></a>$$MAD =\frac{\sum \left|{\text {observation-fit}}\right| }{{\text {number of observations}}}.$$</span>
<span id="cb69-490"><a href="#cb69-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-491"><a href="#cb69-491" aria-hidden="true" tabindex="-1"></a>For the horsehearts data, stepwise selection can be implemented using many R packages including <span class="in">`MASS`</span>, <span class="in">`car`</span>, <span class="in">`leaps`</span> <span class="in">`HH`</span> <span class="in">`caret`</span>, and <span class="in">`SignifReg`</span>. Examples given below are based on the horses hearts data.</span>
<span id="cb69-492"><a href="#cb69-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-493"><a href="#cb69-493" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>The <span class="in">`step()`</span> function performs a combination of both forward and backward regression.  This method favours a model with four variables: <span class="in">`WEIGHT ~ INNERDIA + OUTERSYS + EXTSYS + EXTDIA`</span></span>
<span id="cb69-494"><a href="#cb69-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-495"><a href="#cb69-495" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE, results=FALSE}</span></span>
<span id="cb69-496"><a href="#cb69-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-497"><a href="#cb69-497" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> ., <span class="at">data =</span> horsehearts)</span>
<span id="cb69-498"><a href="#cb69-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-499"><a href="#cb69-499" aria-hidden="true" tabindex="-1"></a>stats<span class="sc">::</span><span class="fu">step</span>(full.model) </span>
<span id="cb69-500"><a href="#cb69-500" aria-hidden="true" tabindex="-1"></a><span class="co"># or MASS::stepAIC(full.model)</span></span>
<span id="cb69-501"><a href="#cb69-501" aria-hidden="true" tabindex="-1"></a><span class="co"># or step(full.model, trace = FALSE) </span></span>
<span id="cb69-502"><a href="#cb69-502" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-503"><a href="#cb69-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-504"><a href="#cb69-504" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>The <span class="in">`stepAIC()`</span> function from the MASS package can also be used instead of the <span class="in">`step()`</span> function. Try-</span>
<span id="cb69-505"><a href="#cb69-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-506"><a href="#cb69-506" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE, results=FALSE}</span></span>
<span id="cb69-507"><a href="#cb69-507" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS, <span class="at">exclude=</span><span class="st">"select"</span>)</span>
<span id="cb69-508"><a href="#cb69-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-509"><a href="#cb69-509" aria-hidden="true" tabindex="-1"></a><span class="fu">stepAIC</span>(full.reg, <span class="at">direction=</span><span class="st">"backward"</span>, <span class="at">trace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb69-510"><a href="#cb69-510" aria-hidden="true" tabindex="-1"></a><span class="fu">stepAIC</span>(full.reg, <span class="at">direction=</span><span class="st">"both"</span>, <span class="at">trace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb69-511"><a href="#cb69-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-512"><a href="#cb69-512" aria-hidden="true" tabindex="-1"></a>null.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> <span class="dv">1</span>, <span class="at">data=</span>horsehearts)</span>
<span id="cb69-513"><a href="#cb69-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-514"><a href="#cb69-514" aria-hidden="true" tabindex="-1"></a>stats<span class="sc">::</span><span class="fu">step</span>(</span>
<span id="cb69-515"><a href="#cb69-515" aria-hidden="true" tabindex="-1"></a>  full.reg, </span>
<span id="cb69-516"><a href="#cb69-516" aria-hidden="true" tabindex="-1"></a>  <span class="at">scope =</span> <span class="fu">list</span>(</span>
<span id="cb69-517"><a href="#cb69-517" aria-hidden="true" tabindex="-1"></a>    <span class="at">lower =</span> null.model,</span>
<span id="cb69-518"><a href="#cb69-518" aria-hidden="true" tabindex="-1"></a>    <span class="at">upper =</span> <span class="sc">~</span>INNERSYS<span class="sc">+</span>INNERDIA<span class="sc">+</span>OUTERSYS<span class="sc">+</span>OUTERDIA<span class="sc">+</span>EXTSYS<span class="sc">+</span>EXTDIA</span>
<span id="cb69-519"><a href="#cb69-519" aria-hidden="true" tabindex="-1"></a>    ), </span>
<span id="cb69-520"><a href="#cb69-520" aria-hidden="true" tabindex="-1"></a>  <span class="at">direction =</span> <span class="st">"forward"</span>)</span>
<span id="cb69-521"><a href="#cb69-521" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-522"><a href="#cb69-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-523"><a href="#cb69-523" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>The <span class="in">`SignifReg`</span> package allows variable selection under various criteria. Try-</span>
<span id="cb69-524"><a href="#cb69-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-525"><a href="#cb69-525" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE, results=FALSE}</span></span>
<span id="cb69-526"><a href="#cb69-526" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(SignifReg)</span>
<span id="cb69-527"><a href="#cb69-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-528"><a href="#cb69-528" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb69-529"><a href="#cb69-529" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"backward"</span>, </span>
<span id="cb69-530"><a href="#cb69-530" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"BIC"</span>,</span>
<span id="cb69-531"><a href="#cb69-531" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb69-532"><a href="#cb69-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-533"><a href="#cb69-533" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb69-534"><a href="#cb69-534" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"backward"</span>, </span>
<span id="cb69-535"><a href="#cb69-535" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"r-adj"</span>, </span>
<span id="cb69-536"><a href="#cb69-536" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb69-537"><a href="#cb69-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-538"><a href="#cb69-538" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb69-539"><a href="#cb69-539" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"backward"</span>,</span>
<span id="cb69-540"><a href="#cb69-540" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"p-value"</span>, </span>
<span id="cb69-541"><a href="#cb69-541" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb69-542"><a href="#cb69-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-543"><a href="#cb69-543" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb69-544"><a href="#cb69-544" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"both"</span>,</span>
<span id="cb69-545"><a href="#cb69-545" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"BIC"</span>,</span>
<span id="cb69-546"><a href="#cb69-546" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb69-547"><a href="#cb69-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-548"><a href="#cb69-548" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb69-549"><a href="#cb69-549" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"both"</span>,</span>
<span id="cb69-550"><a href="#cb69-550" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"r-adj"</span>,</span>
<span id="cb69-551"><a href="#cb69-551" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb69-552"><a href="#cb69-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-553"><a href="#cb69-553" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb69-554"><a href="#cb69-554" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"both"</span>, </span>
<span id="cb69-555"><a href="#cb69-555" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"p-value"</span>,</span>
<span id="cb69-556"><a href="#cb69-556" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb69-557"><a href="#cb69-557" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-558"><a href="#cb69-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-559"><a href="#cb69-559" aria-hidden="true" tabindex="-1"></a>The forward selection procedure also picks only just two variables as seen from the following output:</span>
<span id="cb69-560"><a href="#cb69-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-563"><a href="#cb69-563" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-564"><a href="#cb69-564" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb69-565"><a href="#cb69-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-566"><a href="#cb69-566" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb69-567"><a href="#cb69-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-568"><a href="#cb69-568" aria-hidden="true" tabindex="-1"></a>stmdl <span class="ot">&lt;-</span> <span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb69-569"><a href="#cb69-569" aria-hidden="true" tabindex="-1"></a>                   <span class="at">direction =</span> <span class="st">"both"</span>,</span>
<span id="cb69-570"><a href="#cb69-570" aria-hidden="true" tabindex="-1"></a>                   <span class="at">criterion =</span> <span class="st">"AIC"</span>,</span>
<span id="cb69-571"><a href="#cb69-571" aria-hidden="true" tabindex="-1"></a>                   <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb69-572"><a href="#cb69-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-573"><a href="#cb69-573" aria-hidden="true" tabindex="-1"></a>stmdl <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span>
<span id="cb69-574"><a href="#cb69-574" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-575"><a href="#cb69-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-576"><a href="#cb69-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-579"><a href="#cb69-579" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-580"><a href="#cb69-580" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb69-581"><a href="#cb69-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-582"><a href="#cb69-582" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(knitr<span class="sc">::</span><span class="fu">is_html_output</span>()) {</span>
<span id="cb69-583"><a href="#cb69-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-584"><a href="#cb69-584" aria-hidden="true" tabindex="-1"></a>  stmdl <span class="sc">|&gt;</span> </span>
<span id="cb69-585"><a href="#cb69-585" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-586"><a href="#cb69-586" aria-hidden="true" tabindex="-1"></a>    <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">3</span>,</span>
<span id="cb69-587"><a href="#cb69-587" aria-hidden="true" tabindex="-1"></a>          <span class="at">table.attr =</span> <span class="st">'data-quarto-disable-processing="true"'</span></span>
<span id="cb69-588"><a href="#cb69-588" aria-hidden="true" tabindex="-1"></a>          ) <span class="sc">|&gt;</span> </span>
<span id="cb69-589"><a href="#cb69-589" aria-hidden="true" tabindex="-1"></a>    <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-590"><a href="#cb69-590" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb69-591"><a href="#cb69-591" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb69-592"><a href="#cb69-592" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-593"><a href="#cb69-593" aria-hidden="true" tabindex="-1"></a>  stmdl <span class="sc">|&gt;</span> </span>
<span id="cb69-594"><a href="#cb69-594" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-595"><a href="#cb69-595" aria-hidden="true" tabindex="-1"></a>    <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">3</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-596"><a href="#cb69-596" aria-hidden="true" tabindex="-1"></a>    <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-597"><a href="#cb69-597" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-598"><a href="#cb69-598" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb69-599"><a href="#cb69-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-600"><a href="#cb69-600" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-601"><a href="#cb69-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-602"><a href="#cb69-602" aria-hidden="true" tabindex="-1"></a>For the full regression model, the $AIC$ is -40.5 and it drops to -42.35 for the four variable model. That is, according to the AIC criterion, a further reduction in model size does not compensate for the decline in model fit as measured by the AIC. The $C_{p}$ index also recommends the four variable model because for the $C_{p}$ value of 4.9 is closer to 5, the number of model coefficients.</span>
<span id="cb69-603"><a href="#cb69-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-604"><a href="#cb69-604" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=FALSE, results=FALSE}</span></span>
<span id="cb69-605"><a href="#cb69-605" aria-hidden="true" tabindex="-1"></a>b.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(</span>
<span id="cb69-606"><a href="#cb69-606" aria-hidden="true" tabindex="-1"></a>  WEIGHT <span class="sc">~</span> INNERDIA <span class="sc">+</span> OUTERSYS <span class="sc">+</span> EXTSYS <span class="sc">+</span> EXTDIA,</span>
<span id="cb69-607"><a href="#cb69-607" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> horsehearts</span>
<span id="cb69-608"><a href="#cb69-608" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb69-609"><a href="#cb69-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-610"><a href="#cb69-610" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> b.model <span class="sc">|&gt;</span> <span class="fu">anova</span>() <span class="sc">|&gt;</span> <span class="fu">as.matrix</span>()</span>
<span id="cb69-611"><a href="#cb69-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-612"><a href="#cb69-612" aria-hidden="true" tabindex="-1"></a>MSQ <span class="ot">&lt;-</span> e[<span class="dv">5</span>,<span class="dv">3</span>]</span>
<span id="cb69-613"><a href="#cb69-613" aria-hidden="true" tabindex="-1"></a>cp <span class="ot">&lt;-</span> (e[<span class="dv">5</span>,<span class="dv">2</span>] <span class="sc">/</span> MSQ) <span class="sc">-</span> (<span class="fu">length</span>(horsehearts<span class="sc">$</span>WEIGHT)<span class="sc">-</span><span class="dv">2</span><span class="sc">*</span><span class="dv">5</span>)</span>
<span id="cb69-614"><a href="#cb69-614" aria-hidden="true" tabindex="-1"></a>cp</span>
<span id="cb69-615"><a href="#cb69-615" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-616"><a href="#cb69-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-617"><a href="#cb69-617" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>Step-wise selection of predictors can also be done along with cross validation in each step. The <span class="in">`R`</span> package *caret* enables this. For the horses heart data, the following codes perform the backward regression.</span>
<span id="cb69-618"><a href="#cb69-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-619"><a href="#cb69-619" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, results="hide"}</span></span>
<span id="cb69-620"><a href="#cb69-620" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false </span></span>
<span id="cb69-621"><a href="#cb69-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-622"><a href="#cb69-622" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb69-623"><a href="#cb69-623" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(leaps)</span>
<span id="cb69-624"><a href="#cb69-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-625"><a href="#cb69-625" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb69-626"><a href="#cb69-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-627"><a href="#cb69-627" aria-hidden="true" tabindex="-1"></a>fitControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(</span>
<span id="cb69-628"><a href="#cb69-628" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"repeatedcv"</span>, </span>
<span id="cb69-629"><a href="#cb69-629" aria-hidden="true" tabindex="-1"></a>  <span class="at">number =</span> <span class="dv">5</span>, </span>
<span id="cb69-630"><a href="#cb69-630" aria-hidden="true" tabindex="-1"></a>  <span class="at">repeats =</span> <span class="dv">100</span></span>
<span id="cb69-631"><a href="#cb69-631" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb69-632"><a href="#cb69-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-633"><a href="#cb69-633" aria-hidden="true" tabindex="-1"></a>leapBackwardfit <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb69-634"><a href="#cb69-634" aria-hidden="true" tabindex="-1"></a>  WEIGHT <span class="sc">~</span> ., </span>
<span id="cb69-635"><a href="#cb69-635" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> horsehearts,</span>
<span id="cb69-636"><a href="#cb69-636" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> fitControl, </span>
<span id="cb69-637"><a href="#cb69-637" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"leapBackward"</span></span>
<span id="cb69-638"><a href="#cb69-638" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb69-639"><a href="#cb69-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-640"><a href="#cb69-640" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(leapBackwardfit)</span>
<span id="cb69-641"><a href="#cb69-641" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-642"><a href="#cb69-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-643"><a href="#cb69-643" aria-hidden="true" tabindex="-1"></a>Note that an asterisk in the row means that a particular variable is included in the step. The model in the last step excludes <span class="in">`INNERSYS`</span> and <span class="in">`OUTERDIA.`</span> On the other hand, the forward regression includes only two variables namely <span class="in">`INNERDIA`</span> and <span class="in">`OUTERSYS`</span>. We can also directly use the <span class="in">`leaps`</span> package without cross validation.</span>
<span id="cb69-644"><a href="#cb69-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-647"><a href="#cb69-647" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-648"><a href="#cb69-648" aria-hidden="true" tabindex="-1"></a>fitControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(</span>
<span id="cb69-649"><a href="#cb69-649" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"repeatedcv"</span>, </span>
<span id="cb69-650"><a href="#cb69-650" aria-hidden="true" tabindex="-1"></a>  <span class="at">number =</span> <span class="dv">5</span>, </span>
<span id="cb69-651"><a href="#cb69-651" aria-hidden="true" tabindex="-1"></a>  <span class="at">repeats =</span> <span class="dv">100</span></span>
<span id="cb69-652"><a href="#cb69-652" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb69-653"><a href="#cb69-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-654"><a href="#cb69-654" aria-hidden="true" tabindex="-1"></a>leapForwardfit <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb69-655"><a href="#cb69-655" aria-hidden="true" tabindex="-1"></a>  WEIGHT <span class="sc">~</span> ., </span>
<span id="cb69-656"><a href="#cb69-656" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> horsehearts,</span>
<span id="cb69-657"><a href="#cb69-657" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> fitControl, </span>
<span id="cb69-658"><a href="#cb69-658" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"leapForward"</span></span>
<span id="cb69-659"><a href="#cb69-659" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb69-660"><a href="#cb69-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-661"><a href="#cb69-661" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(leapForwardfit)</span>
<span id="cb69-662"><a href="#cb69-662" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-663"><a href="#cb69-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-664"><a href="#cb69-664" aria-hidden="true" tabindex="-1"></a><span class="fu">## Best Subsets Selection</span></span>
<span id="cb69-665"><a href="#cb69-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-666"><a href="#cb69-666" aria-hidden="true" tabindex="-1"></a>An exhaustive screening of all possible regression models (and hence the name **best subsets** regression) can also be done using software. For example, there are 6 predictor variables in the horses' hearts data. If we fix the number of predictors as 3, then $\small {\left(\begin{array}{c} {6} <span class="sc">\\</span> {3} \end{array}\right)} = 20$ regression models are possible. One may select the 'best' 3-variable model based on criteria such as AIC, $C_{p}$, $R_{adj}^{2}$ etc. Software must be employed to perform the conventional stepwise regression procedures. Software algorithms give one or more best candidate models fixing the number of variables in each step.</span>
<span id="cb69-667"><a href="#cb69-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-668"><a href="#cb69-668" aria-hidden="true" tabindex="-1"></a>On the basis of our analysis on the horses' hear data, we might decide to recommend the model with predictor variables <span class="in">`EXTDIA`</span>, <span class="in">`EXTSYS`</span>, <span class="in">`INNERDIA`</span> and <span class="in">`OUTERSYS`</span>. In particular if the model is to be used for describing relationships then we would tend to include more variables. For prediction purposes, however, a simpler feasible model is preferred and in this case we may opt for the smaller model with only <span class="in">`INNERDIA`</span> and <span class="in">`OUTERSYS`</span>. See @tbl-subset11 produced using the following <span class="in">`R`</span> codes:</span>
<span id="cb69-669"><a href="#cb69-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-672"><a href="#cb69-672" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-673"><a href="#cb69-673" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-674"><a href="#cb69-674" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb69-675"><a href="#cb69-675" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-subset11</span></span>
<span id="cb69-676"><a href="#cb69-676" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Subset selection"</span></span>
<span id="cb69-677"><a href="#cb69-677" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(leaps)</span>
<span id="cb69-678"><a href="#cb69-678" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(HH)</span>
<span id="cb69-679"><a href="#cb69-679" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb69-680"><a href="#cb69-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-681"><a href="#cb69-681" aria-hidden="true" tabindex="-1"></a>b.model <span class="ot">&lt;-</span> <span class="fu">regsubsets</span>(WEIGHT <span class="sc">~</span> ., <span class="at">data =</span> horsehearts) <span class="sc">|&gt;</span></span>
<span id="cb69-682"><a href="#cb69-682" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summaryHH</span>() </span>
<span id="cb69-683"><a href="#cb69-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-684"><a href="#cb69-684" aria-hidden="true" tabindex="-1"></a>b.model <span class="sc">|&gt;</span> </span>
<span id="cb69-685"><a href="#cb69-685" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">3</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-686"><a href="#cb69-686" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">bootstrap_options =</span> <span class="st">"basic"</span>, <span class="at">full_width =</span> F)</span>
<span id="cb69-687"><a href="#cb69-687" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-688"><a href="#cb69-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-689"><a href="#cb69-689" aria-hidden="true" tabindex="-1"></a>Sometimes theory may indicate that a certain explanatory variable should be included in the model (e.g. due to small sample size). If this variable is found to make an insignificant contribution to the model, then one should exclude the variable when the model is to be used for prediction but if the model is to be used for explanation purposes only then the variable should be included. Other considerations such as cost and time may also be taken into account. For every method or algorithm, one could find peculiar data sets where it fouls up. The moral -- be alert and don't automatically accept models thrown up by a program. Note there is **never one right answer** as different methods and different criteria lead to different models.</span>
<span id="cb69-690"><a href="#cb69-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-691"><a href="#cb69-691" aria-hidden="true" tabindex="-1"></a>Variable selection procedures can be a valuable tool in data analysis, particularly in the early stages of building a model. At the same time, they present certain dangers. There are several reasons for this:</span>
<span id="cb69-692"><a href="#cb69-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-693"><a href="#cb69-693" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>These procedures automatically snoop though many models and may select ones which, by chance, happen to fit well.</span>
<span id="cb69-694"><a href="#cb69-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-695"><a href="#cb69-695" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>These forward or backward stepwise procedures are *heuristic* (i.e., shortcut) algorithms, which often work very well but which may not always select the best model for a given number of predictors (here best may refer to adjusted $R^2$-values, or AIC or some other criterion).</span>
<span id="cb69-696"><a href="#cb69-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-697"><a href="#cb69-697" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Automatic procedures cannot take into account special knowledge the analyst may have about the data. Therefore, the model selected may not be the best (or make sense) from a practical point of view.</span>
<span id="cb69-698"><a href="#cb69-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-699"><a href="#cb69-699" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>Methods are available that *shrink* coefficients towards zero. The least squares approach minimises the residual sums of squares or RSS without placing any constraint on the coefficients. The shrinkage methods, which place a constraint on the coefficients, work well when there are large numbers of predictors. A *ridge regression* shrinks the coefficients towards zero but in relation each other. On the other hand, (Least Absolute Selection and Shrinkage Operator) *lasso* regression shrinks some of coefficients to zero which means these predictors can be dropped. Note that the ridge regression does not completely remove predictors. By shrinking large coefficients, we obtain a model with higher bias but lower variance. This process is known as *regularisation* in the literature (not covered in this course).</span>
<span id="cb69-700"><a href="#cb69-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-701"><a href="#cb69-701" aria-hidden="true" tabindex="-1"></a><span class="fu"># Polynomial Models</span></span>
<span id="cb69-702"><a href="#cb69-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-703"><a href="#cb69-703" aria-hidden="true" tabindex="-1"></a>Consider the **pinetree** data set which contains the circumference measurements of pine trees at four positions. The simple regression of the top circumference on the first (bottom) circumference, the fit is ${\text {Top = -6.33 + 0.763 First}}$. This fit is satisfactory on many counts (highly significant $t$ and $F$ values, high $R^{2}$ etc); see @tbl-poly1tidy and @tbl-poly1glance.</span>
<span id="cb69-704"><a href="#cb69-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-707"><a href="#cb69-707" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-708"><a href="#cb69-708" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(</span>
<span id="cb69-709"><a href="#cb69-709" aria-hidden="true" tabindex="-1"></a>  <span class="at">url =</span> <span class="st">"http://www.massey.ac.nz/~anhsmith/data/pinetree.RData"</span>, </span>
<span id="cb69-710"><a href="#cb69-710" aria-hidden="true" tabindex="-1"></a>  <span class="at">destfile =</span> <span class="st">"pinetree.RData"</span>)</span>
<span id="cb69-711"><a href="#cb69-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-712"><a href="#cb69-712" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"pinetree.RData"</span>)</span>
<span id="cb69-713"><a href="#cb69-713" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-714"><a href="#cb69-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-715"><a href="#cb69-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-718"><a href="#cb69-718" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-719"><a href="#cb69-719" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-720"><a href="#cb69-720" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb69-721"><a href="#cb69-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-722"><a href="#cb69-722" aria-hidden="true" tabindex="-1"></a>pine1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Top <span class="sc">~</span> First, <span class="at">data =</span> pinetree) </span>
<span id="cb69-723"><a href="#cb69-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-724"><a href="#cb69-724" aria-hidden="true" tabindex="-1"></a>pine1 <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span>
<span id="cb69-725"><a href="#cb69-725" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-726"><a href="#cb69-726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-727"><a href="#cb69-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-730"><a href="#cb69-730" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-731"><a href="#cb69-731" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb69-732"><a href="#cb69-732" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb69-733"><a href="#cb69-733" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-poly1tidy</span></span>
<span id="cb69-734"><a href="#cb69-734" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "tidy() output of lm(Top~First, data=pinetree)"</span></span>
<span id="cb69-735"><a href="#cb69-735" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(knitr<span class="sc">::</span><span class="fu">is_html_output</span>()) {</span>
<span id="cb69-736"><a href="#cb69-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-737"><a href="#cb69-737" aria-hidden="true" tabindex="-1"></a>  pine1 <span class="sc">|&gt;</span> </span>
<span id="cb69-738"><a href="#cb69-738" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-739"><a href="#cb69-739" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">3</span>,</span>
<span id="cb69-740"><a href="#cb69-740" aria-hidden="true" tabindex="-1"></a>        <span class="at">table.attr =</span> <span class="st">'data-quarto-disable-processing="true"'</span></span>
<span id="cb69-741"><a href="#cb69-741" aria-hidden="true" tabindex="-1"></a>        ) <span class="sc">|&gt;</span> </span>
<span id="cb69-742"><a href="#cb69-742" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-743"><a href="#cb69-743" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb69-744"><a href="#cb69-744" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb69-745"><a href="#cb69-745" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-746"><a href="#cb69-746" aria-hidden="true" tabindex="-1"></a>  pine1 <span class="sc">|&gt;</span> </span>
<span id="cb69-747"><a href="#cb69-747" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-748"><a href="#cb69-748" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">3</span> ) <span class="sc">|&gt;</span> </span>
<span id="cb69-749"><a href="#cb69-749" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-750"><a href="#cb69-750" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-751"><a href="#cb69-751" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb69-752"><a href="#cb69-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-753"><a href="#cb69-753" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb69-754"><a href="#cb69-754" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-755"><a href="#cb69-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-756"><a href="#cb69-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-759"><a href="#cb69-759" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-760"><a href="#cb69-760" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb69-761"><a href="#cb69-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-762"><a href="#cb69-762" aria-hidden="true" tabindex="-1"></a>pine1 <span class="sc">|&gt;</span> </span>
<span id="cb69-763"><a href="#cb69-763" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-764"><a href="#cb69-764" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(adj.r.squared, sigma, statistic, p.value, AIC, BIC)</span>
<span id="cb69-765"><a href="#cb69-765" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-766"><a href="#cb69-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-767"><a href="#cb69-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-770"><a href="#cb69-770" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-771"><a href="#cb69-771" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb69-772"><a href="#cb69-772" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-poly1glance</span></span>
<span id="cb69-773"><a href="#cb69-773" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "glance() output of lm(Top~First, data=pinetree)"</span></span>
<span id="cb69-774"><a href="#cb69-774" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(knitr<span class="sc">::</span><span class="fu">is_html_output</span>()) {</span>
<span id="cb69-775"><a href="#cb69-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-776"><a href="#cb69-776" aria-hidden="true" tabindex="-1"></a>  pine1 <span class="sc">|&gt;</span> </span>
<span id="cb69-777"><a href="#cb69-777" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-778"><a href="#cb69-778" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(adj.r.squared, sigma, statistic, p.value, AIC, BIC) <span class="sc">|&gt;</span> </span>
<span id="cb69-779"><a href="#cb69-779" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">3</span>,</span>
<span id="cb69-780"><a href="#cb69-780" aria-hidden="true" tabindex="-1"></a>        <span class="at">table.attr =</span> <span class="st">'data-quarto-disable-processing="true"'</span></span>
<span id="cb69-781"><a href="#cb69-781" aria-hidden="true" tabindex="-1"></a>        ) <span class="sc">|&gt;</span> </span>
<span id="cb69-782"><a href="#cb69-782" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F) </span>
<span id="cb69-783"><a href="#cb69-783" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb69-784"><a href="#cb69-784" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb69-785"><a href="#cb69-785" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-786"><a href="#cb69-786" aria-hidden="true" tabindex="-1"></a>  pine1 <span class="sc">|&gt;</span> </span>
<span id="cb69-787"><a href="#cb69-787" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-788"><a href="#cb69-788" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(adj.r.squared, sigma, statistic, p.value, AIC, BIC) <span class="sc">|&gt;</span> </span>
<span id="cb69-789"><a href="#cb69-789" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">3</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-790"><a href="#cb69-790" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F) </span>
<span id="cb69-791"><a href="#cb69-791" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-792"><a href="#cb69-792" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb69-793"><a href="#cb69-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-794"><a href="#cb69-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-795"><a href="#cb69-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-796"><a href="#cb69-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-797"><a href="#cb69-797" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-798"><a href="#cb69-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-799"><a href="#cb69-799" aria-hidden="true" tabindex="-1"></a>The residual plot, shown as @fig-pine1, still provides an important clue that we should try a polynomial (cubic) model.</span>
<span id="cb69-800"><a href="#cb69-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-803"><a href="#cb69-803" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-804"><a href="#cb69-804" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-805"><a href="#cb69-805" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-pine1</span></span>
<span id="cb69-806"><a href="#cb69-806" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Residuals vs fits plot"</span></span>
<span id="cb69-807"><a href="#cb69-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-808"><a href="#cb69-808" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggfortify)</span>
<span id="cb69-809"><a href="#cb69-809" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-810"><a href="#cb69-810" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(pine1, <span class="at">which=</span><span class="dv">1</span>, <span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb69-811"><a href="#cb69-811" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-812"><a href="#cb69-812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-815"><a href="#cb69-815" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-816"><a href="#cb69-816" aria-hidden="true" tabindex="-1"></a>pine3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Top <span class="sc">~</span> <span class="fu">poly</span>(First, <span class="dv">3</span>, <span class="at">raw=</span><span class="cn">TRUE</span>), </span>
<span id="cb69-817"><a href="#cb69-817" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> pinetree)</span>
<span id="cb69-818"><a href="#cb69-818" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-819"><a href="#cb69-819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-820"><a href="#cb69-820" aria-hidden="true" tabindex="-1"></a>@tbl-poly3tidy shows the significance results for the polynomial model ${\text Top=44.1 - 3.97First+0.142}\left({\text First}\right)^{2} - 0.00135\left(\text {First}\right)^{3}$. This model has achieved a good reduction in the residual standard error and improved AIC and BIC (see @tbl-poly3glance). The residual diagnostic plots are somewhat satisfactory. The Scale-Location plot suggests that there may be a subgrouping variable. The fitted model can be further improved using the Area categorical factor. This topic, known as the analysis of covariance will be covered later on. Note that both models are satisfactory in terms of Cook's distance. A few leverage or $h_{ii}$ values cause concern seen in @fig-pinelev but we will ignore them given the size of the data set.</span>
<span id="cb69-821"><a href="#cb69-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-824"><a href="#cb69-824" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-825"><a href="#cb69-825" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb69-826"><a href="#cb69-826" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb69-827"><a href="#cb69-827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-828"><a href="#cb69-828" aria-hidden="true" tabindex="-1"></a>pine3 <span class="sc">|&gt;</span> <span class="fu">tidy</span>() </span>
<span id="cb69-829"><a href="#cb69-829" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-830"><a href="#cb69-830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-833"><a href="#cb69-833" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-834"><a href="#cb69-834" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb69-835"><a href="#cb69-835" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb69-836"><a href="#cb69-836" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-poly3tidy</span></span>
<span id="cb69-837"><a href="#cb69-837" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "tidy() output of lm(Top~poly(First, 3, raw=TRUE), data=pinetree)"</span></span>
<span id="cb69-838"><a href="#cb69-838" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(knitr<span class="sc">::</span><span class="fu">is_html_output</span>()) {</span>
<span id="cb69-839"><a href="#cb69-839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-840"><a href="#cb69-840" aria-hidden="true" tabindex="-1"></a>  pine3 <span class="sc">|&gt;</span> </span>
<span id="cb69-841"><a href="#cb69-841" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-842"><a href="#cb69-842" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">4</span>,</span>
<span id="cb69-843"><a href="#cb69-843" aria-hidden="true" tabindex="-1"></a>        <span class="at">table.attr =</span> <span class="st">'data-quarto-disable-processing="true"'</span></span>
<span id="cb69-844"><a href="#cb69-844" aria-hidden="true" tabindex="-1"></a>        ) <span class="sc">|&gt;</span> </span>
<span id="cb69-845"><a href="#cb69-845" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-846"><a href="#cb69-846" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb69-847"><a href="#cb69-847" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb69-848"><a href="#cb69-848" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-849"><a href="#cb69-849" aria-hidden="true" tabindex="-1"></a>  pine3 <span class="sc">|&gt;</span> </span>
<span id="cb69-850"><a href="#cb69-850" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-851"><a href="#cb69-851" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">4</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-852"><a href="#cb69-852" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-853"><a href="#cb69-853" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-854"><a href="#cb69-854" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb69-855"><a href="#cb69-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-856"><a href="#cb69-856" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb69-857"><a href="#cb69-857" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-858"><a href="#cb69-858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-859"><a href="#cb69-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-862"><a href="#cb69-862" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-863"><a href="#cb69-863" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-864"><a href="#cb69-864" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb69-865"><a href="#cb69-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-866"><a href="#cb69-866" aria-hidden="true" tabindex="-1"></a>pine3 <span class="sc">|&gt;</span> </span>
<span id="cb69-867"><a href="#cb69-867" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-868"><a href="#cb69-868" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(adj.r.squared, sigma, statistic, p.value, AIC, BIC) </span>
<span id="cb69-869"><a href="#cb69-869" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-870"><a href="#cb69-870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-873"><a href="#cb69-873" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-874"><a href="#cb69-874" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb69-875"><a href="#cb69-875" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-poly3glance</span></span>
<span id="cb69-876"><a href="#cb69-876" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "glance() output of lm(Top~poly(First,3, raw=TRUE), data=pinetree)"</span></span>
<span id="cb69-877"><a href="#cb69-877" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(knitr<span class="sc">::</span><span class="fu">is_html_output</span>()) {</span>
<span id="cb69-878"><a href="#cb69-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-879"><a href="#cb69-879" aria-hidden="true" tabindex="-1"></a>  pine3 <span class="sc">|&gt;</span> </span>
<span id="cb69-880"><a href="#cb69-880" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-881"><a href="#cb69-881" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(adj.r.squared, sigma, statistic, p.value, AIC, BIC) <span class="sc">|&gt;</span> </span>
<span id="cb69-882"><a href="#cb69-882" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>,</span>
<span id="cb69-883"><a href="#cb69-883" aria-hidden="true" tabindex="-1"></a>        <span class="at">table.attr =</span> <span class="st">'data-quarto-disable-processing="true"'</span></span>
<span id="cb69-884"><a href="#cb69-884" aria-hidden="true" tabindex="-1"></a>        ) <span class="sc">|&gt;</span> </span>
<span id="cb69-885"><a href="#cb69-885" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-886"><a href="#cb69-886" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb69-887"><a href="#cb69-887" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb69-888"><a href="#cb69-888" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-889"><a href="#cb69-889" aria-hidden="true" tabindex="-1"></a>  pine3 <span class="sc">|&gt;</span> </span>
<span id="cb69-890"><a href="#cb69-890" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-891"><a href="#cb69-891" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(adj.r.squared, sigma, statistic, p.value, AIC, BIC) <span class="sc">|&gt;</span> </span>
<span id="cb69-892"><a href="#cb69-892" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-893"><a href="#cb69-893" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-894"><a href="#cb69-894" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-895"><a href="#cb69-895" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb69-896"><a href="#cb69-896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-897"><a href="#cb69-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-898"><a href="#cb69-898" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-899"><a href="#cb69-899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-902"><a href="#cb69-902" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-903"><a href="#cb69-903" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-904"><a href="#cb69-904" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-pinelev</span></span>
<span id="cb69-905"><a href="#cb69-905" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Residual vs Leverage plot"</span></span>
<span id="cb69-906"><a href="#cb69-906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-907"><a href="#cb69-907" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(pine3, <span class="at">which=</span><span class="dv">5</span>, <span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb69-908"><a href="#cb69-908" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-909"><a href="#cb69-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-910"><a href="#cb69-910" aria-hidden="true" tabindex="-1"></a>How quadratic and quartic models fare compared to the cubic fit is also of interest. Try the <span class="in">`R`</span> code given below and compare the outputs:</span>
<span id="cb69-911"><a href="#cb69-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-912"><a href="#cb69-912" aria-hidden="true" tabindex="-1"></a><span class="in">```{r polysum, echo=TRUE, results='hide'}</span></span>
<span id="cb69-913"><a href="#cb69-913" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(WEIGHT <span class="sc">~</span> OUTERDIA, <span class="at">data =</span> horsehearts))</span>
<span id="cb69-914"><a href="#cb69-914" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(WEIGHT <span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">2</span>, <span class="at">raw=</span>T), <span class="at">data =</span> horsehearts))</span>
<span id="cb69-915"><a href="#cb69-915" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(WEIGHT <span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">3</span>, <span class="at">raw=</span>T), <span class="at">data =</span> horsehearts))</span>
<span id="cb69-916"><a href="#cb69-916" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(WEIGHT <span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">4</span>, <span class="at">raw=</span>T), <span class="at">data =</span> horsehearts))</span>
<span id="cb69-917"><a href="#cb69-917" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-918"><a href="#cb69-918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-919"><a href="#cb69-919" aria-hidden="true" tabindex="-1"></a>The key model summary measures of the four polynomial models are shown in @tbl-polysummary. As expected, the $R^2$ value increases, although not by much in this case, as polynomial terms are added. Note that the multicollinearity among the polynomial terms renders all the coefficients of the quadratic regression insignificant at 5% level. For the cubic regression model, all the coefficients are significant. It is usual to keep adding the higher order terms until there is no significant increase in the additional variation explained (measured by the $t$ or $F$ statistic). Alternatively we may use the AIC criterion. In the above example, when the quartic term <span class="in">`OUTERDIA`</span>$^4$ is added, the AIC slightly increases to 114.99 (from 114.65) suggesting that we may stop with the cubic regression.</span>
<span id="cb69-920"><a href="#cb69-920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-923"><a href="#cb69-923" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-924"><a href="#cb69-924" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-925"><a href="#cb69-925" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb69-926"><a href="#cb69-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-927"><a href="#cb69-927" aria-hidden="true" tabindex="-1"></a>modstats <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb69-928"><a href="#cb69-928" aria-hidden="true" tabindex="-1"></a>  <span class="at">straight.line =</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> OUTERDIA, </span>
<span id="cb69-929"><a href="#cb69-929" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data =</span> horsehearts), </span>
<span id="cb69-930"><a href="#cb69-930" aria-hidden="true" tabindex="-1"></a>  <span class="at">quadratic =</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">2</span>,<span class="at">raw=</span>T),</span>
<span id="cb69-931"><a href="#cb69-931" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data=</span>horsehearts), </span>
<span id="cb69-932"><a href="#cb69-932" aria-hidden="true" tabindex="-1"></a>  <span class="at">cubic =</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">3</span>, <span class="at">raw=</span>T), </span>
<span id="cb69-933"><a href="#cb69-933" aria-hidden="true" tabindex="-1"></a>             <span class="at">data=</span>horsehearts), </span>
<span id="cb69-934"><a href="#cb69-934" aria-hidden="true" tabindex="-1"></a>  <span class="at">quartic =</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">4</span>, <span class="at">raw=</span>T),</span>
<span id="cb69-935"><a href="#cb69-935" aria-hidden="true" tabindex="-1"></a>               <span class="at">data=</span>horsehearts)</span>
<span id="cb69-936"><a href="#cb69-936" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span> </span>
<span id="cb69-937"><a href="#cb69-937" aria-hidden="true" tabindex="-1"></a>  <span class="fu">enframe</span>(</span>
<span id="cb69-938"><a href="#cb69-938" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">"model"</span>,</span>
<span id="cb69-939"><a href="#cb69-939" aria-hidden="true" tabindex="-1"></a>    <span class="at">value =</span> <span class="st">"fit"</span></span>
<span id="cb69-940"><a href="#cb69-940" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span> </span>
<span id="cb69-941"><a href="#cb69-941" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">glanced =</span> <span class="fu">map</span>(fit, glance)) <span class="sc">|&gt;</span> </span>
<span id="cb69-942"><a href="#cb69-942" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(glanced) <span class="sc">|&gt;</span> </span>
<span id="cb69-943"><a href="#cb69-943" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(model, r.squared, adj.r.squared, sigma, </span>
<span id="cb69-944"><a href="#cb69-944" aria-hidden="true" tabindex="-1"></a>         statistic, AIC, BIC)</span>
<span id="cb69-945"><a href="#cb69-945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-946"><a href="#cb69-946" aria-hidden="true" tabindex="-1"></a>modstats</span>
<span id="cb69-947"><a href="#cb69-947" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-948"><a href="#cb69-948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-949"><a href="#cb69-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-952"><a href="#cb69-952" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-953"><a href="#cb69-953" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb69-954"><a href="#cb69-954" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-polysummary</span></span>
<span id="cb69-955"><a href="#cb69-955" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Glancing Polynomial models"</span></span>
<span id="cb69-956"><a href="#cb69-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-957"><a href="#cb69-957" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(knitr<span class="sc">::</span><span class="fu">is_html_output</span>()) {</span>
<span id="cb69-958"><a href="#cb69-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-959"><a href="#cb69-959" aria-hidden="true" tabindex="-1"></a>  modstats <span class="sc">|&gt;</span> </span>
<span id="cb69-960"><a href="#cb69-960" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">2</span>,</span>
<span id="cb69-961"><a href="#cb69-961" aria-hidden="true" tabindex="-1"></a>        <span class="at">table.attr =</span> <span class="st">'data-quarto-disable-processing="true"'</span></span>
<span id="cb69-962"><a href="#cb69-962" aria-hidden="true" tabindex="-1"></a>        ) <span class="sc">|&gt;</span> </span>
<span id="cb69-963"><a href="#cb69-963" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-964"><a href="#cb69-964" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb69-965"><a href="#cb69-965" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb69-966"><a href="#cb69-966" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-967"><a href="#cb69-967" aria-hidden="true" tabindex="-1"></a>  modstats <span class="sc">|&gt;</span> </span>
<span id="cb69-968"><a href="#cb69-968" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-969"><a href="#cb69-969" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-970"><a href="#cb69-970" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-971"><a href="#cb69-971" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb69-972"><a href="#cb69-972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-973"><a href="#cb69-973" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-974"><a href="#cb69-974" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-975"><a href="#cb69-975" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-976"><a href="#cb69-976" aria-hidden="true" tabindex="-1"></a>It is desirable to keep the coefficients the same when higher order polynomial terms are added. This can be done using orthogonal polynomial coefficients (we will skip the theory) for which we will avoid the argument <span class="in">`raw`</span> within the function <span class="in">`poly()`</span>. Try-</span>
<span id="cb69-977"><a href="#cb69-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-978"><a href="#cb69-978" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, results='hide'}</span></span>
<span id="cb69-979"><a href="#cb69-979" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Top <span class="sc">~</span> <span class="fu">poly</span>(First,<span class="dv">1</span>), <span class="at">data=</span>pinetree)</span>
<span id="cb69-980"><a href="#cb69-980" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Top <span class="sc">~</span> <span class="fu">poly</span>(First,<span class="dv">2</span>), <span class="at">data=</span>pinetree)</span>
<span id="cb69-981"><a href="#cb69-981" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Top <span class="sc">~</span> <span class="fu">poly</span>(First,<span class="dv">3</span>), <span class="at">data=</span>pinetree)</span>
<span id="cb69-982"><a href="#cb69-982" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-983"><a href="#cb69-983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-984"><a href="#cb69-984" aria-hidden="true" tabindex="-1"></a>Stepwise methods are not employed for developing polynomial models as it would not be appropriate (say) to have the linear and cubic terms but drop the quadratic one. The coefficient terms for the higher order terms become very small. It is also possible that the coefficient estimation may be incorrect due to ill conditioning of the data matrix which is used obtain the model coefficients. Some authors recommend appropriate rescaling of the polynomial terms (such as subtracting the mean etc) to avoid such problems.</span>
<span id="cb69-985"><a href="#cb69-985" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-986"><a href="#cb69-986" aria-hidden="true" tabindex="-1"></a>The use of polynomials greater than second-order is discouraged. Higher-order polynomials are known to be extremely volatile; they have high variance, and make bad predictions. If you need a more flexible model, then it is generally better to use some sort of smoother than a high-order polynomial.</span>
<span id="cb69-987"><a href="#cb69-987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-988"><a href="#cb69-988" aria-hidden="true" tabindex="-1"></a>In fact, a popular method of smoothing is known as "local polynomial fitting", or **spline smoothing**. Local polynomials are sometimes preferred to a single polynomial regression model for the whole data set. An example based on the <span class="in">`pinetree`</span> data is shown in @fig-spline which uses the <span class="in">`bs()`</span> function from the *splines* package.</span>
<span id="cb69-989"><a href="#cb69-989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-992"><a href="#cb69-992" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-993"><a href="#cb69-993" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-994"><a href="#cb69-994" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-spline</span></span>
<span id="cb69-995"><a href="#cb69-995" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Polynomial Spline smoothing"</span></span>
<span id="cb69-996"><a href="#cb69-996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-997"><a href="#cb69-997" aria-hidden="true" tabindex="-1"></a>pinetree <span class="sc">|&gt;</span> </span>
<span id="cb69-998"><a href="#cb69-998" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb69-999"><a href="#cb69-999" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(First, Top) <span class="sc">+</span></span>
<span id="cb69-1000"><a href="#cb69-1000" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb69-1001"><a href="#cb69-1001" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> lm, </span>
<span id="cb69-1002"><a href="#cb69-1002" aria-hidden="true" tabindex="-1"></a>              <span class="at">formula =</span> y <span class="sc">~</span> splines<span class="sc">::</span><span class="fu">bs</span>(x, <span class="dv">3</span>))</span>
<span id="cb69-1003"><a href="#cb69-1003" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1004"><a href="#cb69-1004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1005"><a href="#cb69-1005" aria-hidden="true" tabindex="-1"></a><span class="fu"># Model structure and other issues</span></span>
<span id="cb69-1006"><a href="#cb69-1006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1007"><a href="#cb69-1007" aria-hidden="true" tabindex="-1"></a>The difficult task in statistical modelling is the assessment of the underlying model structure or alternatively knowing the true form of the relationship. For example, the true relationship between $Y$ and $X$ variables may be nonlinear. If we incorrectly assume a multiple linear relationship instead, a good model may not result. The interaction between the explanatory variables is also important and this topic is covered in a different section. We may also fit a robust linear model in order to validate the ordinary least squares fit. For the horses heart data, OUTERSYS and EXTDIA were short-listed as the predictors of WEIGHT using the AIC criterion. This least squares regression model can be compared to the robust versions as shown in @fig-mcompare1.</span>
<span id="cb69-1008"><a href="#cb69-1008" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1011"><a href="#cb69-1011" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1012"><a href="#cb69-1012" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1013"><a href="#cb69-1013" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-mcompare1</span></span>
<span id="cb69-1014"><a href="#cb69-1014" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Comparison of predictions"</span></span>
<span id="cb69-1015"><a href="#cb69-1015" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1016"><a href="#cb69-1016" aria-hidden="true" tabindex="-1"></a>hh_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> OUTERSYS <span class="sc">+</span> EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb69-1017"><a href="#cb69-1017" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1018"><a href="#cb69-1018" aria-hidden="true" tabindex="-1"></a>hh_rlm <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">rlm</span>(WEIGHT <span class="sc">~</span> OUTERSYS <span class="sc">+</span> EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb69-1019"><a href="#cb69-1019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1020"><a href="#cb69-1020" aria-hidden="true" tabindex="-1"></a>hh_lmrob <span class="ot">&lt;-</span> robustbase<span class="sc">::</span><span class="fu">lmrob</span>(WEIGHT <span class="sc">~</span> OUTERSYS <span class="sc">+</span> EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb69-1021"><a href="#cb69-1021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1022"><a href="#cb69-1022" aria-hidden="true" tabindex="-1"></a>horsehearts <span class="sc">|&gt;</span> </span>
<span id="cb69-1023"><a href="#cb69-1023" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather_predictions</span>(hh_lm, hh_rlm, hh_lmrob) <span class="sc">%&gt;%</span> </span>
<span id="cb69-1024"><a href="#cb69-1024" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>WEIGHT, <span class="at">y=</span>pred, <span class="at">colour=</span>model)) <span class="sc">+</span> </span>
<span id="cb69-1025"><a href="#cb69-1025" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb69-1026"><a href="#cb69-1026" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>) <span class="sc">+</span> </span>
<span id="cb69-1027"><a href="#cb69-1027" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Predicted WEIGHT"</span>) <span class="sc">+</span> <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb69-1028"><a href="#cb69-1028" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Comparison of model predictions"</span>)</span>
<span id="cb69-1029"><a href="#cb69-1029" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1030"><a href="#cb69-1030" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1031"><a href="#cb69-1031" aria-hidden="true" tabindex="-1"></a>@fig-mcompare1 shows that the scatter plot of predicted versus actual $Y$ values for the three fitted models which confirms that these models perform very similarly. We may also extract measures such as mean absolute percentage error (MAPE) or residual SD or root mean square error (RMSE) for the three models using <span class="in">`modelr`</span> package; see the code shown below:</span>
<span id="cb69-1032"><a href="#cb69-1032" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1035"><a href="#cb69-1035" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1036"><a href="#cb69-1036" aria-hidden="true" tabindex="-1"></a><span class="fu">list</span>(<span class="at">hh_lm =</span> hh_lm, </span>
<span id="cb69-1037"><a href="#cb69-1037" aria-hidden="true" tabindex="-1"></a>     <span class="at">hh_rlm =</span> hh_rlm, </span>
<span id="cb69-1038"><a href="#cb69-1038" aria-hidden="true" tabindex="-1"></a>     <span class="at">hh_lmrob =</span> hh_lmrob) <span class="sc">|&gt;</span> </span>
<span id="cb69-1039"><a href="#cb69-1039" aria-hidden="true" tabindex="-1"></a>  <span class="fu">enframe</span>(<span class="st">"method"</span>, <span class="st">"fit"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-1040"><a href="#cb69-1040" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb69-1041"><a href="#cb69-1041" aria-hidden="true" tabindex="-1"></a>    <span class="at">MAPE =</span> <span class="fu">map_dbl</span>(fit, \(x){<span class="fu">mape</span>(x, horsehearts)}),</span>
<span id="cb69-1042"><a href="#cb69-1042" aria-hidden="true" tabindex="-1"></a>    <span class="at">RMSE =</span> <span class="fu">map_dbl</span>(fit, \(x){<span class="fu">rmse</span>(x, horsehearts)})</span>
<span id="cb69-1043"><a href="#cb69-1043" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb69-1044"><a href="#cb69-1044" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1045"><a href="#cb69-1045" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1046"><a href="#cb69-1046" aria-hidden="true" tabindex="-1"></a>Measures such as AIC or BIC need corrections when the normality assumption does not hold but the above summary measures do not require such a distributional assumption to hold.</span>
<span id="cb69-1047"><a href="#cb69-1047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1048"><a href="#cb69-1048" aria-hidden="true" tabindex="-1"></a>If a large dataset is in hand, a part of the data (training data) can be used to fit the model and then we can see how well the fitted model works for the remaining data.</span>
<span id="cb69-1049"><a href="#cb69-1049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1050"><a href="#cb69-1050" aria-hidden="true" tabindex="-1"></a><span class="fu"># Smoothing and Regression modeling for Time series</span></span>
<span id="cb69-1051"><a href="#cb69-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1052"><a href="#cb69-1052" aria-hidden="true" tabindex="-1"></a>For time series data, the term **smoothing** means the technique of removing random variation in the data but retaining any trend and cyclic/seasonal type of variations. Two types of smoothing methods are considered in this section. These two methods are basically averaging techniques, which use only the immediate past data (rather than all the observations) with constant and variable weights for each observation.</span>
<span id="cb69-1053"><a href="#cb69-1053" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1054"><a href="#cb69-1054" aria-hidden="true" tabindex="-1"></a><span class="fu">## Time Series Regression with seasonality components</span></span>
<span id="cb69-1055"><a href="#cb69-1055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1056"><a href="#cb69-1056" aria-hidden="true" tabindex="-1"></a>Indicator variables are used to capture the seasonality such as months and quarters. Time related trends can be picked up with the usual regression. The function <span class="in">`tslm()`</span> from the <span class="in">`forecast`</span> package is handy to model the response $Y$ using the time variable and the seasonal indicators. Consider the credit card balance series discussed in Chapter 2. The fitted linear model is shown in @tbl-cbfit1 and the forecasts made the model for 48 months ahead are shown in @fig-cbforecast.</span>
<span id="cb69-1057"><a href="#cb69-1057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1060"><a href="#cb69-1060" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1061"><a href="#cb69-1061" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readxl)</span>
<span id="cb69-1062"><a href="#cb69-1062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1063"><a href="#cb69-1063" aria-hidden="true" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="st">"http://www.massey.ac.nz/~anhsmith/data/hc12_daily_average_balances.xlsx"</span></span>
<span id="cb69-1064"><a href="#cb69-1064" aria-hidden="true" tabindex="-1"></a>destfile <span class="ot">&lt;-</span> <span class="st">"hc12.xlsx"</span></span>
<span id="cb69-1065"><a href="#cb69-1065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1066"><a href="#cb69-1066" aria-hidden="true" tabindex="-1"></a>curl<span class="sc">::</span><span class="fu">curl_download</span>(url, destfile)</span>
<span id="cb69-1067"><a href="#cb69-1067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1068"><a href="#cb69-1068" aria-hidden="true" tabindex="-1"></a>credit.balance <span class="ot">&lt;-</span> </span>
<span id="cb69-1069"><a href="#cb69-1069" aria-hidden="true" tabindex="-1"></a>  <span class="fu">read_excel</span>(destfile, <span class="at">na =</span> <span class="st">"-"</span>, <span class="at">skip =</span> <span class="dv">4</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-1070"><a href="#cb69-1070" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(CRCD.MOA20) <span class="sc">|&gt;</span> </span>
<span id="cb69-1071"><a href="#cb69-1071" aria-hidden="true" tabindex="-1"></a>  <span class="fu">na.omit</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-1072"><a href="#cb69-1072" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ts</span>(<span class="at">start=</span><span class="fu">c</span>(<span class="dv">2000</span>,<span class="dv">7</span>), <span class="at">frequency=</span><span class="dv">12</span>)</span>
<span id="cb69-1073"><a href="#cb69-1073" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1074"><a href="#cb69-1074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1077"><a href="#cb69-1077" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1078"><a href="#cb69-1078" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1079"><a href="#cb69-1079" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb69-1080"><a href="#cb69-1080" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-cbforecast</span></span>
<span id="cb69-1081"><a href="#cb69-1081" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "tidy() output of the tslm() fit"</span></span>
<span id="cb69-1082"><a href="#cb69-1082" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1083"><a href="#cb69-1083" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(forecast)</span>
<span id="cb69-1084"><a href="#cb69-1084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1085"><a href="#cb69-1085" aria-hidden="true" tabindex="-1"></a>cbfit <span class="ot">&lt;-</span> <span class="fu">tslm</span>(credit.balance <span class="sc">~</span> trend <span class="sc">+</span> season)</span>
<span id="cb69-1086"><a href="#cb69-1086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1087"><a href="#cb69-1087" aria-hidden="true" tabindex="-1"></a>cbfit <span class="sc">|&gt;</span> <span class="fu">forecast</span>(<span class="at">h=</span><span class="dv">48</span>) <span class="sc">|&gt;</span> <span class="fu">autoplot</span>()</span>
<span id="cb69-1088"><a href="#cb69-1088" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1089"><a href="#cb69-1089" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1092"><a href="#cb69-1092" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1093"><a href="#cb69-1093" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1094"><a href="#cb69-1094" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb69-1095"><a href="#cb69-1095" aria-hidden="true" tabindex="-1"></a>cbfit <span class="sc">|&gt;</span> <span class="fu">tidy</span>()  </span>
<span id="cb69-1096"><a href="#cb69-1096" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1097"><a href="#cb69-1097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1098"><a href="#cb69-1098" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1101"><a href="#cb69-1101" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1102"><a href="#cb69-1102" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb69-1103"><a href="#cb69-1103" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-cbfit1</span></span>
<span id="cb69-1104"><a href="#cb69-1104" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "tidy() output of the tslm() fit"</span></span>
<span id="cb69-1105"><a href="#cb69-1105" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(knitr<span class="sc">::</span><span class="fu">is_html_output</span>()) {</span>
<span id="cb69-1106"><a href="#cb69-1106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1107"><a href="#cb69-1107" aria-hidden="true" tabindex="-1"></a>  cbfit <span class="sc">|&gt;</span> </span>
<span id="cb69-1108"><a href="#cb69-1108" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-1109"><a href="#cb69-1109" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">3</span>,</span>
<span id="cb69-1110"><a href="#cb69-1110" aria-hidden="true" tabindex="-1"></a>        <span class="at">table.attr =</span> <span class="st">'data-quarto-disable-processing="true"'</span></span>
<span id="cb69-1111"><a href="#cb69-1111" aria-hidden="true" tabindex="-1"></a>        ) <span class="sc">|&gt;</span> </span>
<span id="cb69-1112"><a href="#cb69-1112" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-1113"><a href="#cb69-1113" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb69-1114"><a href="#cb69-1114" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb69-1115"><a href="#cb69-1115" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-1116"><a href="#cb69-1116" aria-hidden="true" tabindex="-1"></a>  cbfit <span class="sc">|&gt;</span> </span>
<span id="cb69-1117"><a href="#cb69-1117" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb69-1118"><a href="#cb69-1118" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">3</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-1119"><a href="#cb69-1119" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span>
<span id="cb69-1120"><a href="#cb69-1120" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb69-1121"><a href="#cb69-1121" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb69-1122"><a href="#cb69-1122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1123"><a href="#cb69-1123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1124"><a href="#cb69-1124" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1125"><a href="#cb69-1125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1126"><a href="#cb69-1126" aria-hidden="true" tabindex="-1"></a>@tbl-cbfit1 shows that the seasonal effects are highly significant. @fig-cbforecast shows that the fitted model is not faring well for the year 2020, which was affected by COVID. The forecasts ahead are also untrustworthy.</span>
<span id="cb69-1127"><a href="#cb69-1127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1128"><a href="#cb69-1128" aria-hidden="true" tabindex="-1"></a>Note that the time variable $t$ becomes the predictor in the fitted model but the model is not based on the past or lagged $Y$ data. The smoothing methods discussed below employ such past data.</span>
<span id="cb69-1129"><a href="#cb69-1129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1130"><a href="#cb69-1130" aria-hidden="true" tabindex="-1"></a><span class="fu">## Moving Average Smoothing</span></span>
<span id="cb69-1131"><a href="#cb69-1131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1132"><a href="#cb69-1132" aria-hidden="true" tabindex="-1"></a>Here we compute the mean of successive smaller sets of numbers of immediate past data. The period or length (also called span) of the **moving average** is the number of observations (including the present one) used for averaging. The general expression for the moving average $M_t$ at time $t$ is $$M_t = <span class="co">[</span><span class="ot">X_t + X_{t-1} + ... + X_{t-N+1}</span><span class="co">]</span> / N$$ where $X_t$ is the observation at time $t$ and $N$ the moving average length. @fig-MAcntr shows the moving average smoothing for the '\$20 Notes in public hands' data. It can be noted that the degree of smoothing is directly related to the length of the moving average (i.e., longer the length, greater the smoothing).</span>
<span id="cb69-1133"><a href="#cb69-1133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1136"><a href="#cb69-1136" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1137"><a href="#cb69-1137" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb69-1138"><a href="#cb69-1138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1139"><a href="#cb69-1139" aria-hidden="true" tabindex="-1"></a>NZnotes20 <span class="ot">&lt;-</span> <span class="fu">read_table</span>(</span>
<span id="cb69-1140"><a href="#cb69-1140" aria-hidden="true" tabindex="-1"></a>  <span class="st">"http://www.massey.ac.nz/~anhsmith/data/20dollar.txt"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb69-1141"><a href="#cb69-1141" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(value) <span class="sc">|&gt;</span> </span>
<span id="cb69-1142"><a href="#cb69-1142" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ts</span>(<span class="at">start=</span><span class="dv">1968</span>, <span class="at">frequency=</span><span class="dv">1</span>)</span>
<span id="cb69-1143"><a href="#cb69-1143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1144"><a href="#cb69-1144" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1145"><a href="#cb69-1145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1148"><a href="#cb69-1148" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1149"><a href="#cb69-1149" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1150"><a href="#cb69-1150" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb69-1151"><a href="#cb69-1151" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-MAcntr</span></span>
<span id="cb69-1152"><a href="#cb69-1152" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Centred and Non-centred Moving Averages"</span></span>
<span id="cb69-1153"><a href="#cb69-1153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1154"><a href="#cb69-1154" aria-hidden="true" tabindex="-1"></a>MA.centred <span class="ot">&lt;-</span> <span class="fu">ma</span>(NZnotes20, <span class="dv">2</span>, <span class="at">centre =</span> <span class="cn">TRUE</span>)</span>
<span id="cb69-1155"><a href="#cb69-1155" aria-hidden="true" tabindex="-1"></a>MA.noncentred <span class="ot">&lt;-</span> <span class="fu">ma</span>(NZnotes20, <span class="dv">2</span>, <span class="at">centre =</span> <span class="cn">FALSE</span>)</span>
<span id="cb69-1156"><a href="#cb69-1156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1157"><a href="#cb69-1157" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(forecast)</span>
<span id="cb69-1158"><a href="#cb69-1158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1159"><a href="#cb69-1159" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(NZnotes20) <span class="sc">+</span> </span>
<span id="cb69-1160"><a href="#cb69-1160" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autolayer</span>(MA.centred, <span class="at">series =</span> <span class="st">"2 y MA centred"</span>) <span class="sc">+</span> </span>
<span id="cb69-1161"><a href="#cb69-1161" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autolayer</span>(MA.noncentred, <span class="at">series =</span> <span class="st">"2 y MA noncentred"</span>, <span class="at">linetype=</span><span class="dv">2</span>)</span>
<span id="cb69-1162"><a href="#cb69-1162" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1163"><a href="#cb69-1163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1164"><a href="#cb69-1164" aria-hidden="true" tabindex="-1"></a>When placing the moving averages against time, placing them in the middle time period is more appropriate. Strictly speaking the moving average must fall at $t = 1.5, 2.5, 3.5$ etc when the period of the moving average is an even number. Hence we need to smooth again the moving average smoothed values to place the moving averages at $t = 2, 3, 4$ etc. @fig-MAcntr also compares the centred moving average smoothing and non-centred moving average smoothing (length 2) for the '\$20 Notes in public hands' data. It is easy to see that centring has stopped the moving averages from drifting below the original series and 'lined' them with the original data.</span>
<span id="cb69-1165"><a href="#cb69-1165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1166"><a href="#cb69-1166" aria-hidden="true" tabindex="-1"></a><span class="fu">## Exponential Smoothing</span></span>
<span id="cb69-1167"><a href="#cb69-1167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1168"><a href="#cb69-1168" aria-hidden="true" tabindex="-1"></a>In moving average smoothing all past observations are given equal weight. In exponential average smoothing, past observations (i.e. as the observations become older) are given exponentially decreasing weights. That is, recent observations are given relatively more weight than the older observations. Hence the exponential smoothing method becomes a representative method to produce a smoothed time series. The average computed using exponentially decreasing weights is known as the **Exponentially Weighted Moving average** (EWMA). This fitted average is also called <span class="in">`level`</span> because this method does not allow for trends or seasonality (and everything gets smoothed).</span>
<span id="cb69-1169"><a href="#cb69-1169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1170"><a href="#cb69-1170" aria-hidden="true" tabindex="-1"></a>EWMA smoothing begins by setting $S_0$ to $x_1$ (usually), where $S$ stands for smoothed observation (or EWMA), and $x$ for the observation. The subscript in $x$ refers to the time periods $t =1, 2, ... ,n$. For the second period, $S_2 = \alpha x_2 + (1-\alpha)x_1$ and so on. Here the parameter $\alpha$ is called the smoothing constant, the weight given to the current observation. A general formula is also available to compute the EWMA for any time period $t$. @fig-ewma shows the single exponential smoothing on the \$20 Notes series for $\alpha=0.5$. Instead of fixing an $\alpha$ value such as 0.5, we may leave it to the software to find an optimum value.</span>
<span id="cb69-1171"><a href="#cb69-1171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1174"><a href="#cb69-1174" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1175"><a href="#cb69-1175" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1176"><a href="#cb69-1176" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb69-1177"><a href="#cb69-1177" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-ewma</span></span>
<span id="cb69-1178"><a href="#cb69-1178" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Single exponential smoothing (fits)"</span></span>
<span id="cb69-1179"><a href="#cb69-1179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1180"><a href="#cb69-1180" aria-hidden="true" tabindex="-1"></a>single.exp <span class="ot">&lt;-</span> NZnotes20 <span class="sc">|&gt;</span> <span class="fu">ses</span>(<span class="at">alpha=</span><span class="fl">0.5</span>) <span class="sc">|&gt;</span> <span class="fu">fitted</span>()</span>
<span id="cb69-1181"><a href="#cb69-1181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1182"><a href="#cb69-1182" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">autoplot</span>(NZnotes20) <span class="sc">+</span> </span>
<span id="cb69-1183"><a href="#cb69-1183" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autolayer</span>(single.exp, <span class="at">series =</span><span class="st">"alpha=0.5"</span>)</span>
<span id="cb69-1184"><a href="#cb69-1184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1185"><a href="#cb69-1185" aria-hidden="true" tabindex="-1"></a>single.exp1 <span class="ot">&lt;-</span> NZnotes20 <span class="sc">|&gt;</span> <span class="fu">ses</span>() <span class="sc">|&gt;</span> <span class="fu">fitted</span>()</span>
<span id="cb69-1186"><a href="#cb69-1186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1187"><a href="#cb69-1187" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">autoplot</span>(NZnotes20) <span class="sc">+</span> </span>
<span id="cb69-1188"><a href="#cb69-1188" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autolayer</span>(single.exp1, <span class="at">series =</span> <span class="st">"optimised alpha"</span>)</span>
<span id="cb69-1189"><a href="#cb69-1189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1190"><a href="#cb69-1190" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb69-1191"><a href="#cb69-1191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1192"><a href="#cb69-1192" aria-hidden="true" tabindex="-1"></a>p1<span class="sc">/</span>p2</span>
<span id="cb69-1193"><a href="#cb69-1193" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1194"><a href="#cb69-1194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1195"><a href="#cb69-1195" aria-hidden="true" tabindex="-1"></a>The rate at which the effect of older observations on the current EWMA will be dampened depends on $\alpha$, the smoothing constant. Larger the $\alpha$ value, faster the dampening effect of older observations.</span>
<span id="cb69-1196"><a href="#cb69-1196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1197"><a href="#cb69-1197" aria-hidden="true" tabindex="-1"></a>A naive choice for the initial value for $S_0$ (i.e. at the origin) is $x_1$, the first observation. The other choices include the average of two or more successive observations, estimating using regression methods etc. In this course we will not be concerned with the choice of the initial values very much (and accept the defaults of the <span class="in">`R`</span> packages).</span>
<span id="cb69-1198"><a href="#cb69-1198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1199"><a href="#cb69-1199" aria-hidden="true" tabindex="-1"></a><span class="fu">## Double Exponential Smoothing</span></span>
<span id="cb69-1200"><a href="#cb69-1200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1201"><a href="#cb69-1201" aria-hidden="true" tabindex="-1"></a>Single exponential smoothing is improved to **double exponential smoothing** to account for the trend type of variations. This is achieved by introducing a second smoothing constant say $\beta$. This weighting constant captures linear trends using the successive differences in the fitted EWMAs. The process of double exponential smoothing is conveniently represented by the following two equations.</span>
<span id="cb69-1202"><a href="#cb69-1202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1203"><a href="#cb69-1203" aria-hidden="true" tabindex="-1"></a>$S_t = \alpha X_t+(1-\alpha)<span class="co">[</span><span class="ot">S_{t-1} + T_{t-1}</span><span class="co">]</span>$ (called level equation)</span>
<span id="cb69-1204"><a href="#cb69-1204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1205"><a href="#cb69-1205" aria-hidden="true" tabindex="-1"></a>where</span>
<span id="cb69-1206"><a href="#cb69-1206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1207"><a href="#cb69-1207" aria-hidden="true" tabindex="-1"></a>$T_t =\beta <span class="co">[</span><span class="ot">S_t - S_{t-1}</span><span class="co">]</span> + (1 -\beta)T_{t-1}$ (called trend equation).</span>
<span id="cb69-1208"><a href="#cb69-1208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1209"><a href="#cb69-1209" aria-hidden="true" tabindex="-1"></a>The second equation for the trend EWMA gives a weight of $\beta$ to the current differences in the EWMAs (i.e. $S_t - S_{t-1}$) and the balance weight $(1-\beta)$ to the preceding trend EWMA.</span>
<span id="cb69-1210"><a href="#cb69-1210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1211"><a href="#cb69-1211" aria-hidden="true" tabindex="-1"></a>The main or usual EWMA (i.e. $S_t$) gives a weight of $\alpha$ to the current observation and the balance weight $(1-\alpha)$ to the sum of preceding main and trend EWMAs (i.e. $S_{t-1} + T_{t-1}$). A naive choice for the initial value for $T_0$ (i.e. at the origin) is $x_2-x_1$, the difference between the first and the second observations. The other choices include the average of two or more successive differences, estimating using regression methods etc. In this course we will not be concerned with the choice of the initial values very much. The smoothing constants $\alpha$ and $\beta$ are obtained by non-linear optimisation methods (such as the Marquardt algorithm). In this course, we will just accept the <span class="in">`R`</span> outputs as the optimised fits. @fig-dewma shows the double exponential smoothing on the \$20 Notes series with optimum $\alpha$ and $\beta$ (as determined by the <span class="in">`forecast`</span> package).</span>
<span id="cb69-1212"><a href="#cb69-1212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1215"><a href="#cb69-1215" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1216"><a href="#cb69-1216" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1217"><a href="#cb69-1217" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb69-1218"><a href="#cb69-1218" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-dewma</span></span>
<span id="cb69-1219"><a href="#cb69-1219" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Double exponential smoothing"</span></span>
<span id="cb69-1220"><a href="#cb69-1220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1221"><a href="#cb69-1221" aria-hidden="true" tabindex="-1"></a>double.exp <span class="ot">&lt;-</span> NZnotes20 <span class="sc">|&gt;</span> <span class="fu">holt</span>() <span class="sc">|&gt;</span> <span class="fu">fitted</span>()</span>
<span id="cb69-1222"><a href="#cb69-1222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1223"><a href="#cb69-1223" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(NZnotes20) <span class="sc">+</span> </span>
<span id="cb69-1224"><a href="#cb69-1224" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autolayer</span>(double.exp, <span class="at">series =</span> <span class="st">"DEWMA-optimised"</span>)</span>
<span id="cb69-1225"><a href="#cb69-1225" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1226"><a href="#cb69-1226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1227"><a href="#cb69-1227" aria-hidden="true" tabindex="-1"></a><span class="fu">## Triple Exponential Smoothing</span></span>
<span id="cb69-1228"><a href="#cb69-1228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1229"><a href="#cb69-1229" aria-hidden="true" tabindex="-1"></a>This approach developed by Holt and Winter (hence the name **Holts-Winter (HW) smoothing**) employs a level equation, a trend equation, and a seasonal equation for smoothing at each time period. Hence three weights, or smoothing parameters are needed.</span>
<span id="cb69-1230"><a href="#cb69-1230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1231"><a href="#cb69-1231" aria-hidden="true" tabindex="-1"></a>$S_t = \alpha(X_t-P_{t-p}) + (1-\alpha)<span class="co">[</span><span class="ot">S_{t-1}+T_{t-1}</span><span class="co">]</span>$ (level equation)\</span>
<span id="cb69-1232"><a href="#cb69-1232" aria-hidden="true" tabindex="-1"></a>$T_t = \beta <span class="co">[</span><span class="ot">S_t-S_{t-1}</span><span class="co">]</span>+ 1-\beta)T_{t-1}$ (trend equation)\</span>
<span id="cb69-1233"><a href="#cb69-1233" aria-hidden="true" tabindex="-1"></a>$P_t = \phi (X_t-S_t)+(1-\phi)P_{t-p}$ (seasonal equation of a given period $p$)</span>
<span id="cb69-1234"><a href="#cb69-1234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1235"><a href="#cb69-1235" aria-hidden="true" tabindex="-1"></a>The smoothing parameters $\alpha$, $\beta$, and $\phi$ are constants and are usually estimated minimising the MSE. In order to proceed with the triple exponential smoothing, we need at least one complete season's data to determine initial estimates of the seasonal indices. For estimating the trend components, it is preferable to have at least two complete season's data.</span>
<span id="cb69-1236"><a href="#cb69-1236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1237"><a href="#cb69-1237" aria-hidden="true" tabindex="-1"></a>The initial trend is usually estimated using the average differences in the corresponding observations in two adjacent seasons. The estimating initial values for seasonal components, we use the averages rather than differences. Regression methods are also employed for estimating the initial values. In this course, we will not study the estimation methods for initial values in any detail but will accept computations and optimisation reported in the <span class="in">`forecast`</span> R package. @fig-tewma shows the triple exponential smoothing to the outstanding credit card balances series.</span>
<span id="cb69-1238"><a href="#cb69-1238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1241"><a href="#cb69-1241" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1242"><a href="#cb69-1242" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1243"><a href="#cb69-1243" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb69-1244"><a href="#cb69-1244" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-tewma</span></span>
<span id="cb69-1245"><a href="#cb69-1245" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Triple exponential smoothing"</span></span>
<span id="cb69-1246"><a href="#cb69-1246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1247"><a href="#cb69-1247" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(forecast)</span>
<span id="cb69-1248"><a href="#cb69-1248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1249"><a href="#cb69-1249" aria-hidden="true" tabindex="-1"></a>trp.exp <span class="ot">&lt;-</span> credit.balance <span class="sc">|&gt;</span> <span class="fu">hw</span>() <span class="sc">|&gt;</span> <span class="fu">fitted</span>()</span>
<span id="cb69-1250"><a href="#cb69-1250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1251"><a href="#cb69-1251" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(credit.balance) <span class="sc">+</span></span>
<span id="cb69-1252"><a href="#cb69-1252" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autolayer</span>(trp.exp, </span>
<span id="cb69-1253"><a href="#cb69-1253" aria-hidden="true" tabindex="-1"></a>            <span class="at">series =</span> <span class="st">"Holt-Winter- optimised"</span>)</span>
<span id="cb69-1254"><a href="#cb69-1254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1255"><a href="#cb69-1255" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1256"><a href="#cb69-1256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1257"><a href="#cb69-1257" aria-hidden="true" tabindex="-1"></a><span class="fu">## Assessment of Fit:</span></span>
<span id="cb69-1258"><a href="#cb69-1258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1259"><a href="#cb69-1259" aria-hidden="true" tabindex="-1"></a>Forecast accuracy measures such as MSE are useful for fixing the smoothing parameters such as the moving average length or the EWMA smoothing constant. We may minimise MSE (say) to fix a value for the EWMA smoothing constant. This can be done by trial and error or by nonlinear optimisation methods (such as Marquardt's procedure).</span>
<span id="cb69-1260"><a href="#cb69-1260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1261"><a href="#cb69-1261" aria-hidden="true" tabindex="-1"></a>By the term **forecasting**, we mean projecting the present time series for future time points. For example, assume that we used an uncentered two period moving average to smooth the '\$20 Notes' time series. The moving average value (non-centred) for 1969 is 18.05. A *naive* approach to forecasting will be to use the smoothed value at time $(t-1)$ to forecast for time $t$. Hence the forecasted value (or simply forecast) of \$20 bills for 1970 would be 18.05 as against the actual observed value of 21.76. In the absence of Year 1970 data, the same value 18.05 would be the forecast for 1971 and so on. MAs are not useful for forecasting in general and hence this average is just employed to fit trends or extract trends when seasonal variation is absent.</span>
<span id="cb69-1262"><a href="#cb69-1262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1263"><a href="#cb69-1263" aria-hidden="true" tabindex="-1"></a>For EWMA Forecasting, the forecast approach is to add an adjustment for the error that occurred in the last forecast. We again consider '\$20 Notes' time series and obtain the EWMA smoothed values for $\alpha = 0.4$. For the year 1969 (say), the EWMA value is 17.78 as against the actual value 19.41 giving an error of 19.41- 17.78= 2.72. This error is given a weight of 0.4 and added to the 1969 forecast (naive estimate) of 16.69 as $16.69+0.4\times2.72$ giving a forecast value of 17.78 for 1970. The term 'adjustment error' will refer to $0.4\times2.72 = 1.088$. This forecast value is also obtained as</span>
<span id="cb69-1264"><a href="#cb69-1264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1265"><a href="#cb69-1265" aria-hidden="true" tabindex="-1"></a>Forecast for $1970 = 0.4\times19.41+0.6\times16.69= 17.78$.</span>
<span id="cb69-1266"><a href="#cb69-1266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1267"><a href="#cb69-1267" aria-hidden="true" tabindex="-1"></a>(from the relationship $S_{t+1}=\alpha x_{t+1}+(1-\alpha)S_t$ where the unavailable value $X_{t+1}$ is replaced by the naive estimate $X_t$). This forecasting approach is also not useful in the presence of trend etc. Hence only a forecast of one time period ahead is usually done. For forecasting two or more time periods ahead, methods such as double and triple exponential smoothing are more useful.</span>
<span id="cb69-1268"><a href="#cb69-1268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1269"><a href="#cb69-1269" aria-hidden="true" tabindex="-1"></a>If we perform the double exponential forecasting for some $m$ periods ahead from a point at time $t$, the trend part of EWMA, $T_t$, will be added $m$ times to the naive level estimate $S_t$. As shown in @fig-dewmaf, the double exponential smoothing approach provides no nonsense forecasts compared to the naive single exponential forecasts in the presence of trends. The fit/forecast quality measures such as the MSE, MAD etc will also be smaller for the double exponential smoothing in the presence of trends.</span>
<span id="cb69-1270"><a href="#cb69-1270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1273"><a href="#cb69-1273" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1274"><a href="#cb69-1274" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1275"><a href="#cb69-1275" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb69-1276"><a href="#cb69-1276" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-dewmaf</span></span>
<span id="cb69-1277"><a href="#cb69-1277" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Double and triple exponential forecasts for credit balance data"</span></span>
<span id="cb69-1278"><a href="#cb69-1278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1279"><a href="#cb69-1279" aria-hidden="true" tabindex="-1"></a>holt1 <span class="ot">&lt;-</span> <span class="fu">holt</span>(credit.balance)</span>
<span id="cb69-1280"><a href="#cb69-1280" aria-hidden="true" tabindex="-1"></a>holt2 <span class="ot">&lt;-</span> <span class="fu">hw</span>(credit.balance)</span>
<span id="cb69-1281"><a href="#cb69-1281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1282"><a href="#cb69-1282" aria-hidden="true" tabindex="-1"></a>p0 <span class="ot">&lt;-</span> forecast<span class="sc">::</span><span class="fu">autoplot</span>(<span class="fu">window</span>(credit.balance, <span class="at">start=</span><span class="dv">2012</span>)) <span class="sc">+</span> </span>
<span id="cb69-1283"><a href="#cb69-1283" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="dv">2012</span>, <span class="dv">2025</span>) <span class="sc">+</span> <span class="fu">ylim</span>(<span class="dv">4500</span>,<span class="dv">7000</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">""</span>)</span>
<span id="cb69-1284"><a href="#cb69-1284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1285"><a href="#cb69-1285" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> p0 <span class="sc">+</span> <span class="fu">autolayer</span>(holt1, <span class="at">series =</span> <span class="st">"Double exponential"</span>)</span>
<span id="cb69-1286"><a href="#cb69-1286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1287"><a href="#cb69-1287" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> p0 <span class="sc">+</span> <span class="fu">autolayer</span>(holt2, <span class="at">series =</span> <span class="st">"Triple exponential"</span>)</span>
<span id="cb69-1288"><a href="#cb69-1288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1289"><a href="#cb69-1289" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb69-1290"><a href="#cb69-1290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1291"><a href="#cb69-1291" aria-hidden="true" tabindex="-1"></a>p1<span class="sc">/</span>p2</span>
<span id="cb69-1292"><a href="#cb69-1292" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1293"><a href="#cb69-1293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1294"><a href="#cb69-1294" aria-hidden="true" tabindex="-1"></a>The forecast accuracy measures can also be obtained using the accuracy() function in the forecast package. This function also give a few other accuracy measures. For the credit card balances data, we obtain-</span>
<span id="cb69-1295"><a href="#cb69-1295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1296"><a href="#cb69-1296" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE}</span></span>
<span id="cb69-1297"><a href="#cb69-1297" aria-hidden="true" tabindex="-1"></a><span class="fu">bind_cols</span>(</span>
<span id="cb69-1298"><a href="#cb69-1298" aria-hidden="true" tabindex="-1"></a>  <span class="at">Method =</span> <span class="fu">c</span>(</span>
<span id="cb69-1299"><a href="#cb69-1299" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Double exponential smoothing"</span>,</span>
<span id="cb69-1300"><a href="#cb69-1300" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Triple exponential smoothing"</span></span>
<span id="cb69-1301"><a href="#cb69-1301" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb69-1302"><a href="#cb69-1302" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(</span>
<span id="cb69-1303"><a href="#cb69-1303" aria-hidden="true" tabindex="-1"></a>    <span class="fu">accuracy</span>(holt1)[,<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">5</span>)],</span>
<span id="cb69-1304"><a href="#cb69-1304" aria-hidden="true" tabindex="-1"></a>    <span class="fu">accuracy</span>(holt2)[,<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">5</span>)]</span>
<span id="cb69-1305"><a href="#cb69-1305" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb69-1306"><a href="#cb69-1306" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb69-1307"><a href="#cb69-1307" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1308"><a href="#cb69-1308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1309"><a href="#cb69-1309" aria-hidden="true" tabindex="-1"></a>Evidently the triple exponential smoothing fares well for our credit card balances data.</span>
<span id="cb69-1310"><a href="#cb69-1310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1311"><a href="#cb69-1311" aria-hidden="true" tabindex="-1"></a><span class="fu">## Intro to Autoregressive Modelling</span></span>
<span id="cb69-1312"><a href="#cb69-1312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1313"><a href="#cb69-1313" aria-hidden="true" tabindex="-1"></a>The concept of **stationarity** plays in important role for building time series models. In crude terms, a time series is said to be **stationary** if the mean and variance do not change over time (alternatively the same probability law applies over time). In fact stationarity is defined in a pure mathematical way but we will not worry about this in this course.</span>
<span id="cb69-1314"><a href="#cb69-1314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1315"><a href="#cb69-1315" aria-hidden="true" tabindex="-1"></a>A white noise series is defined as a series with a constant mean and variance, and the true mean and variance remain the same for all $t$. Normal random data is an example of white noise but the normal assumption is not required for a series to be white noise. You can also intuitively guess that a white noise series is stationary.</span>
<span id="cb69-1316"><a href="#cb69-1316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1317"><a href="#cb69-1317" aria-hidden="true" tabindex="-1"></a>A quick collection of EDA displays can be obtained using a single function ggtsdisplay() or tsdisplay() in <span class="in">`R`</span>. This display is shown for the white noise series in @fig-tsdispwn.</span>
<span id="cb69-1318"><a href="#cb69-1318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1321"><a href="#cb69-1321" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1322"><a href="#cb69-1322" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1323"><a href="#cb69-1323" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-tsdispwn</span></span>
<span id="cb69-1324"><a href="#cb69-1324" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "A summary plots for white noise"</span></span>
<span id="cb69-1325"><a href="#cb69-1325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1326"><a href="#cb69-1326" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb69-1327"><a href="#cb69-1327" aria-hidden="true" tabindex="-1"></a>wht.noise <span class="ot">&lt;-</span> <span class="fu">arima.sim</span>(<span class="fu">list</span>(<span class="at">order=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>)),<span class="dv">500</span>)</span>
<span id="cb69-1328"><a href="#cb69-1328" aria-hidden="true" tabindex="-1"></a><span class="fu">ggtsdisplay</span>(wht.noise)</span>
<span id="cb69-1329"><a href="#cb69-1329" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1330"><a href="#cb69-1330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1331"><a href="#cb69-1331" aria-hidden="true" tabindex="-1"></a>Time series modelling is not needed for a series such as this one. The above random series must be distinguished from a series whose autocorrelations are not decaying to zero or becoming significant frequently.</span>
<span id="cb69-1332"><a href="#cb69-1332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1333"><a href="#cb69-1333" aria-hidden="true" tabindex="-1"></a>A drifting random walk series is defined as $$X_t = \delta + X_{t-1} + W_t $$</span>
<span id="cb69-1334"><a href="#cb69-1334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1335"><a href="#cb69-1335" aria-hidden="true" tabindex="-1"></a>where $\delta$ is the constant drift, and $W_t$ is white noise which induces the random walk for the series. The mean function depends on $t$ for this series and hence not stationary. This is not of concern because we can model the drift and make the residuals stationary. The trick is to model the difference $X_{t} - X_{t-1}$ or just use the first lag $X_{t-1}$ as a predictor in the usual regression.</span>
<span id="cb69-1336"><a href="#cb69-1336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1339"><a href="#cb69-1339" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1340"><a href="#cb69-1340" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1341"><a href="#cb69-1341" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-tsdisprw</span></span>
<span id="cb69-1342"><a href="#cb69-1342" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "A summary plots for drifting random walk series"</span></span>
<span id="cb69-1343"><a href="#cb69-1343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1344"><a href="#cb69-1344" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb69-1345"><a href="#cb69-1345" aria-hidden="true" tabindex="-1"></a>rwd <span class="ot">&lt;-</span> <span class="fu">arima.sim</span>(<span class="fu">list</span>(<span class="at">order=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>)),<span class="dv">500</span>)</span>
<span id="cb69-1346"><a href="#cb69-1346" aria-hidden="true" tabindex="-1"></a><span class="fu">ggtsdisplay</span>(rwd)</span>
<span id="cb69-1347"><a href="#cb69-1347" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1348"><a href="#cb69-1348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1349"><a href="#cb69-1349" aria-hidden="true" tabindex="-1"></a>In @fig-tsdisprw, it should also be noted that the ACFs decay to zero which is a good thing when compared to the case where ACFs are not decaying to zero.</span>
<span id="cb69-1350"><a href="#cb69-1350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1351"><a href="#cb69-1351" aria-hidden="true" tabindex="-1"></a>$$X_t=\beta_0+\beta_1(\sin(\frac {2\pi}{12} t)+\beta_1(\cos(\frac {2\pi}{12} t)+\epsilon_t$$ The above model introduces a 12-period seasonal pattern using $\sin$ and $\cos$ functions (which are periodic). The time series EDA plots for this function is obtained below:</span>
<span id="cb69-1352"><a href="#cb69-1352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1355"><a href="#cb69-1355" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1356"><a href="#cb69-1356" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1357"><a href="#cb69-1357" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-tsdisptrig</span></span>
<span id="cb69-1358"><a href="#cb69-1358" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Seasonal series EDA plots"</span></span>
<span id="cb69-1359"><a href="#cb69-1359" aria-hidden="true" tabindex="-1"></a>t<span class="ot">=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">500</span></span>
<span id="cb69-1360"><a href="#cb69-1360" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb69-1361"><a href="#cb69-1361" aria-hidden="true" tabindex="-1"></a>Xt<span class="ot">=</span><span class="fu">sin</span>(t<span class="sc">*</span><span class="dv">2</span><span class="sc">*</span>pi<span class="sc">/</span><span class="dv">12</span>)<span class="sc">+</span><span class="fu">cos</span>(t<span class="sc">*</span><span class="dv">2</span><span class="sc">*</span>pi<span class="sc">/</span><span class="dv">12</span>)<span class="sc">+</span><span class="fu">rnorm</span>(<span class="dv">500</span>)</span>
<span id="cb69-1362"><a href="#cb69-1362" aria-hidden="true" tabindex="-1"></a><span class="fu">ggtsdisplay</span>(Xt)</span>
<span id="cb69-1363"><a href="#cb69-1363" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1364"><a href="#cb69-1364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1365"><a href="#cb69-1365" aria-hidden="true" tabindex="-1"></a>Note the periodical patterns in the EDA plots shown in @fig-tsdisptrig. Analysis of a time series using sine and cosine functions is known as <span class="in">`frequency domain`</span> approach and is popular in meteorology, chemistry and geophysics. Instead of using trigonometric functions, say if indicator variables are used to model seasonality, we stay within the <span class="in">`time domain`</span>. The autocovariance function in the time domain is analogous to the spectral density function in the frequency domain.</span>
<span id="cb69-1366"><a href="#cb69-1366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1367"><a href="#cb69-1367" aria-hidden="true" tabindex="-1"></a>Consider the model $$X_t=\alpha_1 X_{t-1}+ \alpha_2 X_{t-2}+ \dots + \alpha_p X_{t-p} + \epsilon_t$$</span>
<span id="cb69-1368"><a href="#cb69-1368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1369"><a href="#cb69-1369" aria-hidden="true" tabindex="-1"></a>This model is called the *auto-regressive model* of order $p$ and called the $AR(p)$ process. Under this model, we assume that the present value depends linearly on the immediate past values as well as a random error. Note that this model is very similar to the multiple regression model where the predictors are just the past values of the series. This $AR(p)$ series is stationary if the variance of the terms are finite. When $p = 1$ (the first-order process), the model is known as a Markov process. The EDA plots for random data from this process is shown in @fig-tsdispmk. @fig-tsdispp shows the $AR(3)$ process EDA plots. Note that the PACF shows a pattern matching the parameters set <span class="in">`ar= c(0.8, -0.7, .3)`</span>. The last PACF in an $AR(p)$ model accounts the excess autocorrelation at lag $p$ that is not accounted for by an $AR(p-1)$ model.</span>
<span id="cb69-1370"><a href="#cb69-1370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1373"><a href="#cb69-1373" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1374"><a href="#cb69-1374" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1375"><a href="#cb69-1375" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-tsdispmk</span></span>
<span id="cb69-1376"><a href="#cb69-1376" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "A typical Markov series EDA plots"</span></span>
<span id="cb69-1377"><a href="#cb69-1377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1378"><a href="#cb69-1378" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb69-1379"><a href="#cb69-1379" aria-hidden="true" tabindex="-1"></a>Xt <span class="ot">&lt;-</span> <span class="fu">arima.sim</span>(<span class="fu">list</span>(<span class="at">order=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>), <span class="at">ar=</span>.<span class="dv">6</span>), <span class="at">n=</span><span class="dv">500</span>)</span>
<span id="cb69-1380"><a href="#cb69-1380" aria-hidden="true" tabindex="-1"></a><span class="fu">ggtsdisplay</span>(Xt)</span>
<span id="cb69-1381"><a href="#cb69-1381" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1382"><a href="#cb69-1382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1385"><a href="#cb69-1385" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1386"><a href="#cb69-1386" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1387"><a href="#cb69-1387" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-tsdispp</span></span>
<span id="cb69-1388"><a href="#cb69-1388" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "A typical AR(p=3)  series EDA plots"</span></span>
<span id="cb69-1389"><a href="#cb69-1389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1390"><a href="#cb69-1390" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb69-1391"><a href="#cb69-1391" aria-hidden="true" tabindex="-1"></a>Xt <span class="ot">&lt;-</span> <span class="fu">arima.sim</span>(<span class="fu">list</span>(<span class="at">order=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">0</span>,<span class="dv">0</span>), <span class="at">ar=</span> <span class="fu">c</span>(<span class="fl">0.8</span>, <span class="sc">-</span><span class="fl">0.7</span>, .<span class="dv">3</span>)), <span class="at">n=</span><span class="dv">500</span>)</span>
<span id="cb69-1392"><a href="#cb69-1392" aria-hidden="true" tabindex="-1"></a><span class="fu">ggtsdisplay</span>(Xt)</span>
<span id="cb69-1393"><a href="#cb69-1393" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1394"><a href="#cb69-1394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1395"><a href="#cb69-1395" aria-hidden="true" tabindex="-1"></a>The *moving average process* for <span class="in">`errors`</span> is defined by the following equation. $$X_t=\beta_0 z_{t}+ \beta_1 z_{t-1}+ \dots + \beta_q z_{t-q}$$ Note that $X_t$ is modelled with errors $z_1$, $z_2$,..., whose means are assumed to be zero and constant variance. The $\beta$s are coefficients of the model and $q$ is the order. The mean of this $MA(q)$ process is zero but we can always add some mean $\mu$ which will not affect the properties such as ACFs. The basic idea behind the $MA(q)$ process is that the current value of the response is due to variety of current and past unpredictable random events. It is proved that the moving average process is a stationary process and that the ACFs at lags greater than $q$ are zero. @fig-tsdispma1 and @fig-tsdispma3 show the basic EDA plots for the $MA(1)$ and $MA(3)$ processes.</span>
<span id="cb69-1396"><a href="#cb69-1396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1399"><a href="#cb69-1399" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1400"><a href="#cb69-1400" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1401"><a href="#cb69-1401" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-tsdispma1</span></span>
<span id="cb69-1402"><a href="#cb69-1402" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "EDA plots of a typical MA(1) process"</span></span>
<span id="cb69-1403"><a href="#cb69-1403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1404"><a href="#cb69-1404" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb69-1405"><a href="#cb69-1405" aria-hidden="true" tabindex="-1"></a>Xt <span class="ot">&lt;-</span> <span class="fu">arima.sim</span>(<span class="fu">list</span>(<span class="at">order=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>), <span class="at">ma=</span>.<span class="dv">6</span>), <span class="at">n=</span><span class="dv">500</span>)</span>
<span id="cb69-1406"><a href="#cb69-1406" aria-hidden="true" tabindex="-1"></a><span class="fu">ggtsdisplay</span>(Xt)</span>
<span id="cb69-1407"><a href="#cb69-1407" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1408"><a href="#cb69-1408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1411"><a href="#cb69-1411" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1412"><a href="#cb69-1412" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1413"><a href="#cb69-1413" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-tsdispma3</span></span>
<span id="cb69-1414"><a href="#cb69-1414" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "EDA plots of a typical MA(3) process"</span></span>
<span id="cb69-1415"><a href="#cb69-1415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1416"><a href="#cb69-1416" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb69-1417"><a href="#cb69-1417" aria-hidden="true" tabindex="-1"></a>Xt <span class="ot">&lt;-</span> <span class="fu">arima.sim</span>(<span class="fu">list</span>(<span class="at">order=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">3</span>), <span class="at">ma=</span><span class="fu">c</span>(.<span class="dv">3</span>, .<span class="dv">1</span>, <span class="sc">-</span>.<span class="dv">4</span>)), <span class="at">n=</span><span class="dv">500</span>)</span>
<span id="cb69-1418"><a href="#cb69-1418" aria-hidden="true" tabindex="-1"></a><span class="fu">ggtsdisplay</span>(Xt)</span>
<span id="cb69-1419"><a href="#cb69-1419" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1420"><a href="#cb69-1420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1421"><a href="#cb69-1421" aria-hidden="true" tabindex="-1"></a>**ARMA Model**</span>
<span id="cb69-1422"><a href="#cb69-1422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1423"><a href="#cb69-1423" aria-hidden="true" tabindex="-1"></a>The term $ARMA(p, q)$ model refers to the following equation that combines both the $AR(p)$ and $MA(q)$ models.</span>
<span id="cb69-1424"><a href="#cb69-1424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1425"><a href="#cb69-1425" aria-hidden="true" tabindex="-1"></a>$$X_t=\alpha_1 X_{t-1}+ \alpha_2 X_{t-2}+ \dots + \alpha_p X_{t-p} + \beta_o z_{t}+ \beta_1 z_{t-1}+ \dots + \beta_q z_{t-q}$$ It is easy to see that the term $\epsilon_t$ in the $AR(p)$ model is replaced or expanded with the $MA(q)$ model. You may wonder why to have such a complicated model. In fact the ARMA model requires fewer parameters than using just $MA(q)$ or $AR(p)$ model. $ARMA(p, q)$ model is a stationary model. @fig-tsdisparima shows the EDA plots for the simulated series from the $ARMA(2,2)$ process; note the constants fixed under the <span class="in">`ar`</span> and <span class="in">`ma`</span> parts of the <span class="in">`arima.sim`</span> function and compare the ACF and PACF plots.</span>
<span id="cb69-1426"><a href="#cb69-1426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1429"><a href="#cb69-1429" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1430"><a href="#cb69-1430" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1431"><a href="#cb69-1431" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-tsdisparima</span></span>
<span id="cb69-1432"><a href="#cb69-1432" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "EDA plots of a typical MA(3) process"</span></span>
<span id="cb69-1433"><a href="#cb69-1433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1434"><a href="#cb69-1434" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb69-1435"><a href="#cb69-1435" aria-hidden="true" tabindex="-1"></a>Xt <span class="ot">&lt;-</span> <span class="fu">arima.sim</span>(<span class="fu">list</span>(<span class="at">order=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">2</span>), <span class="at">ar=</span><span class="fu">c</span>(.<span class="dv">5</span>, <span class="sc">-</span>.<span class="dv">3</span>), <span class="at">ma=</span><span class="fu">c</span>(.<span class="dv">3</span>, .<span class="dv">1</span>)), <span class="at">n=</span><span class="dv">500</span>)</span>
<span id="cb69-1436"><a href="#cb69-1436" aria-hidden="true" tabindex="-1"></a><span class="fu">ggtsdisplay</span>(Xt)</span>
<span id="cb69-1437"><a href="#cb69-1437" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1438"><a href="#cb69-1438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1439"><a href="#cb69-1439" aria-hidden="true" tabindex="-1"></a>**Fitting ARMA model** Fitting an AR model can be done approximately using the multiple regression approach. If we use the sample mean $\bar{X}$ to estimate the mean $\mu$ of the process, the AR model becomes the multiple regression model with lags as predictors. However we cannot take the same approach to fitting ARMA models and we need to employ nonlinear optimisation methods.</span>
<span id="cb69-1440"><a href="#cb69-1440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1441"><a href="#cb69-1441" aria-hidden="true" tabindex="-1"></a>After fitting the ARMA model, we perform diagnostics of the fitted model. Here we explore the residuals of the fitted model for randomness and periodicity. In order to avoid *over fitting*, we will also examine the standard errors of the fitted coefficients. The need for transformations such the logarithm or the square root will also be indicated by the residuals.</span>
<span id="cb69-1442"><a href="#cb69-1442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1443"><a href="#cb69-1443" aria-hidden="true" tabindex="-1"></a>If the residuals are found to be nonstationary (often the case), we opt for differencing of the series. We have briefly seen that differencing can bring stationarity to a drifting process. Formally, the first difference $X_t-X_{t-1}$ is denoted as $\bigtriangledown X_t$. If we perform the differencing of the differences, we obtain $\bigtriangledown^2 X_t$ and so on. In order to bring stationarity to residuals, we may do differencing $d$ times. We then fit the model to $\bigtriangledown^2 X_t$ instead of $X_t$. This model is known as an autoregressive integrated moving average (ARIMA) model and denoted as $ARIMA(p, d, q)$. The term "integrated" means that the stationary model that was fitted based on the differenced data has to be summed (or "integrated") to provide a model for the original data.</span>
<span id="cb69-1444"><a href="#cb69-1444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1445"><a href="#cb69-1445" aria-hidden="true" tabindex="-1"></a>The ARIMA model is further generalised to seasonal ARIMA (SARIMA) model. The AR part for seasons (parameter P), differencing part (D) and the MA part (Q) form part of the $SARIMA(p,d,q ,P, D, Q)$. This topic is covered in higher level courses.</span>
<span id="cb69-1446"><a href="#cb69-1446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1447"><a href="#cb69-1447" aria-hidden="true" tabindex="-1"></a>Building good ARIMA models of @boxgenkins generally requires a reasonable amount of experience compared to building models to cross-section data. **In this course you are expected not to build ARIMA models** (no exam questions). But it should not be too hard to recognise the situations such as seasonality in the data series using EDA tools.</span>
<span id="cb69-1448"><a href="#cb69-1448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1449"><a href="#cb69-1449" aria-hidden="true" tabindex="-1"></a>The <span class="in">`R`</span> package *forecast* has a convenient function called <span class="in">`auto.arima`</span> which can quickly fit an ARIMA model. This is just an initial model which must be improved further. For the credit balance data, we obtain the following output:</span>
<span id="cb69-1450"><a href="#cb69-1450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1453"><a href="#cb69-1453" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1454"><a href="#cb69-1454" aria-hidden="true" tabindex="-1"></a><span class="fu">auto.arima</span>(credit.balance)</span>
<span id="cb69-1455"><a href="#cb69-1455" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1456"><a href="#cb69-1456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1457"><a href="#cb69-1457" aria-hidden="true" tabindex="-1"></a>This package can also generate forecasts easily, see @fig-creditfcast. This plot also shows the confidence bands for the forecasts.</span>
<span id="cb69-1458"><a href="#cb69-1458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1461"><a href="#cb69-1461" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb69-1462"><a href="#cb69-1462" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb69-1463"><a href="#cb69-1463" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-creditfcast</span></span>
<span id="cb69-1464"><a href="#cb69-1464" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Forecasts for credit balance series"</span></span>
<span id="cb69-1465"><a href="#cb69-1465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1466"><a href="#cb69-1466" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">auto.arima</span>(credit.balance)</span>
<span id="cb69-1467"><a href="#cb69-1467" aria-hidden="true" tabindex="-1"></a>forecast<span class="sc">::</span><span class="fu">autoplot</span>(<span class="fu">forecast</span>(fit,<span class="at">h=</span><span class="dv">24</span>))</span>
<span id="cb69-1468"><a href="#cb69-1468" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb69-1469"><a href="#cb69-1469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1470"><a href="#cb69-1470" aria-hidden="true" tabindex="-1"></a><span class="fu"># Summary</span></span>
<span id="cb69-1471"><a href="#cb69-1471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1472"><a href="#cb69-1472" aria-hidden="true" tabindex="-1"></a>Regression methods are the most commonly used of statistics techniques. The main aim is to fit a model by least squares to explain the variation in the response variable $Y$ by using one or more explanatory variables $X_1$, $X_2$, ... , $X_k$. The correlation coefficient $r_{xy}$ measures the strength of the linear relationship between $Y$ and $X$; $R^{2}$ measures the strength of the linear relationship between $Y$ and $X_1$, $X_2$, ... , $X_k$. When $k$=1, then $r_{xy}^{2} =R^{2}$. Scatter plots and correlation coefficients provide important clues to the inter-relationships between the variables.</span>
<span id="cb69-1473"><a href="#cb69-1473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1474"><a href="#cb69-1474" aria-hidden="true" tabindex="-1"></a>In building up a model by adding new variables, the correlation (or overlap) with $y$ is important but the correlations between a new explanatory variable and each of the existing explanatory variables also determine how effective the addition of the variable will be.</span>
<span id="cb69-1475"><a href="#cb69-1475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1476"><a href="#cb69-1476" aria-hidden="true" tabindex="-1"></a>Stepwise regression procedures identify potentially good regression models by repeatedly comparing an existing model with other models in which an explanatory variable has been either deleted or added, using some criterion such as significance of the deleted or added term (as measured by the $p$-value of the relevant $t$ or $F$ statistic) or the AIC of the model. Polynomial regression models employ the square, cube etc terms of the original variables as additional predictors.</span>
<span id="cb69-1477"><a href="#cb69-1477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1478"><a href="#cb69-1478" aria-hidden="true" tabindex="-1"></a>When at least two explanatory variables are highly correlated, we have multicollinear data. The effect is that the variance of least square estimators will be inflated rendering the coefficients insignificant and hence we may need to discard one or more of the highly correlated variables.</span>
<span id="cb69-1479"><a href="#cb69-1479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-1480"><a href="#cb69-1480" aria-hidden="true" tabindex="-1"></a>EDA plots of residuals help to answer the question as to whether the fit is good or whether a transformation may help or whether other variables (including square, cubic etc) should be added. If residuals are plotted against fitted $Y$ or $X$ variables no discernible pattern should be observed. Estimated regression coefficients may be affected by leverage points, and hence influence diagnostics are performed.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>