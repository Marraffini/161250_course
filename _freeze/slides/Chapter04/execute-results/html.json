{
  "hash": "68b835cd637c19bc354fa4d4772f03d5",
  "result": {
    "markdown": "---\ntitle: \"Chapter 4:<br>Introduction to Statistical Inference\"\nimage: img/inference.png\nformat: \n  revealjs:\n    width: 1050\n    height:\t700\n    scrollable: true\n    transition: fade\n    theme: [default, myquarto.scss]\n    slide-number: c/t  \n    logo: img/L_Color.png\n    footer: \"[161250 Data Analysis](https://anhsmith.github.io/161250/slides.html)\"\n    styles:\n      - revealjs.dark:\n        background-color: #222\n        color: #fff\n    \nexecute:\n  echo: true\neditor: \n  markdown: \n    wrap: 72\n---\n\n::: {.cell}\n\n:::\n\n\n# Statistical Inference {.background-black}\n\n> “A statistical analysis, properly conducted, is a delicate dissection of uncertainties, a surgery of suppositions.”\n>\n> — M.J. Moroney\n\n\n## Statistical Inference\n\n::::{.columns}\n\n:::{.column width=\"65%\"}\n\nThe term *statistical inference* means that we are using properties of a sample to make statements about the population from which the sample was drawn. \n\nFor example, say you wanted to know the mean length of the leaves on a tree ($\\mu$). You wouldn't want to (nor need to) measure every single leaf! You would take a random sample of leaves and measure their lengths ($x_i$), calculate the sample mean ($\\bar x$), and use $\\bar x$ as an estimate of $\\mu$.\n\n:::\n\n:::{.column width=\"35%\"}\n\n![](img/sampling_variation2.gif)\n\n:::\n\n::::\n\n\n## Statistical Inference for a Population Mean\n\n::::{.columns}\n\n:::{.column width=\"60%\"}\n\nConsider a population $X$ with mean $\\mu$,\\\nvariance $\\text{Var}(X)=\\sigma^2$, and\\\nstandard deviation $\\sigma$.\n\nWe can estimate $\\mu$ by: \n\n- taking a random sample of values $\\{x_1, x_2, ..., x_n\\}$ from the population, $X$, and\n- calculating the sample mean $\\bar x = \\frac 1 n \\sum_{i=1}^{n}x_i$.\n\n\n:::\n\n:::{.column width=\"40%\"}\n\n![](img/inference.png)\n\n:::\n\n::::\n\nImportantly:\n\n- The sample mean $\\bar x$ is a single draw from a random variable $\\bar X$. It will never be exactly equal to the population mean, $\\mu$, unless you measure every single leaf. \n- There is ***uncertainty*** in our estimate of $\\mu$. Each sample yields a different $\\bar x$. This is called ***sampling error***. \n\n\n## Sampling Variation\n\n![](img/samp_dist.gif)\n\n## Sampling Error\n\nThe variability of the sample means from sample to sample, $\\text{Var}(\\bar X)$, depends on two things: \n\n- the variability of the population values, $\\text{Var}(x)$, and \n- the size of the sample, $n$.\n\nThe variability of the sample estimate of a parameter is usually expressed as a ***standard error*** (SE), which is simply the theoretical standard deviation of $\\bar X$ from sample to sample.\n\nThe equation is surprisingly simple!\n\n$\\text{Var}(\\bar X) = \\text{Var}(X)/n$\n\n$\\text{SE}(\\bar X) = \\text{SD}(\\bar X) = \\sigma/\\sqrt n$\n\n\n## Quetelet's dataset\n\n::::{.columns}\n\n:::{.column width=\"70%\"}\n\nIn 1846, a Belgian scholar Adolphe Quetelet published an analysis of the chest sizes of a full population of 5,738 Scottish soldiers.\n\nThe distribution of the measurements (in inches) in his database has a mean of $\\mu$ = 39.83 inches, a standard deviation of $\\sigma$ = 2.05 inches, and is well approximated by a normal distribution.\n\n:::\n\n:::{.column width=\"30%\"}\n\n![Adolphe Quetelet<br>1796-1874](img/quetelet_face.jpg)\n:::\n\n::::\n\n\n::: {.cell layout-align=\"center\" output-location='column'}\n\n```{.r .cell-code}\nqd <- tibble(\n  Chest = 33:48, \n  Count = c(3, 18, 81, 185, 420, 749, 1073, 1079, \n            934, 658, 370, 92, 50, 21, 4, 1),\n  Prob = Count / sum(Count)\n  )\n\nqd |> \n  ggplot() +\n  aes(x = Chest, y = Count) +\n  geom_col() +\n  xlab(\"\") + ylab(\"\") +\n  ggtitle(\"Chest circumferences of Scottish soldiers\")\n```\n\n::: {.cell-output-display}\n![](Chapter04_files/figure-revealjs/unnamed-chunk-1-1.png){fig-align='center' width=480}\n:::\n:::\n\n\n\n\n## Quetelet's dataset\n\nEvery soldier was measured so we can treat this as the population, and $\\mu$ = 39.83 and $\\sigma$ = 2.05 as population parameters. Let's take some samples of size $n$ = 6 from this population.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Convert to a long vector of values\nqd_long <- rep(qd$Chest, qd$Count)\n```\n:::\n\n\n::: {.fragment}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# A single sample\nsample(qd_long, size = 6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 43 41 38 41 42 40\n```\n:::\n:::\n\n\n:::\n\n::: {.fragment}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Ten samples\nmap(1:7, ~ sample(qd_long, size = 6))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] 39 37 39 40 42 43\n\n[[2]]\n[1] 37 42 42 41 39 40\n\n[[3]]\n[1] 34 38 41 41 40 38\n\n[[4]]\n[1] 41 34 40 40 42 37\n\n[[5]]\n[1] 40 42 39 42 36 41\n\n[[6]]\n[1] 41 38 39 42 40 40\n\n[[7]]\n[1] 39 39 39 40 40 41\n```\n:::\n:::\n\n\n:::\n\n## Quetelet's dataset\n\nEvery soldier was measured so we can treat this as the population, and $\\mu$ = 39.83 and $\\sigma$ = 2.05 as population parameters. Let's take some samples of size $n$ = 6 from this population.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Convert to a long vector of values\nqd_long <- rep(qd$Chest, qd$Count)\n```\n:::\n\n\n::: {.fragment}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Put ten samples in a tibble\nq_samples <- tibble( sample = as_factor(1:10) ) |> \n  mutate( \n    values = map(sample, ~ sample(qd_long, size = 6)) \n    ) |> \n  unnest()\n\nhead(q_samples, 15)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 × 2\n   sample values\n   <fct>   <int>\n 1 1          36\n 2 1          41\n 3 1          42\n 4 1          41\n 5 1          38\n 6 1          38\n 7 2          41\n 8 2          40\n 9 2          42\n10 2          36\n11 2          39\n12 2          41\n13 3          38\n14 3          38\n15 3          41\n```\n:::\n:::\n\n\n:::\n\n\n## Quetelet's dataset\n\nEvery soldier was measured so we can treat this as the population, and $\\mu$ = 39.83 and $\\sigma$ = 2.05 as population parameters. Let's take some samples of size $n$ = 6 from this population.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Convert to a long vector of values\nqd_long <- rep(qd$Chest, qd$Count)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Put ten samples in a tibble\nq_samples <- tibble( sample = as_factor(1:10) ) |> \n  mutate( \n    values = map(sample, ~ sample(qd_long, size = 6)) \n    ) |> \n  unnest()\n```\n:::\n\n\n\n::: {.fragment}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calculate means of each sample\nsample_means <- q_samples |> \n  group_by(sample) |> \n  summarise(mean = mean(values))\n\nsample_means\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 2\n   sample  mean\n   <fct>  <dbl>\n 1 1       40.3\n 2 2       39.3\n 3 3       40.2\n 4 4       38.8\n 5 5       40  \n 6 6       40  \n 7 7       38.3\n 8 8       41.5\n 9 9       40.2\n10 10      40.2\n```\n:::\n:::\n\n\n:::\n\n## Quetelet's dataset\n\n\n::::{.columns}\n\n:::{.column width=\"55%\"}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Make a function to do it all and plot\nplot_samples <- function(dat = qd_long,\n                         no_samples = 12,\n                         sample_size = 6) {\n\n  # Put samples in a tibble\n  q_samples <- tibble( \n    sample = as_factor(1:no_samples),\n    values = map(sample, ~ sample(dat, size = sample_size))\n    ) |> unnest()\n  \n  # Calculate means of each sample\n  sample_means <- q_samples |> group_by(sample) |> \n    summarise(mean = mean(values))\n  \n  ggplot() + \n    xlim(min(dat), max(dat)) +\n    geom_vline(xintercept = mean(dat), alpha = .4) +\n    geom_jitter(\n      data = q_samples,\n      mapping = aes(y = sample, x = values),\n      width = 0, height = 0.1, alpha = .8\n      ) + \n    geom_point(\n      data = sample_means,\n      mapping = aes(y = sample, x = mean),\n      shape = 15, size = 3, \n      colour = \"dark orange\"\n      ) +\n    ggtitle(paste(\"Sample size =\", sample_size))\n}\n```\n:::\n\n\n:::\n\n:::{.column width=\"45%\"}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_samples(sample_size = 6)\n```\n\n::: {.cell-output-display}\n![](Chapter04_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='center' width=480}\n:::\n:::\n\n\n:::\n::::\n\n## Sample means and sample sizes\n\n::::{.columns}\n\n:::{.column width=\"40%\"}\n\nLet's compare the distribution of means for different sample sizes *across the samples*.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_samples(sample_size = 3)\nplot_samples(sample_size = 5)\nplot_samples(sample_size = 10)\nplot_samples(sample_size = 20)\nplot_samples(sample_size = 50)\nplot_samples(sample_size = 100)\nplot_samples(sample_size = 200)\n```\n:::\n\n\n:::\n:::{.column width=\"60%\"}\n\n\n::: {.cell layout-align=\"center\" animation.hook='gifski'}\n::: {.cell-output-display}\n![](Chapter04_files/figure-revealjs/unnamed-chunk-13-.gif){fig-align='center' width=480}\n:::\n:::\n\n:::\n::::\n\nThe larger the $n$, the less the sample means vary.\n\n\n\n## Standard error\n\nIf is distributed as a normal random variable with mean $\\mu$ and variance $\\sigma^2$,\n\n$$X \\sim \\text{Normal}(\\mu, \\sigma)$$\n\nthen sample means of size $n$ are distributed as\n\n$$\\bar X \\sim \\text{Normal}(\\mu_\\bar{X} = \\mu, \\sigma_\\bar{X} = \\sigma/\\sqrt{n})$$\n$\\text{SE}(\\bar{X}) = \\sigma_\\bar{X}= \\sigma/\\sqrt{n})$ is known as the ***standard error of the sample mean***. \n\nMore generally, a standard error is the standard deviation of an estimated parameter over $\\infty$ theoretical samples. \n\nAccording to the Central Limit Theorem (CLT), raw $X$ values don't have to be normally distributed for the sample means to be normally distributed (for any decent sample size)!\n\n## Quetelet's chests: Standard error of means of samples\n\n**Question:**\n\nIf Quetelet's chest circumferences are distributed as $X \\sim \\text{N}(\\mu=39.83, \\sigma=2.05)$, then how variable are the means of samples of size $n$ = 6?\n\n**Answer:**\n\n$$\n\\begin{aligned}\nSE(\\bar{X}_{n=6})&=\\sigma/\\sqrt{n} \\\\\n&=2.05/\\sqrt{6} \\\\\n&=0.8369 \n\\end{aligned}\n$$\nSample means of size $n$ = 6 would be distributed as \n\n$\\bar{X}_{n=6} \\sim \\text{N}(\\mu=39.83, \\sigma=0.8369)$\n\n\n## Quetelet's chests: Distribution of means of samples\n\n\n::: {.cell layout-align=\"center\" animation.hook='gifski'}\n::: {.cell-output-display}\n![](Chapter04_files/figure-revealjs/unnamed-chunk-14-.gif){fig-align='center' width=480}\n:::\n:::\n\n## Confidence intervals\n\n:::{.incremental}\n\n- Another common way of expressing uncertainty when making statistical inferences is to present:\n  + a point estimate (e.g., the sample mean) and \n  + a confidence interval around that estimate.\n      \n- A confidence interval gives an indication of the sampling error. \n\n- A 95% confidence interval is constructed so that ***intervals from 95% of samples will contain the true population parameter***. \n\n- In reality the interval either contains the true value or not, so you must **not** interpret a confidence interval as \"there's a 95% probability that the interval contains the true parameter\". \n\n- We can say:\n  + “95% of so-constructed intervals will contain the true value of the parameter” or\n  + “with 95% confidence, the interval contains the true value of the parameter”.\n\n:::\n\n## Confidence intervals\n\n::::{.columns}\n\n:::{.column width=\"50%\"}\n\nBecause we know the population parameters for the Quetelet dataset, we can calculate where 95% of sample means will lie for any particular sample size.\n\nRecall that, for a normal distribution, 95% of values lie between $\\mu \\pm 1.96\\times\\sigma$ \\\n(i.e., $\\mu - 1.96\\times\\sigma$ and $\\mu + 1.96\\times\\sigma$). \n\nIt follows that 95% of means of samples of size $n$ will lie within $\\mu \\pm 1.96 \\times \\sigma/\\sqrt{n}$.\n\nFor example, for samples of size 6 from the Quetelet dataset, 95% of means will lie within $39.83 \\pm 1.96\\times 2.05 / \\sqrt 6$, \\\nso $\\{ 37.02 , 42.64\\}$.\n\n:::\n:::{.column width=\"50%\"}\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Chapter04_files/figure-revealjs/unnamed-chunk-16-1.png){fig-align='center' width=480}\n:::\n:::\n\n:::\n::::\n\n## Estimating the distribution of sample means from data\n\n:::{.incremental}\n\n- It's all very well deriving the distribution of sample means when we *know the population parameters* ($\\mu$ and $\\sigma$) but *in most cases we only have our one sample*.\n\n- We don't know any of the population parameters. We have to *estimate* the population mean (usually denoted $\\hat\\mu$ or $\\bar x$) and *estimate* of the population standard deviation (usually denoted $\\hat\\sigma$ or $s$) from the sample data.\n\n- This additional uncertainty complicates things a bit. In fact, we can't even use the normal distribution any more!\n\n:::\n\n## The *t* distribution\n\n\n::::{.columns}\n\n:::{.column width=\"70%\"}\n\n- Introducing William Sealy Gosset, who described the *t* distribution after working with random numbers.\n\n- Gosset was a chemist and mathematician who worked for the Guinness brewery in Dublin. \n\n- Guinness forbade anyone from publishing under their own names so that competing breweries wouldn’t know what they were up to, so he published his discovery in 1908 under the penname “Student”. Student’s identity was only revealed when he died. It is therefore often called “Student’s *t* distribution”. \n\n:::\n:::{.column width=\"30%\"}\n\n![Willam Sealy Gosset<br>1876-1937](img/gosset_1876-1937.jpg)\n\n:::\n::::\n\n\n## The *t* distribution\n\n\n- The *t* distribution is like the standard normal. It is bell-shaped and symmetric with mean = 0, but it has fatter tails (greater uncertainty) due to the fact that we do not *know* $\\sigma$; we have to *estimate* it.\n\n- The *t* distribution is not just a single distribution. It is really an entire series of distributions which is indexed by something called the “degrees of freedom” (or $df$).\n\n::::{.columns}\n\n:::{.column width=\"40%\"}\n\n- As $df \\rightarrow \\infty$, $t \\rightarrow Z$.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np <- expand_grid(\n  df = c(2, 5, Inf),\n  x = seq(-4, 4, by = .01)\n  ) |> \n  mutate(\n    Density = dt(x = x, df = df),\n    `degrees of freedom` = as_factor(df)\n  ) |> \n  ggplot() +\n  aes(x = x, y = Density, \n      group = `degrees of freedom`, \n      colour = `degrees of freedom`) +\n  geom_line()\n```\n:::\n\n\n\n:::\n:::{.column width=\"60%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Chapter04_files/figure-revealjs/unnamed-chunk-18-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n:::\n::::\n\n## The *t* distribution\n\nFor a sample of size $n$, if\n\n- $X$ is a normal random variable with mean $\\mu$,\n- $\\bar X$ is the sample mean, and \n- $s$ is the sample standard deviation, \n\nthen the variable:\n\n$$\nT = \\frac{\\bar X - \\mu} {s/\\sqrt{n}}\n$$\n\nis distributed as a $t$ distribution with $(n – 1)$ degrees of freedom.\n\n## Confidence intervals and the *t* distribution\n\nThe process of using sample data to try and make useful statements about an unknown parameter, $\\theta$, is called statistical inference.\n\nA confidence interval for the true value of a parameter is often obtained by:\n\n$$\n\\hat \\theta \\pm t \\times \\text{SE}(\\hat \\theta)\n$$\nwhere $\\hat \\theta$ is the sample estimate of $\\theta$ and $t$ is a quantile from the $t$ distribution with the appropriate degrees of freedom. \n\nFor example, to get the $t$ score for a 95% confidence interval with 9 degrees of freedom:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nqt(p = 0.975, df = 9)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.262157\n```\n:::\n:::\n\n\nThe piece that is being added and subtracted, $t \\times \\text{SE}(\\hat \\theta)$, is often called the *margin of error*.\n\n\n## Confidence intervals for a sample mean\n\nWe can calculate a 95% confidence interval for a sample mean with the following information:\n\n::: {style=\"font-size: 75%;\"}\n- sample mean $\\bar x$,\n- sample standard deviation $s$, \n- the sample size $n$, and \n- the 0.025th quantile of the $t$ distribution with degrees of freedom $df=n-1$.\n:::\n\n\n::::{.fragment}\n:::{.absolute top=\"45%\" left=0}\n\nA sample of size $n$ = 6 from Quetelet data\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nn1 <- 6; df1 <- n1-1\n( dq1 <- sample(qd_long, size = n1) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 39 42 38 36 40 38\n```\n:::\n\n```{.r .cell-code}\n( mean1 <- mean(dq1) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 38.83333\n```\n:::\n\n```{.r .cell-code}\n( sd1 <- sd(dq1) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.041241\n```\n:::\n\n```{.r .cell-code}\n( t1 <- qt(c(0.025, 0.975), df = df1) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -2.570582  2.570582\n```\n:::\n\n```{.r .cell-code}\nmean1 + t1 * sd1 / sqrt(n1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 36.69118 40.97548\n```\n:::\n:::\n\n\n:::\n::::\n\n::::{.fragment}\n:::{.absolute top=\"45%\" right=0}\nOr, more simply...\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nt.test(dq1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne Sample t-test\n\ndata:  dq1\nt = 46.6, df = 5, p-value = 8.595e-08\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 36.69118 40.97548\nsample estimates:\nmean of x \n 38.83333 \n```\n:::\n:::\n\n\n:::\n::::\n\n## Confidence intervals for sample means\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\" output-location='fragment'}\n::: {.cell-output-display}\n![](Chapter04_files/figure-revealjs/unnamed-chunk-23-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n## *t* as a test statistic\n\nThis method can be used when the estimator $\\hat\\theta$ is approximately normally distributed and\n\n$$\n \\frac{\\hat\\theta - \\theta} {\\text{SE}(\\hat \\theta)}\n$$\n\nhas approximately a Student’s *t* distribution.\n\nThis paves the way for hypothesis testing for specific values of $\\theta$. Many of the methods you will learn in this course are based on this general rule.\n\n\n## Testing hypotheses\n\n- Testing hypotheses underpins a lot of scientific work.\n- A hypothesis is a proposition, a specific idea about the state of the world that can be tested with data.\n- For logical reasons, instead of measuring evidence for a hypothesis of interest, scientists will often:\n   + specify a ***null hypotheses***, which must be true if our hypothesis of interest is false, and \n   + measure the evidence *against* the null hypothesis, usually in the form of a *p*-value.\n\n## Example: growth of alfalfa\n\nSay a farmer has 9 paddocks of alfalfa. He's hired a new manager, and wants to know if, on average, this year's crop is different to last year's. He measures the yield for each paddock in year 1 and year 2, and calculates the difference.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nyear1 <- c(0.8, 1.3, 1.7, 1.7, 1.8, 2.0, 2.0, 2.0, 2.2)\nyear2 <- c(0.7, 1.4, 1.8, 1.8, 2.0, 2.0, 2.1, 2.1, 2.2)\ndiff <- year2 - year1\n( xbar <- mean(diff) ) ; ( s <- sd(diff) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.06666667\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.08660254\n```\n:::\n:::\n\nThe mean difference is 0.067. On average, yields were 0.067 greater than last year. \\\nIs that convincing different from zero? \n\nHow likely is such a difference to have arisen just by chance, and really, if we had a million paddocks, there would be no difference?\n\nWhat is the probability of seeing a difference of 0.067 or more in our dataset if the true mean were zero?\n\nThese questions can be addressed with a $p$-value from a hypothesis test.\n\n## Example: growth of alfalfa\n\nThe hypothesis of interest (called the \"alternative\" hypothesis) is: \n\n$\\ \\ \\ \\ \\ H_A: \\mu \\ne 0$, that is, the mean difference in yield $\\mu$ between the two years is not zero. \n\nThe **null** hypothesis (the case if the alternative hypothesis is wrong) is:\n\n$\\ \\ \\ \\ \\ H_0: \\mu = 0$, that is, the mean difference is zero.\n\nWe can test the null hypothesis using a *t* statistic $t_0 = \\frac{\\bar x - \\mu_0} {\\text{SE}(\\bar x)}$, where \\\n$\\ \\ \\ \\ \\ \\mu_0 = 0$ is the hypothesised value of the mean and\\\n$\\ \\ \\ \\ \\ \\text{SE}(\\bar x) = s/\\sqrt{n}$ is the (estimated) standard error of the sample mean. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n( t0 <- (xbar - 0) / ( s / sqrt(9) ) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.309401\n```\n:::\n:::\n\nThe *p*-value is $\\text{Pr}(|t_{df=8}| > t_0)$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n2 * pt(t0, df = 8, lower = F)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.04973556\n```\n:::\n:::\n\n\n:::{.absolute bottom=0 right=0}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Chapter04_files/figure-revealjs/unnamed-chunk-27-1.png){fig-align='center' width=384}\n:::\n:::\n\n:::\n\n## Example: growth of alfalfa\n\nThe hypothesis of interest (called the \"alternative\" hypothesis) is: \n\n$\\ \\ \\ \\ \\ H_A: \\mu \\ne 0$, that is, the mean difference in yield $\\mu$ between the two years is not zero. \n\nThe **null** hypothesis (the case if the alternative hypothesis is wrong) is:\n\n$\\ \\ \\ \\ \\ H_0: \\mu = 0$, that is, the mean difference is zero.\n\nThis can be done more easily:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nt.test(diff)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne Sample t-test\n\ndata:  diff\nt = 2.3094, df = 8, p-value = 0.04974\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 9.806126e-05 1.332353e-01\nsample estimates:\n mean of x \n0.06666667 \n```\n:::\n:::\n\n\n:::{.absolute bottom=0 right=0}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Chapter04_files/figure-revealjs/unnamed-chunk-29-1.png){fig-align='center' width=384}\n:::\n:::\n\n:::\n\n\n## Example: growth of alfalfa\n\nThe $p$-value of 0.05 means that, if the null hypothesis were true, only 5% of sample means would be as or more extreme than the observed value of 0.067. It is the area in orange in the graph below.\n\nWe can therefore reject the null hypothesis at the conventional 5% level, and conclude that, on average, yields were indeed higher this year.\n\nThis is an example of a paired *t* test. They two samples (year 1 and year 2) are not independent of one another because we have the same paddocks in both years. So, we take the differences, treat them like a single sample, and do a one-sample *t* test for the mean difference being zero.\n\n$p$-values are random variables too.\\\n<https://shiny.massey.ac.nz/anhsmith/demos/demo.p.is.rv/>\n\n:::{.absolute bottom=0 right=0}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Chapter04_files/figure-revealjs/unnamed-chunk-30-1.png){fig-align='center' width=384}\n:::\n:::\n\n:::\n\n## Truth and outcomes\n\nIn reality, the null hypothesis is either true or false. \n\nThe outcome of a test is either we reject the null hypothesis, or we fail to reject the null hypothesis (note, we never \"confirm\" or \"accept\" the null hypothesis – absence of evidence is not evidence of absence!). \n\nThis gives us four possibilities:\n\n|                          | *$H_0$ is true*  | *$H_0$ is false*  |\n|--------------------------|------------------|-------------------|\n| **Reject $H_0$**         | Type I error     | Correct result    |\n| **Do not reject $H_0$**  | Correct result   | Type II error     |\n\n\nWith probabilities usually represented by:\n\n|                          | *$H_0$ is true*  | *$H_0$ is false*    |\n|--------------------------|------------------|---------------------|\n| **Reject $H_0$**         | $\\alpha$         | $1-\\beta$ = \"power\" |\n| **Do not reject $H_0$**  | $1 - \\alpha$     | $\\beta$             |\n\n\n## Truth and outcomes\n\nThe probability of making a Type I error, rejecting $H_0$ when $H_0$ is true, is set by the experimenter *a priori* (beforehand) as the significance level, $\\alpha$.\n\n- Say we set $\\alpha$ at the conventional 0.05. We know that, if $H_0$ is true, we have a 5% chance of rejecting $H_0$ (the Type I error rate is 0.05) and a 95% chance of not rejecting $H_0$.\n\nThe probability of retaining (not rejecting) $H_0$ when $H_0$ is false is usually represented by $\\beta$ (“beta”).\n\n- We usually do not know $\\beta$ because it depends on $\\sigma$, $n$ and also the *effect size* under the alternative hypothesis. These must be asserted to calculate $\\beta$ and power, $1-\\beta$. \n\n\n## Calculating power\n\nThe ***power*** of a hypothesis test is the probability of rejecting the\nnull hypothesis if it is indeed false. Basically, *\"if we're right, what is the probability that we'll be able to show it?\"*\n\nThe power of the $t$ test can be evaluated using R if you assert the effect size $\\delta$:\n\n::::{.columns}\n\n:::{.column}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npower.t.test(n = 10, delta = 1, sd = 1, sig.level = 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Two-sample t test power calculation \n\n              n = 10\n          delta = 1\n             sd = 1\n      sig.level = 0.05\n          power = 0.5619846\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n:::\n:::\n\n:::\n\n:::{.column}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npower.t.test(n = 50, delta = 1, sd = 1, sig.level = 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Two-sample t test power calculation \n\n              n = 50\n          delta = 1\n             sd = 1\n      sig.level = 0.05\n          power = 0.9986074\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n:::\n:::\n\n:::\n\n::::\n\nThe bigger the sample size, the bigger more power we have to detect an effect.\n\nOften, experimenters might aim to have a power of 80% or more, so they will most likely reject the null if it is false.\n\n## Sampling distributions\n\nThe term *sampling distribution* means the distribution of the computed\nstatistic such as the sample mean when sampling is repeated many times.\n\nFor a normal population,\n\n-   Student's $t$ distribution is the sampling distribution of the mean\n    (after rescaling).\n\n-   $\\chi^2$ distribution is the sampling distribution of the sample\n    variance $S^2$.\n\n-   $(n-1)S^2/\\sigma^2$ follows $\\chi^2$ distribution.\n\n$F$ distribution is ratio of two $\\chi^2$ distributions.\n\n-   It becomes the sampling distribution of the ratio of two sample\n    variances $S_1^2/S_2^2$ from two normal populations (after scaling).\n\n$t$ distribution is symmetric but $\\chi^2$ and $F$ distributions are\nright skewed. - For large samples, they become normal - For $n>30$, the\nskew will diminish\n\nFor the three sampling distributions, the sample size $n$ becomes the\nproxy parameter, called the degrees of freedom (df).\n\n-   $t_{n-1}$, $\\chi_{n-1}^2$ & $F_{(n_1-1),(n_2-1) }$\n\n## Two sample t-test\n\n- The two-sample *t*-test is a common statistical test. You have two populations, $X_1$ and $X_2$, with means $\\mu_1$ and $\\mu_2$ and variances $\\sigma^2_1$ and $\\sigma^2_2$, respectively. \n\n- We wish to test whether the two population means are equal.\\\nNull hypothesis: $H_0:\\mu=\\mu_1=\\mu_2$\\\nTwo-sided alternative hypothesis: $H_1:\\mu_1 \\neq \\mu_2$\n\n- The basic *t*-test ***assumes equal variances***; that is, $\\sigma^2_1 = \\sigma^2_2$.\\\nIf we make this assumption and it is false, the test may give the wrong conclusion!\n\n## Two sample t-test with equal variances\n\nUnder the assumption of equal variances $\\sigma^2_1 = \\sigma^2_2$, we can perform a **pooled-sample t-test**. \n\nWe calculate the estimated pooled variance as:\n\n$$s_{p}^{2} = w_{1} s_{1}^{2} +w_{2} s_{2}^{2}$$\n\nwhere the *weights* are $w_{1} =\\frac{n_{1}-1}{n_{1} +n_{2}-2}$ and $w_{2} =\\frac{n_{2}-1}{n_{1} +n_{2}-2}$, \\\nand $n_1$ and $n_2$ are the sample sizes for samples 1 and 2, respectively. \n\nFor the pooled case, the $df$ for the $t$-test is simply\n\n$$df = n_{1}+n_{2}-2$$\n\n## Two sample t-test with unequal variances\n\nThis is often called the \"Welch test\".\n\nWe do not need to calculated the pooled variance $s^2_p$;\\\nwe simply use $s^2_1$ and $s^2_2$ as they are. \n\nFor the unpooled case, the $df$ for the test is smaller:\n    $$df=\\frac{\\left(\\frac{s_{1}^{2}}{n_{1}} +\\frac{s_{2}^{2} }{n_{2}} \\right)^{2} }{\\frac{1}{n_{1} -1} \\left(\\frac{s_{1}^{2}}{n_{1}}\\right)^{2} +\\frac{1}{n_{2} -1} \\left(\\frac{s_{2}^{2}}{n_{2} } \\right)^{2}}$$\nThe $df$ doesn't have to be an integer in this case. \n\n\n## Validity of equal variance assumption \n\nWe can test the null hypothesis that the variances are equal using either a Bartlett's test or Levene's test. Levene's is generally favourable over Bartlett's. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntv = read_csv(\"https://www.massey.ac.nz/~anhsmith/data/tv.csv\")\ncar::leveneTest(TELETIME~factor(SEX), data=tv)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value  Pr(>F)  \ngroup  1  3.1789 0.08149 .\n      44                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nHighish *p-value* means there's no strong evidence against the null hypothesis that the variances are equal. Therefore, we might feel happy to assume equal variances and use a pooled variance estimate.\n\n## Validity of equal variance assumption \n\n*t*-test assuming equal variances:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nt.test(TELETIME ~ factor(SEX), var.equal = TRUE, data=tv)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo Sample t-test\n\ndata:  TELETIME by factor(SEX)\nt = -0.7249, df = 44, p-value = 0.4723\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -461.3476  217.2606\nsample estimates:\nmean in group 1 mean in group 2 \n       1668.261        1790.304 \n```\n:::\n:::\n\n\n*t*-test *not* assuming equal variances (Welch test):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nt.test(TELETIME ~ factor(SEX), data=tv)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  TELETIME by factor(SEX)\nt = -0.7249, df = 40.653, p-value = 0.4727\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -462.1384  218.0514\nsample estimates:\nmean in group 1 mean in group 2 \n       1668.261        1790.304 \n```\n:::\n:::\n\n\n## Shiny apps (some not currently working)\n\n<https://shiny.massey.ac.nz/anhsmith/demos/demo.2sample.t.test/>\n\n<https://shiny.massey.ac.nz/anhsmith/demos/explore.2sample.t-test/>\n\n<https://shiny.massey.ac.nz/anhsmith/demos/explore.paired.t-test/>\n\nFor more on non-parametric tests, see Study Guide.\n\n## Test of proportions\n\nTesting the null hypothesis that a proportion $p=0.5$\\\nAlternative hypothesis: $p \\ne 0.5$ \n\nSay a survey of 1000 beached whales had 450 females. \n\n::::{.columns}\n\n:::{.column}\n\nIs the population 50:50?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprop.test(450, 1000)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\t1-sample proportions test with continuity correction\n\ndata:  450 out of 1000, null probability 0.5\nX-squared = 9.801, df = 1, p-value = 0.001744\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.4189204 0.4814685\nsample estimates:\n   p \n0.45 \n```\n:::\n:::\n\n\n:::\n\n:::{.column}\n\nAn exact version of the test\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbinom.test(c(450, 550))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tExact binomial test\n\ndata:  c(450, 550)\nnumber of successes = 450, number of trials = 1000, p-value = 0.001731\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.4188517 0.4814435\nsample estimates:\nprobability of success \n                  0.45 \n```\n:::\n:::\n\n\n:::\n\n::::\n\nTo test for a proportion other than 0.5\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbinom.test(c(450, 550), p = 3/4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tExact binomial test\n\ndata:  c(450, 550)\nnumber of successes = 450, number of trials = 1000, p-value < 2.2e-16\nalternative hypothesis: true probability of success is not equal to 0.75\n95 percent confidence interval:\n 0.4188517 0.4814435\nsample estimates:\nprobability of success \n                  0.45 \n```\n:::\n:::\n\n\n\n## Comparing several proportions\n\nData on smokers in four group of patients\\\n(from Fleiss, 1981, *Statistical methods for rates and proportions*).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsmokers  <- c( 83, 90, 129, 70 )\npatients <- c( 86, 93, 136, 82 )\nprop.test(smokers, patients)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\t4-sample test for equality of proportions without continuity correction\n\ndata:  smokers out of patients\nX-squared = 12.6, df = 3, p-value = 0.005585\nalternative hypothesis: two.sided\nsample estimates:\n   prop 1    prop 2    prop 3    prop 4 \n0.9651163 0.9677419 0.9485294 0.8536585 \n```\n:::\n:::\n\n\nMore on chi-squared tests next week.\n\n## Tests for normality\n\nTesting the hypothesis that sample data came from a normally distributed population. $H_0: X \\sim N(\\mu, \\sigma)$.\n\n-   Kolmogorov-Smirnov test (based on the biggest difference between the empirical and theoretical cumulative distributions)\n-   Shapiro-Wilk test (based on variance of the difference)\n\nExample: a sample of $n$ = 50 from N(100,1).\n\n::::{.columns}\n\n:::{.column}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\nshapiro.test(rnorm(50, mean=100))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  rnorm(50, mean = 100)\nW = 0.98928, p-value = 0.9279\n```\n:::\n:::\n\n\n:::\n\n:::{.column}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\nks.test(rnorm(50), \"pnorm\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tExact one-sample Kolmogorov-Smirnov test\n\ndata:  rnorm(50)\nD = 0.073034, p-value = 0.9347\nalternative hypothesis: two-sided\n```\n:::\n:::\n\n\n:::\n::::\n\nThe large p-values mean that there's no evidence of non-normality. \n\nLike all tests, they can give the wrong answer. Try with `set.seed(1234)`. \n\n## Can also use plots to assess normality\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntv = read_csv(\"https://www.massey.ac.nz/~anhsmith/data/tv.csv\")\n\nggplot(tv, aes(sample = TELETIME)) + \n  stat_qq() + stat_qq_line() +\n  labs(title = \"Normal quantile plot for TV viewing times\") \n```\n\n::: {.cell-output-display}\n![](Chapter04_files/figure-revealjs/unnamed-chunk-42-1.png){fig-align='center' width=384}\n:::\n:::\n\n\n\n## Transformations\n\n-   It can be useful to transform skewed data to make the distribution more like a 'normal' if that is required for a particular analysis. \n\n-   A linear transformation $Y^*= a+bY$ only changes the scale or centre, not the shape of the distribution.\n\n-   Transformations can help to improve symmetry, normality, and stabilise the variance.\n\n## Example\n\nRight skewed distribution is made roughly symmetric using a log transformation for no. of vehicles variable (rangitikei.\\* dataset)\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Chapter04_files/figure-revealjs/unnamed-chunk-43-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n## A Ladder of Powers for Transforming Data\n\n-   Right skewed data needs a shrinking transformation\n-   Left skewed data needs a stretching transformation\n-   The strength or power of the transformation depends on the degree of\n    skew.\\\n\n| POWER | Formula               | Name            | Result                 |\n|:------|:----------------------|:----------------|:-----------------------|\n| 3     | $x^3$                 | cube            | stretches large values |\n| 2     | $x^2$                 | square          | stretches large values |\n| 1     | $x$                   | raw             | No change              |\n| 1/2   | $\\sqrt{x}$            | square root     | squashes large values  |\n| 0     | $\\log{x}$             | logarithm       | squashes large values  |\n| -1/2  | $\\frac{-1}{\\sqrt{x}}$ | reciprocal root | squashes large values  |\n| -1    | $\\frac{-1}{x}$        | reciprocal      | squashes large values  |\n\n\n\n## Box-Cox transformation\n\n::::{.columns}\n\n:::{.column width=\"40%\"}\n\nThis is a normalising transformation based on the Box-Cox power parameter, $\\lambda$.\n\nR gives a point estimate of the Box-Cox power & a confidence interval.\n\nUsually, we are concerned about whether the *residuals from a model* are normally distributed – put the model in the `lm` statement. \n\nSometimes, no \"good\" value of $\\lambda$ can be found.\n\n\n:::\n\n:::{.column width=\"60%\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lindia)\ngg_boxcox(lm(rangitikei$vehicle ~ 1))\n```\n\n::: {.cell-output-display}\n![](Chapter04_files/figure-revealjs/unnamed-chunk-44-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n:::\n\n::::\n\n## Statistical inference based on transformed data\n\n-   Obtain the confidence interval using transformed data and then back\n    transform the limits (to keep the original scale)\n\n    -   The confidence limits calculated on log-transformed data can be\n        exponentiated back to the raw scale (i.e., $e^{\\text{confidence limit}}$)\n    -   The confidence limits of square-root-transformed data can be\n        squared back to the raw scale (ie. ${\\text{confidence limit}^2}$)\n\n-   For hypothesis test, apply the same transformation on the value\n    hypothesised under the null\n\n-   Explore <https://shiny.massey.ac.nz/anhsmith/demos/explore.transformations/> app (not currently working)\n\n## Example \n\nBrain weights of `Animals` data are right-skewed. \n\n\n\n::: {.cell layout-align=\"center\" tbl-cap='Lower and upper confidence limits' output-location='column'}\n\n```{.r .cell-code}\ndata(Animals, package = \"MASS\")\n\nbind_cols( \n  # confidence intervals on raw data\n  `raw x` = Animals |> \n    pull(brain) |> \n    t.test() |> \n    pluck(\"conf.int\"),\n  # confidence intervals on log-transformed data\n  `log x` = Animals |> \n    pull(brain) |> \n    log() |> \n    t.test() |> \n    pluck(\"conf.int\"),\n  # confidence intervals on log-transformed data \n  # and then back-transformed\n  `log x, CIs back-transformed` = Animals |> \n    pull(brain) |> \n    log() |> \n    t.test() |> \n    pluck(\"conf.int\") |>\n    exp()\n  ) |> \n  kable()\n```\n\n::: {.cell-output-display}\n|      raw x|    log x| log x, CIs back-transformed|\n|----------:|--------:|---------------------------:|\n|   56.88993| 3.495101|                    32.95362|\n| 1092.15293| 5.355790|                   211.83131|\n:::\n:::\n\n\n## Non-parametric tests\n\nNon-parametric tests are light on assumptions, and can be used for highly asymmetric data (as an alternative to using transformations). \n\nMany non-parametric methods rely on replacing the observed data by their *ranks*. \n\n## Spearman's Rank Correlation\n\n\n::::{.columns}\n\n:::{.column}\n\nRank the $X$ and $Y$ variables, and then obtain usual Pearson correlation coefficient.\n\nThe plot shows non-parametric Spearman in the the upper triangle and parametric Pearson in the bottom triangle.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(GGally)\n\np <- ggpairs(\n  trees, \n  upper = list(continuous = wrap('cor', method = \"spearman\")),\n  lower = list(continuous = 'cor') \n  )\n```\n:::\n\n\n:::\n\n:::{.column}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Comparison of Pearsonian and Spearman's rank correlations](Chapter04_files/figure-revealjs/fig-spear-1.png){#fig-spear fig-align='center' width=480}\n:::\n:::\n\n\n:::\n::::\n\n## Wilcoxon signed rank test\n\nA non-parametric alternative to the one-sample t-test\n\n$H_0: \\eta=\\eta_0$ where $\\eta$ (Greek letter 'eta') is the population median\n\nBased on based on ranking $(|Y-\\eta_0|)$, where the ranks for data with $Y<\\eta_0$ are compared to the ranks for data with $Y>\\eta_0$\n\n\n::::{.columns}\n\n:::{.column}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwilcox.test(tv$TELETIME, mu=1680, conf.int=T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon signed rank exact test\n\ndata:  tv$TELETIME\nV = 588, p-value = 0.6108\nalternative hypothesis: true location is not equal to 1680\n95 percent confidence interval:\n 1557.5 1906.5\nsample estimates:\n(pseudo)median \n          1728 \n```\n:::\n:::\n\n\n:::\n\n:::{.column}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nt.test(tv$TELETIME, mu=1680)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne Sample t-test\n\ndata:  tv$TELETIME\nt = 0.58856, df = 45, p-value = 0.5591\nalternative hypothesis: true mean is not equal to 1680\n95 percent confidence interval:\n 1560.633 1897.932\nsample estimates:\nmean of x \n 1729.283 \n```\n:::\n:::\n\n\n:::\n::::\n\n## Mann-Whitney test\n\nFor two group comparison, pool the two group responses and then rank the\npooled data\n\nRanks for the first group are compared to the ranks for the second group\n\nThe null hypothesis is that the two group medians are the same:     $H_0: \\eta_1=\\eta_2$.\n\n\n::::{.columns}\n\n:::{.column}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwilcox.test(rangitikei$people~rangitikei$time, conf.int=T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  rangitikei$people by rangitikei$time\nW = 30, p-value = 0.007711\nalternative hypothesis: true location shift is not equal to 0\n95 percent confidence interval:\n -88.99996 -10.00005\nsample estimates:\ndifference in location \n             -36.46835 \n```\n:::\n:::\n\n\n:::\n\n:::{.column}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nt.test(rangitikei$people~rangitikei$time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  rangitikei$people by rangitikei$time\nt = -3.1677, df = 30.523, p-value = 0.003478\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -102.28710  -22.13049\nsample estimates:\nmean in group 1 mean in group 2 \n       22.71429        84.92308 \n```\n:::\n:::\n\n\n:::\n::::\n\n## Another form of test\n\n\n::::{.columns}\n\n:::{.column}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nkruskal.test(rangitikei$people~rangitikei$time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tKruskal-Wallis rank sum test\n\ndata:  rangitikei$people by rangitikei$time\nKruskal-Wallis chi-squared = 7.2171, df = 1, p-value = 0.007221\n```\n:::\n:::\n\n\n:::\n\n:::{.column}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwilcox.test(rangitikei$people~rangitikei$time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  rangitikei$people by rangitikei$time\nW = 30, p-value = 0.007711\nalternative hypothesis: true location shift is not equal to 0\n```\n:::\n:::\n\n\n\n:::\n::::\n\n## Permutation tests\n\nA permutation (or randomisation) test has the following steps:\n\n1. Randomly permute the observed data *many times*, thereby destroying any real relationship, \n2. Recalculate the test statistic $T$  for each random permutation\n3. Compare the observed value of $T$ (from the actual data) with the values of $T$ under permutation.\n\nOne sample hypothesis test example follows:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(exactRankTests)\nperm.test(tv$TELETIME, null.value=1500)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\t1-sample Permutation Test\n\ndata:  tv$TELETIME\nT = 79547, p-value = 2.842e-14\nalternative hypothesis: true mu is not equal to 0\n```\n:::\n:::\n\n\nFor small samples, this approach is not powerful.\n\n## Two group comparison\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nperm.test(TELETIME~SEX, distribution ='exact', data=tv)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\t2-sample Permutation Test\n\ndata:  TELETIME by SEX\nT = 38370, p-value = 0.471\nalternative hypothesis: true mu is not equal to 0\n```\n:::\n:::\n\n\nAlso using a linear model fit (cover later)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lmPerm)\nsummary(lmp(TELETIME~SEX, data=tv))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Settings:  unique SS : numeric variables centered\"\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlmp(formula = TELETIME ~ SEX, data = tv)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-1178.261  -510.793    -7.283   402.989  1130.739 \n\nCoefficients:\n    Estimate Iter Pr(Prob)\nSEX      122   51     0.98\n\nResidual standard error: 570.9 on 44 degrees of freedom\nMultiple R-Squared: 0.0118,\tAdjusted R-squared: -0.01066 \nF-statistic: 0.5255 on 1 and 44 DF,  p-value: 0.4723 \n```\n:::\n:::\n\n\nRead the study guide example for bootstrap tests (not examined)\n\n## Summary\n\nBasic methods of inference include:\n\n- estimating a population parameter (e.g. mean) using a sample of values,\n- estimating standard deviation of a sample estimate using the standard error,\n- constructing confidence intervals for an estimate, and \n- testing hypotheses about particular values of the population parameter.\n\nInference is relatively easy for normally distributed populations.\n\nStudent's *t*-tests include:\n\n- one-sample *t*-test, including paired-sample *t*-test for a difference of zero\n- two-sample *t*-test assuming equal variances (estimating pooled variance)\n- two-sample *t*-test not assuming equal variances (Welch test)\n\nThe *t*-test is generally robust for non-normal populations (especially for large samples).\n\nPower transformations, such as square-root, log, or Box-Cox aim to reduce skewness.\n\nNon-parametric tests can be used for non-normal data, but they are usually less powerful than parametric tests.\n\n\n<!-- ## Exercises -->\n\n<!-- download.file(\"<https://www.massey.ac.nz/~kgovinda/220exer/Chap3moreexamples.R>\", destfile=\"Chap3moreexamples.R\") -->\n\n<!-- download.file(\"<https://www.massey.ac.nz/~kgovinda/220exer/chapter-3-exercises.html>\", destfile=\"chapter-3-exercises.html\") -->\n\n<!-- install.packages(\"remotes\") -->\n\n<!-- remotes::install_github(\"ricompute/ricomisc\") -->\n\n<!-- ricomisc::rstudio_viewer(\"chapter-3.html\", file_path = NULL) -->\n",
    "supporting": [
      "Chapter04_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}