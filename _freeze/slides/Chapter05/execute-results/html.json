{
  "hash": "aa71879b64e90e0ea7cb28f068235c28",
  "result": {
    "markdown": "---\ntitle: \"Chapter 5:<br>Tabulated Counts\"\nimage: img/mendel1.png\nformat: \n  revealjs:\n    width: 1050\n    height:\t700\n    scrollable: true\n    transition: fade\n    theme: [default, myquarto.scss]\n    slide-number: c/t  \n    logo: img/L_Color.png\n    footer: \"[161250 Data Analysis](https://anhsmith.github.io/161250/slides.html)\"\n    styles:\n      - revealjs.dark:\n        background-color: #222\n        color: #fff\n    \nexecute:\n  echo: true\neditor: \n  markdown: \n    wrap: 72\n---\n\n::: {.cell}\n\n:::\n\n\n## Analysing frequencies\n\n- This chapter focuses on data that consist of frequencies or counts of occurrences of some events\n\n- Wish to compare *observed* with what we would have *expected*\n\n- We will cover the $\\chi ^ 2$ distribution, \"Goodness-of-fit\" tests, and test of independence\n\n## Chi squared distribution\n::: left-narrow\n- Continuous 0 to infinity; starts at 0 because it is a square (a square number can't be negative)\n\n- The mean of this distribution is its degrees of freedom (k)\n\n- It is right skewed, mean greater than median and mode; variance is $2k$\n\n- Shape of the $\\chi ^ 2$ distribution is determined by the degrees of freedom (k), at very high k (90 or greater) $\\chi ^ 2$ distribution resembles the normal distribution\n\n- Main purpose is hypothesis testing, not describing real-world distributions\n:::\n\n::: right-wide\n![](img/chi-square-distribution-k-example.png)\n:::\n\n## Tables and frequencies\n\n-   We often have hypotheses regarding the frequencies of levels of a factor or group of factors.\n\n    - For a single two-level factor (e.g., male vs female, survived vs died), we might wish to know how likely the data are to have come from a population with equal proportions (or some other specified proportion). \n\n    - For two factors, we might wish to know whether they are independent. \n\n- In either case, we can specify a null hypothesis and test it using data. \n\n- To do so, compare *observed* counts with *expected* counts, where the *expected* counts are derived from our null model about the population.\n\n- We are employing the Chi-squared statistic with data which consists of integers. That is, the data are discrete rather than continuous. \n\n## Examples of data with one factor \n\n#### Example 1\n\n- A dataset contains 40 males and 50 females.\n- How plausible is the null model of these counts coming from a population with 50% males and 50% females?\n- The expected counts in this case would be 45 males and 45 females.\n\n## Examples of data with one factor \n#### Example 2\n\n::::{.columns}\n:::{.column}\n\n-   Does the distribution of rejects of metal castings by causes in a particular week vary from the long-term average counts?\n-   Treat the long-term average counts as the *expected* counts.\n-   Compare *observed* counts with *expected* counts.\n\n:::\n:::{.column style=\"font-size: 85%;\"}\n\n| Causes of rejection | Rejects during the week | Long-term average |\n|---------------------|-------------------------|-----------|\n| sand                | 90                      | 82        |\n| misrun              | 8                       | 4         |\n| shift               | 16                      | 10        |\n| drop-               | 8                       | 6         |\n| corebreak           | 23                      | 21        |\n| broken              | 21                      | 20        |\n| other               | 5                       | 8         |\n\n:::\n::::\n\n## Chi-squared test statistic\n\n$$\n\\chi ^{2} =\\sum _{1}^{c}\\frac{\\left({\\rm Observed-Expected}\\right)^{{\\rm 2}} }{{\\rm Expected}}  =\\sum _{1}^{c}\\frac{\\left( O-E\\right)^{2}}{E}\n$$\n\nIf the number of categories is $c$, then the degrees of freedom is $c-1$. \n\n## Chi-squared test statistic\n\nIf the null hypothesis were true, then the value of $\\chi ^{2}$ calculated from our data is a random value from a Chi-squared distribuion: \n$$\n\\chi_{0} ^{2} = \\chi_{c-1} ^{2}\n$$\nOnce we calculate the test statistic, we can compare our observed value with its distribution under $H_{0}$ to calculate a p-value.\n\n![](img/chisq_ex.png)\n\n\n## Assumptions\n\n-   The classification of observations into groups must be independent\n\n-   No more than 20% of categories should have expected counts less than 5\n\n\n## Goodness of fit test\n\n- Compare *observed* frequencies with *expected* frequencies under some specified null hypothesis.\n\n- Make a hypothesis about the population, what would we expect the frequency to be under that hypothesis?\n\n- For example:\n\n    - Wish to compare the frequency of occurence of different phenotypes in an organism with the frequencies we would expect under Mendel's laws of inheritance.\n    - Wish to compare the distribution of a observation with expected count we would obtain from a Poisson distribution. \n    \nHypotheses of this sort can be tested using the **Chi-squared test statistic** ($\\chi ^ 2$ = Ki Sq.)\n\n\n## Example\n\nA survey of voters included 550 males and 450 females. Will you call\nthis survey as a biased one?\n\nHere the null hypothesis is that the ratio of males to females is 1:1.\n\nEquivalent: the proportion of males is equal to the proportion of female in the population\n\n| Gender | $O$  | $E$  | $(O-E)^2/E$          |\n|--------|------|------|----------------------|\n| male   | 550  | 500  | $(550-500)^2/ 500=5$ |\n| female | 450  | 500  | $(450-500)^2/ 500=5$ |\n| sum    | 1000 | 1000 | 10                   |\n\n\n$$\n\\chi ^{2} = \\sum _{1}^{c}\\frac{\\left( O-E\\right)^{2}}{E} = \n\\frac{(550-500)^2}{500} + \\frac{(450-500)^2}{500} = 10\n$$\n\n\n## Example\n\n![](img/chisq_ex.png)\n\n-   df= (2-1)=1\n-   At 5% level ($\\alpha =0.05$), the critical value is only 3.84. So the sample is a biased one.\n\n## Mendel's experiment (see Study Guide)\n\n::: left-narrow\n-   Mendel discovered the principles of heredity by breeding garden\n    peas. In one Mendel's trials ratios of various types of peas\n    (dihybrid-crosses) were 9:3:3:1\n\n-   The observed results are very close to expected results. This\n    results in a small chi squared value. Were experimental results\n    fudged or was there a *confirmation bias*?\n:::\n\n::: right-wide\n![](img/mendel1.png)\n:::\n\n## Goodness of fit for distributions\n\n-   Treat class intervals as *categories* and obtain the actual counts (O) \n-   The assumed distribution gives the expected counts (E)\n-   Perform a goodness of fit and validate the assumed theoretical\n    distribution\n-   Adjust the degrees of freedom (df) for the number of estimated\n    parameters of the theoretical distribution\n    -   For example, assume that you have 10 class intervals and test\n        for normal distribution, which has 2 parameters.\\\n    -   So the df for this test will be 10-1-2=7.\n\n## Goodness of fit for distributions example\nA safety inspector monitors car accidents at a bustling intersection. The inspector enters the counts of monthly accidents.\n\nNull: The sample data follow the Poisson distribution.\nAlternative: The sample data do not follow the Poisson distribution.\n\n\n*Note* The Poisson distribution is a discrete probability distribution (integers) that can model counts of events or attributes in a fixed observation space. Many but not all count processes follow this distribution. \n\n## Goodness of fit for distributions example\n| Accidents| $O$ | $E$         | $(O-E)^2/E$         |\n|---------|-----|--------------|----------------------|\n| 0       | 7   |      |                      |\n| 1       | 8   |      |                      |\n| 2       | 13  |      |                      |\n| 3       | 10  |      |                      |\n| >=4     | 12  |      |                      |\n| Sum     | 40  |      |                      |\n\nConclusion:\n\n## Tests of Independence\n\n- In some cases, we have counts of observations cross-classified in terms of two factors.\n\n- We are generally interested in determining whether or not the two factors are independent.\n\n- If we consider the observations falling into each category for factor 1, is this distribution consistent across all levels of factor 2? (or vice versa)\n\n## Contingency table\n\n-   Given a two way table of frequency counts, **we test whether the row\n    and column variables are independent**\n\n-   Hypotheses:\n\n    - Null: the two factors are independent\n    - written another way: the row (or column) distributions are the same\n\n-   The expected count for cell $(i,j)$ is given by $E_{ij}$ =\n    $(T_i \\times T_j)/n$ where\\\n    $~~~~~T_i$, the total for row $i$;\\\n    $~~~~~T_j$, the total for column $j$\\\n    $~~~~~n$, the overall total count\n\n-   Test statistic :\n    $\\chi ^{2} =\\sum _{{i=1}}^{r}\\sum _{{j=1}}^{{\\rm c}}\\frac{\\left({ O}_{{ ij}} { -E}_{{ij}} \\right)^{{ 2}} }{{ E}_{{ij}} }.$\n\n-   degrees of freedom: $(r-1)(c-1)$\n\n## Example\n\n`Context`: Porcine Stress Syndrome (PSS) result in pale, soft meat in\npigs and under conditions of stress- death.\n\n-   Presence of PPS is a positive reaction to breathing halothane.\n    -   Selective breeding for reducing incidence of PSS\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Porcine Stress Syndrome (PSS) data</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:right;\"> Halothane.positive </th>\n   <th style=\"text-align:right;\"> Halothane.negative </th>\n   <th style=\"text-align:right;\"> Totals </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Large White </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 76 </td>\n   <td style=\"text-align:right;\"> 78 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Hampshire </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 86 </td>\n   <td style=\"text-align:right;\"> 89 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Landrace(B) </td>\n   <td style=\"text-align:right;\"> 11 </td>\n   <td style=\"text-align:right;\"> 73 </td>\n   <td style=\"text-align:right;\"> 84 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Landrace(S) </td>\n   <td style=\"text-align:right;\"> 16 </td>\n   <td style=\"text-align:right;\"> 76 </td>\n   <td style=\"text-align:right;\"> 92 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Totals </td>\n   <td style=\"text-align:right;\"> 32 </td>\n   <td style=\"text-align:right;\"> 311 </td>\n   <td style=\"text-align:right;\"> 343 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Example\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Porcine Stress Syndrome (PSS) data</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:right;\"> Halothane.positive </th>\n   <th style=\"text-align:right;\"> Halothane.negative </th>\n   <th style=\"text-align:right;\"> Totals </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Large White </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 76 </td>\n   <td style=\"text-align:right;\"> 78 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Hampshire </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 86 </td>\n   <td style=\"text-align:right;\"> 89 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Landrace(B) </td>\n   <td style=\"text-align:right;\"> 11 </td>\n   <td style=\"text-align:right;\"> 73 </td>\n   <td style=\"text-align:right;\"> 84 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Landrace(S) </td>\n   <td style=\"text-align:right;\"> 16 </td>\n   <td style=\"text-align:right;\"> 76 </td>\n   <td style=\"text-align:right;\"> 92 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Totals </td>\n   <td style=\"text-align:right;\"> 32 </td>\n   <td style=\"text-align:right;\"> 311 </td>\n   <td style=\"text-align:right;\"> 343 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nchisq.test(dt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  dt\nX-squared = 16.433, df = 8, p-value = 0.03659\n```\n:::\n:::\n\n\n## Computations\n::: left\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Porcine Stress Syndrome (PSS) data</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:right;\"> Halothane.positive </th>\n   <th style=\"text-align:right;\"> Halothane.negative </th>\n   <th style=\"text-align:right;\"> Totals </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Large White </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 76 </td>\n   <td style=\"text-align:right;\"> 78 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Hampshire </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 86 </td>\n   <td style=\"text-align:right;\"> 89 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Landrace(B) </td>\n   <td style=\"text-align:right;\"> 11 </td>\n   <td style=\"text-align:right;\"> 73 </td>\n   <td style=\"text-align:right;\"> 84 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Landrace(S) </td>\n   <td style=\"text-align:right;\"> 16 </td>\n   <td style=\"text-align:right;\"> 76 </td>\n   <td style=\"text-align:right;\"> 92 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Totals </td>\n   <td style=\"text-align:right;\"> 32 </td>\n   <td style=\"text-align:right;\"> 311 </td>\n   <td style=\"text-align:right;\"> 343 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n:::\n\n::: right\n![](img/halothane1.png)\n:::\n\n## Inference\n\n-   The tabulated Chisq with (4-1)x(2-1) = 3 d.f are\n    -   7.81 at 5% level; 16.27 at 1% level.\n\n-   ::: red\n    Conclusion: There is a statistical evidence that the breed is not\n    independent of the result of the Halothane test.\n    :::\n\n    -   Note that large counts in the second column (Halothane negative)\n        lead to large expected values but low contributions to\n        chi-squared statistic.\n    -   This is because of the division by the appropriate expected\n        value. On the other hand, the small observations of first column\n        lead to small expected values but large contributions to the\n        $\\chi ^{2}$.\n\n## Significant cell contribution\n\n-   Counts follow Poisson distribution for which *mean = variance*\n\n-   Hence $\\chi^{2}=\\sum \\frac{\\left({\\rm residual}\\right)^{{\\rm 2}} }{{\\rm variance}} =\\sum \\left(\\frac{{\\rm residual}}{{\\rm std\\; dev}} \\right)^{2}.$\n\n-   Individual cell contribution is similar to standardized residual.\n    Any standardized residual greater than 2 is regarded as significant.\n\n-   So $2^2 = 4$ is treated as a significant contribution to the\n    $\\chi ^{2}$ statistic.\n\n## Warnings\n\n-   Use only frequency counts. Use of percentages in place of counts may\n    lead to incorrect conclusions.\n\n-   Check for small expected values. An expected value of less than 5\n    may lead to concern and a very small value of less than 1 is a\n    warning. Sometimes, you can merge/combine categories in case of small\n    expected counts.\n\n-   If the chi-squared statistic is small enough to be not significant,\n    there is no problem.\n\n-   If chi-squared statistic is significant, check the contributions to\n    each cell. If cells with large expected value (\\>5) contribute a\n    large amount to chi-squared statistic, again there is no problem.\n\n-   If cells with expected values less than 5 lead large contributions\n    to chi-squared statistic, the significance of the chi-squared\n    statistic should be treated with caution.\n\n## Simpson's paradox\n\nGroup 1\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2]\n[1,]   80  120\n[2,]   30   80\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test with Yates' continuity correction\n\ndata:  group1\nX-squared = 4.4809, df = 1, p-value = 0.03428\n```\n:::\n:::\n\n\nGroup 2\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2]\n[1,]   20   75\n[2,]   25   20\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test with Yates' continuity correction\n\ndata:  group2\nX-squared = 15.122, df = 1, p-value = 0.0001008\n```\n:::\n:::\n\n\nAfter amalgamation of both groups\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2]\n[1,]  100  195\n[2,]   55  100\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test with Yates' continuity correction\n\ndata:  all\nX-squared = 0.053808, df = 1, p-value = 0.8166\n```\n:::\n:::\n\n\n## Permutation test\n\nThis test is done maintaining the marginal totals.\n\n```         \nData: Smoking Status vs. Staff  Groupings\n```\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Smoking Status vis-a-vis Staff Groupings</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:right;\"> None </th>\n   <th style=\"text-align:right;\"> Moderate </th>\n   <th style=\"text-align:right;\"> Heavy </th>\n   <th style=\"text-align:right;\"> Totals </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Junior employees </td>\n   <td style=\"text-align:right;\"> 18 </td>\n   <td style=\"text-align:right;\"> 57 </td>\n   <td style=\"text-align:right;\"> 13 </td>\n   <td style=\"text-align:right;\"> 88 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Junior managers </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 10 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 18 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Secretaries </td>\n   <td style=\"text-align:right;\"> 10 </td>\n   <td style=\"text-align:right;\"> 13 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 25 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Senior employees </td>\n   <td style=\"text-align:right;\"> 25 </td>\n   <td style=\"text-align:right;\"> 22 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 51 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Senior managers </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 11 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Totals </td>\n   <td style=\"text-align:right;\"> 61 </td>\n   <td style=\"text-align:right;\"> 107 </td>\n   <td style=\"text-align:right;\"> 25 </td>\n   <td style=\"text-align:right;\"> 193 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nPermutation test\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(12321)\nchisq.test(tabledata, simulate.p.value = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test with simulated p-value (based on 2000\n\treplicates)\n\ndata:  tabledata\nX-squared = 15.672, df = NA, p-value = 0.04948\n```\n:::\n:::\n\n\nRegular Chi-square test\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nchisq.test(tabledata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  tabledata\nX-squared = 15.672, df = 8, p-value = 0.04733\n```\n:::\n:::\n\n\n\n## Correspondence Analysis \nCorrespondence Analysis is an exploratory statistical technique for assessing the interdependence of categorical variables whose data are presented primarily in the form of a two-way table of frequencies\n\n\n    Data: Smoking Status vs. Staff Groupings\n\n\\tiny\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n                 None Moderate Heavy\nJunior employees   18       57    13\nJunior managers     4       10     4\nSecretaries        10       13     2\nSenior employees   25       22     4\nSenior managers     4        5     2\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  tabledata\nX-squared = 15.672, df = 8, p-value = 0.04733\n```\n:::\n:::\n\n\n## Row mass & row profiles\n\n-   row profiles are found dividing the cell counts by the corresponding\n    row total\n\n-   row mass is found dividing the row totals by the grand total\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n                  None Moderate  Heavy\nJunior employees 0.205    0.648 0.1477\nJunior managers  0.222    0.556 0.2222\nSecretaries      0.400    0.520 0.0800\nSenior employees 0.490    0.431 0.0784\nSenior managers  0.364    0.455 0.1818\nrowmass          0.316    0.554 0.1295\n```\n:::\n:::\n\n\n-   Similarly column profiles & column masses can be found\n\n## Graphical display of row profiles\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Chapter05_files/figure-revealjs/unnamed-chunk-13-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n-   No clear patterns seen\n\n## Symmetric plots to find subgrouping {.scrollable}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(\"FactoMineR\")\nCA(tabledata) |> summary()\n```\n\n::: {.cell-output-display}\n![](Chapter05_files/figure-revealjs/unnamed-chunk-14-1.png){fig-align='center' fig-pos='FALSE' width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nCA(X = tabledata) \n\nThe chi square of independence between the two variables is equal to 15.7 (p-value =  0.0473 ).\n\nEigenvalues\n                       Dim.1   Dim.2\nVariance               0.074   0.008\n% of var.             90.570   9.430\nCumulative % of var.  90.570 100.000\n\nRows\n                   Iner*1000    Dim.1    ctr   cos2    Dim.2    ctr   cos2  \nJunior employees |    26.268 | -0.235 34.372  0.962 | -0.047 12.934  0.038 |\nJunior managers  |     8.784 | -0.236  7.042  0.590 |  0.197 47.082  0.410 |\nSecretaries      |     5.618 |  0.195  6.670  0.873 | -0.074  9.301  0.127 |\nSenior employees |    37.894 |  0.379 51.521  1.000 |  0.004  0.045  0.000 |\nSenior managers  |     2.636 |  0.071  0.394  0.110 |  0.203 30.638  0.890 |\n\nColumns\n                   Iner*1000    Dim.1    ctr   cos2    Dim.2    ctr   cos2  \nNone             |    49.186 |  0.394 66.705  0.997 |  0.020  1.688  0.003 |\nModerate         |    15.679 | -0.157 18.619  0.873 | -0.060 25.941  0.127 |\nHeavy            |    16.335 | -0.289 14.676  0.661 |  0.207 72.371  0.339 |\n```\n:::\n:::\n\n\n## Symmetric plots to find subgrouping\n\n![](img/CA.png)\n\n## Summary\n\n-   Goodness of fit is for testing whether the observed counts are from\n    the hypothesised population groups.\n\n    -   For $c$ categories (groups), the test involves $c-1$ df.\n\n-   Contingency Table ($r$ rows and $c$ columns) data are tested for the\n    independence.\n\n    -   For $r\\times c$ cells the test involves $(r-1)(c-1)$ df\n\n-   $\\chi ^{2}$ test works well if $E> 5$. Some could be as low as 1.\n\n-   Do correspondence analysis (symmetric plots) when independence is\n    rejected.\n\n<!-- ## Exercises -->\n\n<!-- download.file(\"http://www.massey.ac.nz/~kgovinda/220exer/Chap7moreexamples.R\", destfile=\"Chap7moreexamples.R\") -->\n\n<!-- download.file(\"https://www.massey.ac.nz/~kgovinda/220exer/chapter-7-exercises.html\", destfile=\"chapter-7-exercises.html\") -->\n\n<!-- install.packages(\"remotes\") -->\n\n<!-- remotes::install_github(\"ricompute/ricomisc\") -->\n\n<!-- ricomisc::rstudio_viewer(\"chapter-7-exercises.html\", file_path = NULL) -->\n",
    "supporting": [
      "Chapter05_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ],
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}