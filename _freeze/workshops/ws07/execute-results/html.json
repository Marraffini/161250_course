{
  "hash": "306cb31cb8b1faa9ebcaee170fd17f83",
  "result": {
    "markdown": "---\ntitle: \"Chapter 7 Workshop\"\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n\n# Horse hearts\n\nWe will use the *horses’ hearts* dataset. There are seven variables represented as columns. They comprise six ultrasound measurements and the weights of 46 horses’ hearts, specifically:\n\n\n1.\t`INNERSYS` : Inner-wall ultrasound measurement in systole phase.\n2.\t`INNERDIA` : Inner-wall ultrasound measurement in diastole phase.\n3.\t`OUTERSYS` : Outer-wall ultrasound measurement in systole phase.\n4.\t`OUTERDIA` : Outer-wall ultrasound measurement in diastole phase.\n5.\t`EXTSYS`   : Exterior ultrasound measurement in systole phase.\n6.\t`EXTDIA`   : Exterior ultrasound measurement in diastole phase.\n7.\t`WEIGHT`   : Weight in kilograms.\t\t\n\nWe will build a multiple regression model to predict the weights of hearts using the six ultrasound measurements. \n\n## Load data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhh <- read_csv(\"https://www.massey.ac.nz/~anhsmith/data/horsehearts.csv\")\n```\n:::\n\n\n\n## Pairs plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(GGally)\n\nggpairs(hh)\n```\n\n::: {.cell-output-display}\n![](ws07_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nThis plot reveals some very high correlation amongst predictors, particularly (not surprisingly) between the same measurements taken in the different phases (diastolic and systolic). Thus, multicollinearity is likely to be a problem when fitting a multiple regression model. The challenge will be choose the subset of variables that provides the best model fit. \n\n\n\n## `lm` output\n\nLet’s start by fitting the full model with all of the available predictor variables. \n\nThe formula `WEIGHT ~ .` fits a model with `WEIGHT` as the response variable and all other variables in the data frame as predictor variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmf <- lm(WEIGHT ~ . , data = hh)\n\nsummary(mf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = WEIGHT ~ ., data = hh)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.05051 -0.35313  0.01948  0.18674  2.09335 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  -1.6311     0.4879  -3.343  0.00184 **\nINNERSYS      0.2321     0.3083   0.753  0.45617   \nINNERDIA      0.5195     0.3954   1.314  0.19654   \nOUTERSYS      0.7114     0.3288   2.164  0.03668 * \nOUTERDIA     -0.5574     0.4510  -1.236  0.22386   \nEXTSYS       -0.2996     0.1346  -2.227  0.03182 * \nEXTDIA        0.3387     0.1475   2.296  0.02716 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6006 on 39 degrees of freedom\nMultiple R-squared:  0.7525,\tAdjusted R-squared:  0.7145 \nF-statistic: 19.77 on 6 and 39 DF,  p-value: 1.922e-10\n```\n:::\n:::\n\n\n:::{.callout-tip}\n\n### Interpreting `summary.lm` output\n\nThere is a lot of information in the above summary output to process. Let’s break it down.\n\n1.\tThe `Call` part shows us the command we used to produce the model. \n\n2.\tThe `Residuals` part gives us a five-number summary of the residuals. \n\n3.\tThe `Coefficients` table provides the estimates of the model parameters. Specifically, the `Estimate` column gives us the estimates of the $\\beta$-coefficients, which can be used to reconstruct the predictive formula. Here, that formula is: \n\n    $$\\hat y = -1.6311 + 0.2321 × INNERSYS + 0.5195 × INNERDIA + ... + 0.3387 × EXTDIA$$\n    \n    The `Std. Error` column gives the standard error for the estimates of the coefficients. That is, the expected average deviation of the estimator of the coefficient ($b$ or $\\hat \\beta$) from the true population parameter ($\\beta$). If we were to take many samples (of size $n$) from this population, a coefficient’s standard error represents how much the estimate is expected to vary (due to sampling variation). \n\n    The `t value` is the estimate divided by its standard error, which can be used to test whether the effect of that variable is statistically different from zero. The p-value for this test is provided in the next column, headed `Pr(>|t|)`. If the p-value is low, the observed coefficient estimate is unlikely to have resulted by chance due to sampling variation if the null hypothesis ($H_0 : \\beta = 0$) is true. Asterisks indicate significant results, as coded by the `Signif. codes`:  given below the table.\n\n4.\tThe final three lines give results for the entire model.\n\n    The final three lines give results for the entire model.\n\n    The `Residual standard error` is an estimate of the standard deviation of the residuals, i.e. the average absolute difference between the predicted values and the actual values. When estimating the weight of horse’s hearts using this model, we would expect to, on average, be wrong by 0.6 kg. The `degrees of freedom` here are the residual degrees of freedom—the number of independent pieces of information with which the residual standard error was estimated.\n\n    Next, we have the `Multiple R-squared`, which is the proportion of the total variation in y that is explained by the model. Here, 75% of the variation is explained. The `Adjusted R-squared` is adjusted for the number of variables included in the model (see lecture slides). It cannot be interpreted in same way as the unadjusted $R^2$ can, but it can be used to compare models.\n\n    Finally, an `F-statistic`, associated degrees of freedom (`DF`) , and `p-value` are provided. This tests whether the model explains a significant proportion of the total variation in y. This can be thought of as testing whether any of the $\\beta$ coefficients in model are non-zero. Here, the p-value is very small so we reject the null hypothesis that all of the $\\beta$ coefficients in model are zero.\n\n:::\n\n## Variance Inflation Factor\n\nWe mentioned earlier that we were concerned with multicollinearity—correlation among the predictors. A consequence of multicollinearity is that it increases the uncertainty in the estimates of the coefficients—the standard errors of the coefficients are inflated. We can quantify this effect, for each coefficient, with the Variance Inflation Factor (VIF). This is given by the function `car::vif()`[^1]. \n\n[^1]: The `car::vif()` notation calls the function `vif()` from within the package `car`. Alternatively, you can load the package into R with the command `library(car)`. After doing this, all functions in the car package become available, so you can call the function directly as `vif()`, omitting the `car::`. Either way, you must have the package installed, of course!\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::vif(mf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n INNERSYS  INNERDIA  OUTERSYS  OUTERDIA    EXTSYS    EXTDIA \n 8.772969  8.602746  7.706493  6.662813 16.046340 21.996455 \n```\n:::\n:::\n\n\n\nAccording to a rule of thumb, a VIF > 5 is cause for some concern. A VIF > 10 is definitely problematic. So, we have a problem here. \n\nThe above VIF values pertain to variances. I find it more intuitive to discuss the square root of the VIF because they relate to the standard errors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsqrt(car::vif(mf))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nINNERSYS INNERDIA OUTERSYS OUTERDIA   EXTSYS   EXTDIA \n2.961920 2.933044 2.776057 2.581242 4.005788 4.690038 \n```\n:::\n:::\n\n\nThese $\\sqrt{}$VIF values can be interpreted in the following way: the standard error for the effect of `INNERSYS` is around three times larger because of the presence of the other (correlated) variables in the model. The VIF is greatest for `EXTDIA`, which is consistent with this variable seeming to have the highest correlations with the other predictors.  \n\n## Model selection\n\nStatisticians use the term \"parsimonious\" to describe a model that contains no more predictors than necessary to adequately model the data—a model that has the right balance of complexity. \n\nLet’s run a stepwise model selection process to try to find a more parsimonious model than the full model created above. The criterion we will use to assess the quality of the models is Akaike Information Criterion (AIC). Lower AIC values (i.e. closer to $-\\infty$) are better.\n\nWe will undertake a stepwise process in individual steps, using the `drop1()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(mf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nWEIGHT ~ INNERSYS + INNERDIA + OUTERSYS + OUTERDIA + EXTSYS + \n    EXTDIA\n         Df Sum of Sq    RSS     AIC\n<none>                14.068 -40.500\nINNERSYS  1   0.20434 14.272 -41.836\nINNERDIA  1   0.62273 14.690 -40.507\nOUTERSYS  1   1.68862 15.756 -37.285\nOUTERDIA  1   0.55102 14.618 -40.732\nEXTSYS    1   1.78829 15.856 -36.995\nEXTDIA    1   1.90084 15.968 -36.670\n```\n:::\n:::\n\n\nWe have taken the full model (all predictors included) and asked what the AIC values[^2] would be obtained if we dropped each one of the predictors (or none). The lowest AIC score is for the model with `INNERSYS` removed... so let’s remove it and then use `drop1()` again. \n\n[^2]: Negative values of AIC, as seen here, are uncommon but are nothing to worry about. This occurs when the values of the response variable are small.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- update(mf, ~ . - INNERSYS)\ndrop1(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nWEIGHT ~ INNERDIA + OUTERSYS + OUTERDIA + EXTSYS + EXTDIA\n         Df Sum of Sq    RSS     AIC\n<none>                14.272 -41.836\nINNERDIA  1   2.59025 16.862 -36.164\nOUTERSYS  1   2.11154 16.383 -37.489\nOUTERDIA  1   0.46718 14.739 -42.355\nEXTSYS    1   1.59023 15.862 -38.977\nEXTDIA    1   1.70093 15.973 -38.657\n```\n:::\n:::\n\n\nNow we remove `OUTERDIA` and repeat.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm3 <- update(m2, ~ . - OUTERDIA)\ndrop1(m3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nWEIGHT ~ INNERDIA + OUTERSYS + EXTSYS + EXTDIA\n         Df Sum of Sq    RSS     AIC\n<none>                14.739 -42.355\nINNERDIA  1    3.2083 17.947 -35.295\nOUTERSYS  1    2.0972 16.836 -38.235\nEXTSYS    1    1.3505 16.090 -40.322\nEXTDIA    1    1.3250 16.064 -40.395\n```\n:::\n:::\n\n\nThis time, the best model is that with none removed, so the model selection process stops there. Note that this whole process could have been done in a single line of code. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmstep <- step(mf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=-40.5\nWEIGHT ~ INNERSYS + INNERDIA + OUTERSYS + OUTERDIA + EXTSYS + \n    EXTDIA\n\n           Df Sum of Sq    RSS     AIC\n- INNERSYS  1   0.20434 14.272 -41.836\n- OUTERDIA  1   0.55102 14.618 -40.732\n- INNERDIA  1   0.62273 14.690 -40.507\n<none>                  14.068 -40.500\n- OUTERSYS  1   1.68862 15.756 -37.285\n- EXTSYS    1   1.78829 15.856 -36.995\n- EXTDIA    1   1.90084 15.968 -36.670\n\nStep:  AIC=-41.84\nWEIGHT ~ INNERDIA + OUTERSYS + OUTERDIA + EXTSYS + EXTDIA\n\n           Df Sum of Sq    RSS     AIC\n- OUTERDIA  1   0.46718 14.739 -42.355\n<none>                  14.272 -41.836\n- EXTSYS    1   1.59023 15.862 -38.977\n- EXTDIA    1   1.70093 15.973 -38.657\n- OUTERSYS  1   2.11154 16.383 -37.489\n- INNERDIA  1   2.59025 16.862 -36.164\n\nStep:  AIC=-42.35\nWEIGHT ~ INNERDIA + OUTERSYS + EXTSYS + EXTDIA\n\n           Df Sum of Sq    RSS     AIC\n<none>                  14.739 -42.355\n- EXTDIA    1    1.3250 16.064 -40.395\n- EXTSYS    1    1.3505 16.090 -40.322\n- OUTERSYS  1    2.0972 16.836 -38.235\n- INNERDIA  1    3.2083 17.947 -35.295\n```\n:::\n:::\n\n\nWhen you run this, the whole three-step process we executed above will print onscreen and the object `mstep` represents the stepwise-selected model.\n\nLet’s examine the stepwise model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mstep)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = WEIGHT ~ INNERDIA + OUTERSYS + EXTSYS + EXTDIA, \n    data = hh)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.19400 -0.31530 -0.05037  0.20522  1.92298 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  -1.5120     0.4681  -3.230  0.00244 **\nINNERDIA      0.7991     0.2675   2.987  0.00473 **\nOUTERSYS      0.4931     0.2042   2.415  0.02026 * \nEXTSYS       -0.2360     0.1218  -1.938  0.05950 . \nEXTDIA        0.2500     0.1302   1.920  0.06185 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5996 on 41 degrees of freedom\nMultiple R-squared:  0.7407,\tAdjusted R-squared:  0.7154 \nF-statistic: 29.28 on 4 and 41 DF,  p-value: 1.554e-11\n```\n:::\n:::\n\n\nWe still have two variables that are very highly correlated: `EXTSYS` and `EXTDIA`. Let’s see if this correlation is problematic, according to the VIF criterion.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::vif(mstep)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n INNERDIA  OUTERSYS    EXTSYS    EXTDIA \n 3.950323  2.981334 13.184774 17.198270 \n```\n:::\n:::\n\n\nWith VIF scores for these two variables still well above 5, this is certainly a problem. This illustrates an important point: you must not naively accept a model which results from a stepwise selection process. Always scrutinise a model before accepting it.\n\nWe will force a step where we drop either `EXTSYS` or `EXTDIA`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(mstep)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nWEIGHT ~ INNERDIA + OUTERSYS + EXTSYS + EXTDIA\n         Df Sum of Sq    RSS     AIC\n<none>                14.739 -42.355\nINNERDIA  1    3.2083 17.947 -35.295\nOUTERSYS  1    2.0972 16.836 -38.235\nEXTSYS    1    1.3505 16.090 -40.322\nEXTDIA    1    1.3250 16.064 -40.395\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmstep2 <- update(mstep,  ~ . - EXTDIA)\n```\n:::\n\n\nNow, let’s try another step.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(mstep2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nWEIGHT ~ INNERDIA + OUTERSYS + EXTSYS\n         Df Sum of Sq    RSS     AIC\n<none>                16.064 -40.395\nINNERDIA  1    5.0919 21.156 -29.729\nOUTERSYS  1    3.3053 19.369 -33.788\nEXTSYS    1    0.1091 16.173 -42.083\n```\n:::\n:::\n\n\nIt seems that the model with `EXTSYS` removed, leaving only `INNERDIA` and `OUTERSYS`, is actually preferable. Once the latter two variables are included, `EXTSYS` does not add any strength to the model. Let’s make this model and check for further removals, and our VIFs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmstep3 <- update(mstep2, ~ . - EXTSYS)\ndrop1(mstep3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nWEIGHT ~ INNERDIA + OUTERSYS\n         Df Sum of Sq    RSS     AIC\n<none>                16.173 -42.083\nINNERDIA  1    6.2151 22.388 -29.125\nOUTERSYS  1    3.2771 19.450 -35.596\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::vif(mstep3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nINNERDIA OUTERSYS \n2.471453 2.471453 \n```\n:::\n:::\n\n\nIt seems that this model cannot be improved by dropping any further variables. The variables `INNERDIA` and `OUTERSYS`, though correlated (r = 0.77), do not exert undue influence on each other in the model. \n\nTo summarise, let’s see the AIC scores for all the models we’ve made so far.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAIC(mf, m2, m3, mstep, mstep2, mstep3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       df      AIC\nmf      8 92.04262\nm2      7 90.70599\nm3      6 90.18764\nmstep   6 90.18764\nmstep2  5 92.14759\nmstep3  4 90.45888\n```\n:::\n:::\n\n\nAll of these models have very similar AIC. Statisticians say that AIC scores within, say, 3 points can be considered equivalent, and so often we take the approach of choosing the simplest model (i.e. that with the fewest predictors) of all those within 3 AIC points of the lowest score. In some fields it is common to report all models within 10 AIC points or produce an ensemble model bases on AIC weight (not covered in this course). So, while the `mstep3` model isn’t the absolute lowest, it is the simplest model from a bunch of models with roughly equivalent AIC scores. Also, it is a good choice because it doesn’t have the problems with severe multicollinearity found in the other models.\n\n\nDon’t worry about the fact that the two functions `drop1()` and `AIC()` give different scores. Remember the AIC is a tool for comparing models—the actual scores don’t matter.  If you look at the difference in AIC scores between two models from the two functions, they are the same. It also should not be compared on models that have different data sources because it is unit less and only acts to compare the models in a specific set.\n\nDifference between AIC scores for `mstep2` and `mstep3` from the `drop1(mstep2)` output:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n-40.395 - (-42.083)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.688\n```\n:::\n:::\n\n\nAnd from the `AIC(mf, m2, m3, mstep, mstep2, mstep3)` output:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n92.14759 - 90.45888\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.68871\n```\n:::\n:::\n\n\nSo now we can choose `mstep3` and clean up.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(mf, m2, m3, mstep, mstep2) # this code removes these variables\n```\n:::\n\n\nLet’s examine the summary for our chosen model. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mstep3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = WEIGHT ~ INNERDIA + OUTERSYS, data = hh)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.08663 -0.33797 -0.08511  0.32755  1.82971 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -1.4948     0.3728  -4.009 0.000238 ***\nINNERDIA      0.8797     0.2164   4.065 0.000201 ***\nOUTERSYS      0.5612     0.1901   2.952 0.005100 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6133 on 43 degrees of freedom\nMultiple R-squared:  0.7155,\tAdjusted R-squared:  0.7023 \nF-statistic: 54.07 on 2 and 43 DF,  p-value: 1.833e-12\n```\n:::\n:::\n\n\nWe are now explaining 72% of the variation in heart weights with two variables, as opposed to 75% of the variation with six variables in the original full model. Note also that, in the full model, `INNERDIA` was not significant and `OUTERSYS` was only weakly significant. In the smaller model, both these predictors were highly significant. Personally, I would definitely prefer the more parsimonious two-variable model, especially if it meant that I had only to take two, rather than six, ultrasound measurements on a thousand horses! \n\nBut we’re not done yet. We must use some diagnostic tools to examine whether our model meets the assumptions of linear regression before we can accept it.\n\n## Model diagnostics\n\nExamine the usual four diagnostic plots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(mstep3)\n```\n\n::: {.cell-output-display}\n![](ws07_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](ws07_files/figure-html/unnamed-chunk-24-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](ws07_files/figure-html/unnamed-chunk-24-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](ws07_files/figure-html/unnamed-chunk-24-4.png){width=672}\n:::\n:::\n\n\nThe Residuals-vs-Fitted plot shows a slight decreasing trend in the residuals at low fitted values, but it is only a few points. It might pay, though, to bear in mind that the model is likely to overestimate lower heart weights.\n\nThe normal Q-Q plot is not too worrying, although there are a few higher-than-expected residuals. \n\nThe Scale-Location plot shows no strong evidence of heteroscedasticity—the variance appears fairly constant across fitted values. \n\nAnd, finally, there are no very large values of Cook’s distance or leverage.\n\nThere are many other diagnostic tools and graphs available, many in the `car` library, which we do not have time to go into here. If you’re interested, this website is a good place to start: <http://www.statmethods.net/stats/rdiagnostics.html>.\n\n\n## 3D plots\n\nSince there are three variables involved in this model, it might be useful to examine their relationship using 3D plots. We can include the 2D plane that represents our regression model on the plot, using the following code.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(scatterplot3d)\n\nhh3d <- scatterplot3d(\n  hh$INNERDIA, \n  hh$OUTERSYS, \n  hh$WEIGHT,\n  type=\"h\", \n  highlight.3d=T,\n  pch=16\n  )\n\nhh3d$plane3d(mstep3)\n```\n\n::: {.cell-output-display}\n![](ws07_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\nFinally, use `plotly` to create a dynamic 3D plot which you can rotate using your mouse. Don’t say I never treat you!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(plotly)\n\nplot_ly(\n  hh, \n  x = ~INNERDIA, \n  y = ~OUTERDIA, \n  z = ~WEIGHT\n  ) |> \n  add_markers()\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"plotly html-widget html-fill-item\" id=\"htmlwidget-4d2cfd792df4e0788d82\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-4d2cfd792df4e0788d82\">{\"x\":{\"visdat\":{\"410c6622149e\":[\"function () \",\"plotlyVisDat\"]},\"cur_data\":\"410c6622149e\",\"attrs\":{\"410c6622149e\":{\"x\":{},\"y\":{},\"z\":{},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter3d\",\"mode\":\"markers\",\"inherit\":true}},\"layout\":{\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"scene\":{\"xaxis\":{\"title\":\"INNERDIA\"},\"yaxis\":{\"title\":\"OUTERDIA\"},\"zaxis\":{\"title\":\"WEIGHT\"}},\"hovermode\":\"closest\",\"showlegend\":false},\"source\":\"A\",\"config\":{\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false},\"data\":[{\"x\":[1.8999999999999999,1.7,1.8999999999999999,2,2.7999999999999998,2.2999999999999998,2.5,2.7000000000000002,2.2000000000000002,2.6000000000000001,2.2999999999999998,2.8999999999999999,2.2999999999999998,2.5,2.6000000000000001,1.3999999999999999,2,3.7999999999999998,2.2999999999999998,2.3999999999999999,2.1000000000000001,1.8999999999999999,2.2999999999999998,1.8,1.7,2.3999999999999999,1.3,1.8999999999999999,2,1.3999999999999999,2.2000000000000002,2.2000000000000002,2.2999999999999998,1.3,3.7000000000000002,2.2000000000000002,3.7999999999999998,3.2000000000000002,3.2000000000000002,3.1000000000000001,4,3.2999999999999998,2.5,2.2000000000000002,2.1000000000000001,3.2999999999999998],\"y\":[1.5,1.7,1.7,1.7,2,1.7,2,2.5,1.8,2,2.2000000000000002,2.6000000000000001,2.1000000000000001,1.5,2.6000000000000001,1.3,1.8,2.2000000000000002,2,1.6000000000000001,1.7,1.7,2.2000000000000002,1.3,1.2,1.6000000000000001,1.2,1.5,1.6000000000000001,1.3999999999999999,1.3999999999999999,1.3999999999999999,2.1000000000000001,1,2.3999999999999999,1.5,3,2.2999999999999998,2.1000000000000001,2.6000000000000001,2.1000000000000001,2.2000000000000002,2.2000000000000002,2.2999999999999998,3,3.2999999999999998],\"z\":[1.4319999999999999,1.226,1.46,1.3540000000000001,2.2109999999999999,1.212,1.8,1.758,1.7010000000000001,1.51,1.9139999999999999,2.9980000000000002,2.2610000000000001,2.2400000000000002,1.8,1.276,1.5169999999999999,3.2959999999999998,1.8779999999999999,1.7509999999999999,1.3959999999999999,1.772,2.9980000000000002,1.2050000000000001,1.637,1.3109999999999999,1.091,1.155,1.0349999999999999,0.999,1.5589999999999999,1.4810000000000001,1.6579999999999999,1.5,4.6829999999999998,1.6619999999999999,4.2409999999999997,4.5720000000000001,4.0999999999999996,3.7200000000000002,4.3150000000000004,4.3200000000000003,3.3900000000000001,4.0099999999999998,2.9700000000000002,3.431],\"type\":\"scatter3d\",\"mode\":\"markers\",\"marker\":{\"color\":\"rgba(31,119,180,1)\",\"line\":{\"color\":\"rgba(31,119,180,1)\"}},\"error_y\":{\"color\":\"rgba(31,119,180,1)\"},\"error_x\":{\"color\":\"rgba(31,119,180,1)\"},\"line\":{\"color\":\"rgba(31,119,180,1)\"},\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.20000000000000001,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\nI do not recommend 3-D plots for print reports/publications. They are often best viewed interactively. Instead try using colors or bubbles for continuous third variables and shapes or facets for discrete third variables.\n\nFor example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhh |> ggplot(aes(y=OUTERDIA, x=INNERDIA, color=WEIGHT))+\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](ws07_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n# Dataset **`Prestige`**\n\nWe will continue to use dataset `Prestige` from the `car`\tR package. \n\n\n## Exercise 7.1 {-}\n\nObtain the matrix plot of the numerical variables `education`, `income`, `women`, and `prestige`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\nlibrary(GGally)\nlibrary(tidyverse)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nPrestige |> \n  select(prestige, education, income, women) |> \n  ggpairs(aes(colour=Prestige$type))\n```\n:::\n\n\n\nObtain their correlation matrix.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Old style pairs plot\nPrestige |> \n  select(prestige, education, income, women) |>\n  pairs()\n```\n\n```{.r .cell-code}\nPrestige |> \n  select(prestige, education, income, women) |>\n  cor()\n```\n:::\n\n\nFit a (full) multiple regression of  `prestige` on `education`, `income`, & `women`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull.reg <- lm(prestige ~ education + income + women,\n               data = Prestige)\n```\n:::\n\n\nObtain the plots for residual diagnostics.\nResidual plots\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggfortify)\n\nautoplot(full.reg, 1:6)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Old style plots\nplot(full.reg, 1) # the argument 1 can be changed up to 6\n```\n\n```{.r .cell-code}\n# or just use\npar(mfrow=c(2,2))\nplot(full.reg)\n```\n:::\n\n\nRegression outputs\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(full.reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = prestige ~ education + income + women, data = Prestige)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.8246  -5.3332  -0.1364   5.1587  17.5045 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -6.7943342  3.2390886  -2.098   0.0385 *  \neducation    4.1866373  0.3887013  10.771  < 2e-16 ***\nincome       0.0013136  0.0002778   4.729 7.58e-06 ***\nwomen       -0.0089052  0.0304071  -0.293   0.7702    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.846 on 98 degrees of freedom\nMultiple R-squared:  0.7982,\tAdjusted R-squared:  0.792 \nF-statistic: 129.2 on 3 and 98 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nanova(full.reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: prestige\n          Df  Sum Sq Mean Sq  F value    Pr(>F)    \neducation  1 21608.4 21608.4 350.9741 < 2.2e-16 ***\nincome     1  2248.1  2248.1  36.5153 2.739e-08 ***\nwomen      1     5.3     5.3   0.0858    0.7702    \nResiduals 98  6033.6    61.6                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nextractAIC(full.reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]   4.0000 424.1724\n```\n:::\n:::\n\n\n## Exercise 7.2 {-}\n\nPerform stepwise regression analysis of `prestige` on `education`, `income`, & `women`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull.reg = lm(prestige ~ education + income + women,\n              data = Prestige)\n\nstep(full.reg)\n\nstep(full.reg, direction=\"backward\")\n\nstep(full.reg, direction=\"both\")\n```\n:::\n\n\nThe function `update()` is handy for making adjustments to a model. For example, see try the following codes:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 = update(full.reg,  . ~ . - women)\n\nsummary(m1)\n```\n:::\n\n\nNote that ` . ~ . - women` means that the model is fitted without the `women` variable.\n\nFurther options are available in `leaps` and `HH` packages \n(installation commands are given below).\n\n`install.packages(\"leaps\", repos = \"https://cran.r-project.org\")`\n`install.packages(\"HH\", repos = \"https://cran.r-project.org\")`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(leaps)\n\nmodel = regsubsets(prestige ~ education + income + women, \n                   data = Prestige)\n\nlibrary(HH)\n\nsummaryHH(model)\n\nplot(summaryHH(model))\n```\n:::\n\n\n\n## Exercise 7.3 {-}\n\nPerform a polynomial regression of `prestige` on `income`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cubic fit\np.model <- lm(prestige ~ poly(income,3),\n              data = Prestige)\n\nsummary(p.model)\n\nextractAIC(p.model)\n\nplot(p.model)\n```\n\n```{.r .cell-code}\nautoplot(p.model)\n```\n:::\n\n\n## Try it yourself\nUse the river data from Assignment 1: \n\n::: {.cell}\n\n```{.r .cell-code}\nriv <- read_csv(\"riverdat.csv\")\n```\n:::\n\n\n## Exercise 7.4 {-}\nMake a scatterplot of all the raw values of `Temperature` (x-axis) and `CHLA Mean` (y-axis) for the Canterbury region only, with the points coloured by `Catchment name`. Fit a linear regression to the plot using `geom_smooth`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# your code goes here\n```\n:::\n\n\n## Exercise 7.5 {-}\nFit a multiple linear regression for the Canterbury region only with the raw values of `CHLA Mean` as the response variable, `Temperature` and `Dissolved oxygen` as predictor variables. Produce a summary table and ANOVA table of your results. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# your code goes here\n```\n:::\n\n\n## Exercise 7.6 {-}\nMake an indicator variable for the `Waimakariri River` catchment in Canterbury (0 = not in that catchment, 1 = in that catchment). Add this to your regression from exercise 7.5. Produce new tables and discuss your results. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# your code goes here\n```\n:::\n\n\n+ More R code examples are [here](../exercises/Chap7more.R)\n\n",
    "supporting": [
      "ws07_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\r\n<script src=\"../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\r\n<script src=\"../site_libs/plotly-binding-4.10.4/plotly.js\"></script>\r\n<script src=\"../site_libs/typedarray-0.1/typedarray.min.js\"></script>\r\n<script src=\"../site_libs/jquery-3.5.1/jquery.min.js\"></script>\r\n<link href=\"../site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\r\n<script src=\"../site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\r\n<link href=\"../site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css\" rel=\"stylesheet\" />\r\n<script src=\"../site_libs/plotly-main-2.11.1/plotly-latest.min.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}