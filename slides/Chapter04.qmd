---
title: "Chapter 4:<br>Introduction to Statistical Inference"
image: img/inference.png
format: 
  revealjs:
    width: 1050
    height:	700
    scrollable: true
    transition: fade
    theme: [default, myquarto.scss]
    slide-number: c/t  
    logo: img/L_Color.png
    footer: "[161250 Data Analysis](../slides.qmd)"
    styles:
      - revealjs.dark:
        background-color: #222
        color: #fff
    
execute:
  echo: true
editor: 
  markdown: 
    wrap: 72
---

```{r setup, echo=FALSE, message=FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      echo = FALSE, 
                      include=TRUE, 
                      message=FALSE, 
                      comment = NA, 
                      warn=-1, 
                      warn.conflicts = FALSE, 
                      quietly=TRUE, 
                      fig.align="center")
library(tidyverse)
library(patchwork)
theme_set(theme_minimal())
```

# Statistical Inference {.background-black}

> “A statistical analysis, properly conducted, is a delicate dissection of uncertainties, a surgery of suppositions.”
>
> — M.J. Moroney


## Statistical Inference

::::{.columns}

:::{.column width="65%"}

The term *statistical inference* means that we are using properties of a sample to make statements about the population from which the sample was drawn. 

For example, say you wanted to know the mean length of the leaves on a tree ($\mu$). You wouldn't want to (nor need to) measure every single leaf! You would take a random sample of leaves and measure their lengths ($x_i$), calculate the sample mean ($\bar x$), and use $\bar x$ as an estimate of $\mu$.

:::

:::{.column width="35%"}

![](img/sampling_variation2.gif)

:::

::::


## Statistical Inference

::::{.columns}

:::{.column width="60%"}

Whenever we use sample data to make statements about a population (i.e., do inference): 

- The sample mean $\bar x$ is a single draw from a random variable $\bar X$. It will never be exactly equal to $\mu$ unless you measure every single leaf. 
- Each sample yields a different $\bar x$. This is called ***sampling error***. 
- Therefore, there is ***uncertainty*** in our estimate of $\mu$.



:::

:::{.column width="40%"}

![](img/inference.png)

:::

::::

The variability of the sample means from sample to sample, $\text{Var}(\bar X)$, depends on two things: the variability of the population values, $\text{Var}(x)$, and the size of the sample, $n$.

The variability of the sample estimate of a parameter is usually expressed as a ***standard error***, which is simply the theoretical standard deviation of $\bar X$ from sample to sample.


## Sampling Variation

![](img/samp_dist.gif)

## Quetelet's dataset

::::{.columns}

:::{.column width="70%"}

In 1846, a Belgian scholar Adolphe Quetelet published an analysis of the chest sizes of a full population of 5,738 Scottish soldiers.

The distribution of the measurements (in inches) in his database has a mean of $\mu$ = 39.83 inches, a standard deviation of $\sigma$ = 2.05 inches, and is well approximated by a normal distribution.

:::

:::{.column width="30%"}

![Adolphe Quetelet<br>1796-1874](img/quetelet_face.jpg)
:::

::::

```{r}
#| echo: true
#| fig-width: 5
#| fig-height: 3
#| output-location: column

qd <- tibble(
  Chest = 33:48, 
  Count = c(3, 18, 81, 185, 420, 749, 1073, 1079, 
            934, 658, 370, 92, 50, 21, 4, 1),
  Prob = Count / sum(Count)
  )

qd |> 
  ggplot() +
  aes(x = Chest, y = Count) +
  geom_col() +
  xlab("") + ylab("") +
  ggtitle("Chest circumferences of Scottish soldiers")

```



## Quetelet's dataset

Every soldier was measured so we can treat this as the population, and $\mu$ = 39.83 and $\sigma$ = 2.05 as population parameters. Let's take some samples of size $n$ = 6 from this population.

```{r}
#| echo: true
# Convert to a long vector of values
qd_long <- rep(qd$Chest, qd$Count)
```

::: {.fragment}

```{r}
#| echo: true
# A single sample
sample(qd_long, size = 6)
```

:::

::: {.fragment}

```{r}
#| echo: true
# Ten samples
map(1:7, ~ sample(qd_long, size = 6))
```

:::

## Quetelet's dataset

Every soldier was measured so we can treat this as the population, and $\mu$ = 39.83 and $\sigma$ = 2.05 as population parameters. Let's take some samples of size $n$ = 6 from this population.

```{r}
#| echo: true
# Convert to a long vector of values
qd_long <- rep(qd$Chest, qd$Count)
```

::: {.fragment}

```{r}
#| echo: true
# Put ten samples in a tibble
q_samples <- tibble( sample = as_factor(1:10) ) |> 
  mutate( 
    values = map(sample, ~ sample(qd_long, size = 6)) 
    ) |> 
  unnest()

head(q_samples, 15)
```

:::


## Quetelet's dataset

Every soldier was measured so we can treat this as the population, and $\mu$ = 39.83 and $\sigma$ = 2.05 as population parameters. Let's take some samples of size $n$ = 6 from this population.

```{r}
#| echo: true
# Convert to a long vector of values
qd_long <- rep(qd$Chest, qd$Count)
```

```{r}
#| echo: true
# Put ten samples in a tibble
q_samples <- tibble( sample = as_factor(1:10) ) |> 
  mutate( 
    values = map(sample, ~ sample(qd_long, size = 6)) 
    ) |> 
  unnest()

```


::: {.fragment}

```{r}
#| echo: true
# Calculate means of each sample
sample_means <- q_samples |> group_by(sample) |> 
  summarise(mean = mean(values))

sample_means
```

:::

## Quetelet's dataset


::::{.columns}

:::{.column width="55%"}

```{r}
#| echo: true
# Make a function to do it all and plot
plot_samples <- function(dat = qd_long,
                         no_samples = 12,
                         sample_size = 6) {

  # Put samples in a tibble
  q_samples <- tibble( 
    sample = as_factor(1:no_samples),
    values = map(sample, ~ sample(dat, size = sample_size))
    ) |> unnest()
  
  # Calculate means of each sample
  sample_means <- q_samples |> group_by(sample) |> 
    summarise(mean = mean(values))
  
  ggplot() + 
    xlim(min(dat), max(dat)) +
    geom_vline(xintercept = mean(dat), alpha = .4) +
    geom_jitter(
      data = q_samples,
      mapping = aes(y = sample, x = values),
      width = 0, height = 0.1, alpha = .8
      ) + 
    geom_point(
      data = sample_means,
      mapping = aes(y = sample, x = mean),
      shape = 15, size = 3, 
      colour = "dark orange"
      ) +
    ggtitle(paste("Sample size =", sample_size))
}
```

:::

:::{.column width="45%"}

```{r}
#| echo: true
#| eval: true
#| fig-width: 5
#| fig-height: 4.5
plot_samples(sample_size = 6)
```

:::
::::

## Sample means and sample sizes

::::{.columns}

:::{.column width="40%"}

Let's compare the distribution of means for different sample sizes.

```{r}
#| echo: true
#| eval: false

plot_samples(sample_size = 3)
plot_samples(sample_size = 5)
plot_samples(sample_size = 10)
plot_samples(sample_size = 20)
plot_samples(sample_size = 50)
plot_samples(sample_size = 100)
plot_samples(sample_size = 200)

```

:::
:::{.column width="60%"}

```{r}
#| fig-width: 5
#| fig-height: 4.5
#| fig-show: animate

plot_samples(sample_size = 3)
plot_samples(sample_size = 5)
plot_samples(sample_size = 10)
plot_samples(sample_size = 20)
plot_samples(sample_size = 50)
plot_samples(sample_size = 100)
plot_samples(sample_size = 200)

```
:::
::::

The larger the $n$, the less the sample means vary.



## Standard error

If is distributed as a normal random variable with mean $\mu$ and variance $\sigma^2$,

$$X \sim \text{Normal}(\mu, \sigma)$$

then sample means of size $n$ are distributed as

$$\bar X \sim \text{Normal}(\mu_\bar{X} = \mu, \sigma_\bar{X} = \sigma/\sqrt{n})$$
$\text{SE}(\bar{X}) = \sigma_\bar{X}= \sigma/\sqrt{n})$ is known as the ***standard error of the sample mean***. 

More generally, a standard error is the standard deviation of an estimated parameter over $\infty$ theoretical samples. 

According to the Central Limit Theorem (CLT), raw $X$ values don't have to be normally distributed for the sample means to be normally distributed (for any decent sample size)!

## Quetelet's chests: Standard error of means of samples

If Quetelet's chest circumferences are distributed as $X \sim \text{N}(\mu=39.83, \sigma=2.05)$, then how variable are the means of samples of size $n$ = 6?

$$
\begin{aligned}
SE(\bar{X}_{n=6})&=\sigma/\sqrt{n} \\
&=2.05/\sqrt{6} \\
&=0.8369 
\end{aligned}
$$
Sample means of size $n$ = 6 would be distributed as 

$\bar{X}_{n=6} \sim \text{N}(\mu=39.83, \sigma=0.8369)$


## Quetelet's chests: Distribution of means of samples

```{r}
#| fig-width: 5
#| fig-height: 4.5
#| fig-show: animate


plot_samples_dist <- function(n) {
  
  require(patchwork)
  
  se = sd(qd_long) / sqrt(n)
  
  plot_samples(sample_size = n) / 
    ggplot(
      tibble(
        x = seq( mean(qd_long) - 3.5*se, 
                 mean(qd_long) + 3.5*se, 
                 length = 10 )
        )
      ) + 
    xlim(min(qd_long), max(qd_long)) + 
    aes(x) +
    stat_function(
      xlim = c(mean(qd_long) - 3.5*se, 
               mean(qd_long) + 3.5*se),
      geom = "area",
      fun = dnorm, 
      args = list(mean = mean(qd_long), sd = se),
      colour = "dark orange",
      fill = "dark orange",
      alpha = .4) + 
    theme_void() + 
    annotate("text", label = "Theoretical distribution\nof sample means", 
             x=36, 
             y=0.5 * dnorm(mean(qd_long), mean(qd_long), sd = se)
             ) +
    plot_layout(heights = c(5, 2))
  }
  
plot_samples_dist(5)
plot_samples_dist(10)
plot_samples_dist(20)
plot_samples_dist(50)
plot_samples_dist(100)
plot_samples_dist(200)

```
## Confidence intervals

:::{.incremental}

- Another common way of expressing uncertainty when making statistical inferences is to present:
  + a point estimate (e.g., the sample mean) and 
  + a confidence interval around that estimate.
      
- A confidence interval gives an indication of the sampling error. 

- A 95% confidence interval is constructed so that ***intervals from 95% of samples will contain the true population parameter***. 

- In reality the interval either contains the true value or not, so you must **not** interpret a confidence interval as "there's a 95% probability that the interval contains the true parameter". 

- We can say:
  + “95% of so-constructed intervals will contain the true value of the parameter” or
  + “with 95% confidence, the interval contains the true value of the parameter”.

:::

## Confidence intervals

::::{.columns}

:::{.column width="50%"}

Because we know the population parameters for the Quetelet dataset, we can calculate were 95% of sample means will lie for any particular sample size.

Recall that, for a normal distribution, 95% of values lie between $\mu \pm 1.96\times\sigma$ \
(i.e., $\mu - 1.96\times\sigma$ and $\mu + 1.96\times\sigma$). 

It follows that 95% of means of samples of size $n$ will lie within $\mu \pm 1.96 \times \sigma/\sqrt{n}$.

For example, for samples of size 6 from the Quetelet dataset, 95% of means will lie within $39.83 \pm 1.96\times 2.05 / \sqrt 6$, \
so $\{ 37.02 , 42.64\}$.

:::
:::{.column width="50%"}

```{r}
# Make a function to do it all and plot
plot_samples_intervals <- function(dat = qd_long,
                         no_samples = 12,
                         sample_size = 6) {

  # Put samples in a tibble
  q_samples <- tibble( 
    sample = as_factor(1:no_samples),
    values = map(sample, ~ sample(dat, size = sample_size))
    ) |> unnest()
  
  # Calculate means of each sample
  sample_means <- q_samples |> group_by(sample) |> 
    summarise(mean = mean(values))
  
  ggplot() + 
    xlim(min(dat), max(dat)) +
    annotate(
      "rect", 
      xmin = mean(dat) - 1.96 * sd(dat) / sqrt(sample_size),
      xmax = mean(dat) + 1.96 * sd(dat) / sqrt(sample_size),
      ymin = -Inf, ymax = Inf,
      fill = "dark orange", 
      alpha = .4) +
    geom_vline(xintercept = mean(dat)) +
    geom_jitter(
      data = q_samples,
      mapping = aes(y = sample, x = values),
      width = 0, height = 0.1, alpha = .8
      ) + 
    geom_point(
      data = sample_means,
      mapping = aes(y = sample, x = mean),
      shape = 15, size = 3, 
      colour = "dark orange"
      ) +
    ggtitle(
      "95% of sample means will be within the orange band",
      subtitle = paste("Sample size =", sample_size))
}
```

```{r}
#| fig-width: 5
#| fig-height: 6
set.seed(1232)
plot_samples_intervals(no_samples=20)
```
:::
::::

## Estimating the distribution of sample means from data

:::{.incremental}

- It's all very well deriving the distribution of sample means when we *know the population parameters* ($\mu$ and $\sigma$) but *in most cases we only have our one sample*.

- We don't know any of the population parameters. We have to *estimate* the population mean (usually denoted $\hat\mu$ or $\bar x$) and *estimate* of the population standard deviation (usually denoted $\hat\sigma$ or $s$) from the sample data.

- This additional uncertainty complicates things a bit. In fact, we can't even use the normal distribution any more!

:::

## The *t* distribution


::::{.columns}

:::{.column width="70%"}

- Introducing William Sealy Gosset, who described the *t* distribution after working with random numbers.

- Gosset was a chemist and mathematician who worked for the Guinness brewery in Dublin. 

- Guinness forbade anyone from publishing under their own names so that competing breweries wouldn’t know what they were up to, so he published his discovery in 1908 under the penname “Student”. Student’s identity was only revealed when he died. It is therefore often called “Student’s *t* distribution”. 

:::
:::{.column width="30%"}

![Willam Sealy Gosset<br>1876-1937](img/gosset_1876-1937.jpg)

:::
::::


## The *t* distribution


- The *t* distribution is like the standard normal. It is bell-shaped and symmetric with mean = 0, but it has fatter tails (greater uncertainty) due to the fact that we do not *know* $\sigma$; we have to *estimate* it.

- The *t* distribution is not just a single distribution. It is really an entire series of distributions which is indexed by something called the “degrees of freedom” (or $df$).

::::{.columns}

:::{.column width="40%"}

- As $df \rightarrow \infty$, $t \rightarrow Z$.

```{r}
#| echo: true

p <- expand_grid(
  df = c(2, 5, Inf),
  x = seq(-4, 4, by = .01)
  ) |> 
  mutate(
    Density = dt(x = x, df = df),
    `degrees of freedom` = as_factor(df)
  ) |> 
  ggplot() +
  aes(x = x, y = Density, 
      group = `degrees of freedom`, 
      colour = `degrees of freedom`) +
  geom_line()
```


:::
:::{.column width="60%"}

```{r}
#| fig-height: 3
#| fig-width: 6

p
```

:::
::::

## The *t* distribution

For a sample of size $n$, if

- $X$ is a normal random variable with mean $\mu$,
- $\bar X$ is the sample mean, and 
- $s$ is the sample standard deviation, 

then the variable:

$$
T = \frac{\bar X - \mu} {s/\sqrt{n}}
$$

is distributed as a $t$ distribution with $(n – 1)$ degrees of freedom.

## Confidence intervals and the *t* distribution

The process of using sample data to try and make useful statements about an unknown parameter, $\theta$, is called statistical inference.

A confidence interval for the true value of a parameter is often obtained by:

$$
\hat \theta \pm t \times \text{SE}(\hat \theta)
$$
where $\hat \theta$ is the sample estimate of $\theta$. 

The piece that is being added and subtracted, $t \times \text{SE}(\hat \theta)$, is often called the *margin of error*.


## Confidence intervals for a sample mean

We can calculate a 95% confidence interval for a sample mean with the following information:

::: {style="font-size: 75%;"}
- sample mean $\bar x$,
- sample standard deviation $s$, 
- the sample size $n$, and 
- the 0.025th quantile of the $t$ distribution with degrees of freedom $df=n-1$.
:::


::::{.fragment}
:::{.absolute top="45%" left=0}

A sample of size $n$ = 6 from Quetelet data

```{r}
#| echo: true
n1 <- 6; df1 <- n1-1
( dq1 <- sample(qd_long, size = n1) )
( mean1 <- mean(dq1) )
( sd1 <- sd(dq1) )
( t1 <- qt(c(0.025, 0.975), df = df1) )
mean1 + t1 * sd1 / sqrt(n1)
```

:::
::::

::::{.fragment}
:::{.absolute top="45%" right=0}
Or, more simply...

```{r}
#| echo: true
t.test(dq1)
```

:::
::::

## Confidence intervals for sample means

```{r}
#| echo: false
# Make a function to do it all and plot
plot_samples_ci <- function(dat = qd_long,
                         no_samples = 12,
                         sample_size = 6) {

  # Put samples in a tibble
  q_samples <- tibble( 
    sample = as_factor(1:no_samples),
    values = map(sample, ~ sample(dat, size = sample_size))
    ) |> unnest()
  
  # Calculate means of each sample
  sample_means <- q_samples |> group_by(sample) |> 
    summarise(mean = mean(values),
              sd = sd(values)) |> 
    mutate(
      lower = mean + qt(0.025, df = sample_size-1) * sd / sqrt(sample_size),
      upper = mean + qt(0.975, df = sample_size-1) * sd / sqrt(sample_size)
      )
  
  ggplot() + 
    xlim(min(dat), max(dat)) +
    geom_vline(xintercept = mean(dat), alpha = .4) +
    geom_jitter(
      data = q_samples,
      mapping = aes(y = sample, x = values),
      width = 0, height = 0.1, alpha = .8
      ) + 
    geom_pointrange(
      data = sample_means,
      mapping = aes(
        y = sample, 
        x = mean,
        xmin = lower,
        xmax = upper
        ),
      shape = 15, size = 0.5, 
      colour = "dark orange"
      ) +
    ggtitle(paste("Sample size =", sample_size))
}
```

```{r}
#| fig-height: 5
#| fig-width: 10
#| output-location: fragment

set.seed(123)

plot_samples_ci(no_samples = 30, sample_size = 5) +
  plot_samples_ci(no_samples = 30, sample_size = 10) +
  plot_samples_ci(no_samples = 30, sample_size = 50)
```

## *t* as a test statistic

This method can be used when the estimator $\hat\theta$ is approximately normally distributed and

$$
 \frac{\hat\theta - \theta} {\text{SE}(\hat \theta)}
$$

has approximately a Student’s *t* distribution.

This paves the way for hypothesis testing for specific values of $\theta$. Many of the methods you will learn in this course are based on this general rule.


## Testing hypotheses

- Testing hypotheses underpins a lot of scientific work.
- A hypothesis is a proposition, a specific idea about the state of the world that can be tested with data.
- For logical reasons, instead of measuring evidence for a hypothesis of interest, scientists will often:
   + specify a ***null hypotheses***, a hypothesis that is true if our hypothesis of interest is false, and 
   + measure the evidence *against* the null hypothesis, usually in the form of a *p*-value.

## Example: growth of alfalfa

Say a farmer has 9 paddocks of alfalfa. He's hired a new manager, and wants to know if, on average, this year's crop is different to last year's. He measures the yield for each paddock in year 1 and year 2, and calculates the difference.

```{r}
#| echo: true
year1 <- c(0.8, 1.3, 1.7, 1.7, 1.8, 2.0, 2.0, 2.0, 2.2)
year2 <- c(0.7, 1.4, 1.8, 1.8, 2.0, 2.0, 2.1, 2.1, 2.2)
diff <- year2 - year1
( xbar <- mean(diff) ) ; ( s <- sd(diff) )
```
The mean difference is `r xbar |> round(3)`. On average, yields were `r xbar |> round(3)` greater than last year. \
Is that convincing different from zero? 

How likely is such a difference to have arisen just by chance, and really, if we had a million paddocks, there would be no difference?

What is the probability of seeing a difference of `r xbar |> round(3)` or more in our dataset if the true mean were zero?

These questions can be addressed with a $p$-value from a hypothesis test.

## Example: growth of alfalfa

The hypothesis of interest (called the "alternative" hypothesis) is: 

$\ \ \ \ \ H_A: \mu \ne 0$, that is, the mean difference in yield $\mu$ between the two years is not zero. 

The **null** hypothesis (the case if the alternative hypothesis is wrong) is:

$\ \ \ \ \ H_0: \mu = 0$, that is, the mean difference is zero.

We can test the null hypothesis using a *t* statistic $t_0 = \frac{\bar x - \mu_0} {text{SE}(\bar x)}$, where \
$\ \ \ \ \ \mu_0 = 0$ is the hypothesised value of the mean and\
$\ \ \ \ \ \text{SE}(\bar x) = s/\sqrt{n}$ is the standard error of the sample mean. 

```{r}
#| echo: true
( t0 <- (xbar - 0) / ( s / sqrt(9) ) )
```
The *p*-value is $\text{Pr}(|t_{df=8}| > t_0)$

```{r}
#| echo: true
2 * pt(t0, df = 8, lower = F)
```

:::{.absolute bottom=0 right=0}

```{r}
#| echo: false
#| fig-width: 4
#| fig-height: 2.5
dfa=8

p <- ggplot() + 
  stat_function(
      xlim = c( -4, 4),
      geom = "area",
      fun = dt, 
      args = list(df = dfa),
      alpha = .4) +
  geom_area(
    data = tibble(
      t = seq(-4, -t0, by=.01),
      y = dt(t, df=dfa)
    ), 
    mapping = aes(t,y),
    fill = "dark orange"
    ) +
  geom_area(
    data = tibble(
      t = seq(t0, 4, by=.01),
      y = dt(t, df=dfa)
    ), 
    mapping = aes(t,y),
    fill = "dark orange"
    ) +
  geom_segment(
    aes(x = c(-t0,t0), 
        xend = c(-t0,t0),
        y = c(0,0),
        yend = c(0.1,0.1)
        )
    ) + 
  annotate(
    "text",
    x = c(-t0, t0),
    y = c(0.12,0.12),
    label = c(-t0 |> round(3), t0 |> round(3))
    ) +
  ggtitle("t distribution for df = 8") +
  ylab("")

p
```
:::

## Example: growth of alfalfa

The hypothesis of interest (called the "alternative" hypothesis) is: 

$\ \ \ \ \ H_A: \mu \ne 0$, that is, the mean difference in yield $\mu$ between the two years is not zero. 

The **null** hypothesis (the case if the alternative hypothesis is wrong) is:

$\ \ \ \ \ H_0: \mu = 0$, that is, the mean difference is zero.

This can be done more easily:

```{r}
#| echo: true
t.test(diff)
```

:::{.absolute bottom=0 right=0}

```{r}
#| echo: false
#| fig-width: 4
#| fig-height: 2.5
p
```
:::


## Example: growth of alfalfa

The $p$-value of 0.05 means that, if the null hypothesis were true, only 5% of sample means would be as or more extreme than the observed value of `r xbar |> round(3)`. It is the area in orange in the graph below.

We can therefore reject the null hypothesis at the conventional 5% level, and conclude that, on average, yields were indeed higher this year.

This is an example of a paired *t* test. They two samples (year 1 and year 2) are not independent of one another because we have the same paddocks in both years. So, we take the differences, treat them like a single sample, and do a one-sample *t* test for the mean difference being zero.

$p$-values are random variables too.\
<https://shiny.massey.ac.nz/anhsmith/demos/demo.p.is.rv/>

:::{.absolute bottom=0 right=0}

```{r}
#| echo: false
#| fig-width: 4
#| fig-height: 2.5
p
```
:::


## Concept of power

A hypothesis test has a certain **power** (probability) to reject the
null hypothesis when it is false.

The power of the t test can be evaluated using R for given effect size
$\delta$

```{r, echo=TRUE}
power.t.test(n = 30, delta = 1, sd = 1, sig.level = 0.05)
power.t.test(n = 50, delta = 1, sd = 1, sig.level = 0.05)
```

## Sampling distributions

The term *sampling distribution* means the distribution of the computed
statistic such as the sample mean when sampling is repeated many times.

For a normal population,

-   Student's $t$ distribution is the sampling distribution of the mean
    (after rescaling).

-   $\chi^2$ distribution is the sampling distribution of the sample
    variance $S^2$.

-   $(n-1)S^2/\sigma^2$ follows $\chi^2$ distribution.

$F$ distribution is ratio of two $\chi^2$ distributions.

-   It becomes the sampling distribution of the ratio of two sample
    variances $S_1^2/S_2^2$ from two normal populations (after scaling).

$t$ distribution is symmetric but $\chi^2$ and $F$ distributions are
right skewed. - For large samples, they become normal - For $n>30$, the
skew will diminish

For the three sampling distributions, the sample size $n$ becomes the
proxy parameter, called the degrees of freedom (df).

-   $t_{n-1}$, $\chi_{n-1}^2$ & $F_{(n_1-1),(n_2-1) }$

## Two sample t-test

-   In a two-sample t-test, the equality of two population means is
    tested. Null hypothesis $H_0:\mu=\mu_1=\mu_2$. Two-sided Alternative
    hypothesis $H_1:\mu_1 \neq \mu_2$

-   If EDA suggests that the two populations have the same spread, we
    perform a **pooled-sample t-test** in which the variance common to the two
    population is estimated as
    $S_{p}^{2} = w_{1} S_{1}^{2} +w_{2} S_{2}^{2}$ where the *weights*
    are $w_{1} =\frac{n_{1}-1}{n_{1} +n_{2}-2}$ and
    $w_{2} =\frac{n_{2}-1}{n_{1} +n_{2}-2}$

-   For the pooled case, the $df$ for the $t$-test is $n_{1}+n_{2}-2$
    but becomes smaller for the unpooled case to
    $$df=\frac{\left(\frac{S_{1}^{2}}{n_{1}} +\frac{S_{2}^{2} }{n_{2}} \right)^{2} }{\frac{1}{n_{1} -1} \left(\frac{S_{1}^{2}}{n_{1}}\right)^{2} +\frac{1}{n_{2} -1} \left(\frac{S_{2}^{2}}{n_{2} } \right)^{2}} $$

## Validity of equal variance assumption 

Equal variance assumption is found plausible in the following output:

```{r}
#| echo: true
tv = read_csv("https://www.massey.ac.nz/~anhsmith/data/tv.csv")
bartlett.test(TELETIME~SEX, data=tv)
car::leveneTest(TELETIME~factor(SEX), data=tv)
```
Highish *p-values* means there's no strong evidence against the null hypothesis that the variances are equal.

## Shiny apps (some not currently working)

<https://shiny.massey.ac.nz/anhsmith/demos/demo.2sample.t.test/>

<https://shiny.massey.ac.nz/anhsmith/demos/explore.2sample.t-test/>

<https://shiny.massey.ac.nz/anhsmith/demos/explore.paired.t-test/>

For more on non-parametric tests, see Study Guide.

## Test of proportions

Testing for a single proportion being different to 0.5, or some other value. 

A sample survey of size 1000 has had 450 females.

Can we treat the survey as unbiased?

```{r, echo=TRUE}
prop.test(450, 1000)
```

An exact version of the test

```{r}
binom.test(c(450, 550))
```

Or, for a test for a proportion other than 0.5

```{r}
binom.test(c(450, 550), p = 3/4)
```


## Comparing several proportions

Fleiss (1981) *Statistical methods for rates and proportions* data on
smokers in four group of patients

```{r, echo=TRUE}
smokers  <- c( 83, 90, 129, 70 )
patients <- c( 86, 93, 136, 82 )
prop.test(smokers, patients)
```


## Tests for normality

-   EDA approaches

    -   normal quantile plot, Boxplots,mids vs. spreads plot etc.

-   Hypothesis tests

    -   Kolmogorov-Smirnov test (based on the biggest difference between
        the empirical and theoretical cumulative distributions)
    -   Shapiro-Wilk test (based on variance of the difference)

-   Example: N(100,1) random data of size $n=50$

    -   **The null hypothesis of normality must be justified on
        empirical grounds**

\small

```{r, warning=FALSE, message=FALSE}
set.seed(1234)
shapiro.test(rnorm(50, mean=100))
ks.test(rnorm(50), "pnorm")
```



## Example

```{r, warning=FALSE, fig.height=3, fig.width=4}
tv = read_csv("https://www.massey.ac.nz/~anhsmith/data/tv.csv")

p1 <- ggplot(tv, aes(sample = TELETIME)) + 
  stat_qq() + stat_qq_line()
p1 + 
  labs(title = "Normal quantile plot for TV viewing times") 
```


## Transformations

-   I can be useful to transform data to make the distribution more 'normal'

-   The linear transformation $Y^*= a+bY$ result only in a change of
    scale or of origin

-   A linear transformation does not change the shape of the
    distribution i.e. histogram, boxplot etc. remain the same shape

-   We prefer non-linear transformations which alter the shape of the
    distribution

-   Transformations are needed to-

    -   to bring symmetry
    -   normality
    -   stabilise the variance etc

## Example

-   Right skewed distribution is made roughly symmetric using a log
    transformation for no. of vehicles variable (rangitikei.\* dataset)

```{r}
load("../data/rangitikei.Rdata")
p1 <- ggplot(rangitikei, aes(vehicle))+geom_boxplot()
p1 <- p1+labs(title = "Boxplot of Vehicle (Raw data)")
p2 <- ggplot(rangitikei, aes(vehicle^2))+geom_boxplot()
p2 <- p2+labs(title = "Boxplot of Vehicle (Squared data)")
p3 <- ggplot(rangitikei, aes(sqrt(vehicle)))+geom_boxplot()
p3 <- p3+labs(title = "Boxplot of Vehicle (Square Root data)")
p4 <- ggplot(rangitikei, aes(log(vehicle)))+geom_boxplot()
p4 <- p4+labs(title = "Boxplot of Vehicle (log data)")
library(patchwork)
p2+p1+p3+p4  
```

## A Ladder of Powers for Transforming Data

-   Right skewed data needs a shrinking transformation
-   Left skewed data needs a stretching transformation
-   The strength or power of the transformation depends on the degree of
    skew.\

| POWER | Formula               | Name            | Result                 |
|:------|:----------------------|:----------------|:-----------------------|
| 3     | $x^3$                 | cube            | stretches large values |
| 2     | $x^2$                 | square          | stretches large values |
| 1     | $x$                   | raw             | No change              |
| 1/2   | $\sqrt{x}$            | square root     | squashes large values  |
| 0     | $\log{x}$             | logarithm       | squashes large values  |
| -1/2  | $\frac{-1}{\sqrt{x}}$ | reciprocal root | squashes large values  |
| -1    | $\frac{-1}{x}$        | reciprocal      | squashes large values  |

## D-statistics

-   D-statistics are used for checking the adequacy of a transformation

-   Symmetry implies mean = median

-   A simple approach is to plot the distance from the median for points
    below and above the median.

```{r}
symmetryplot = function(x)
{
  m = length(x) %/% 2
  sx = sort(x)
  dat1=cbind.data.frame(x=median(x) - sx[1:m],y=rev(sx)[1:m] - median(x))
  p1=ggplot(dat1, aes(x=x,y=y))+geom_point()+xlab("Distance below median")+ylab("Distance above median")
  p1+ geom_abline(intercept=0, slope=1)
}

symmetryplot(rangitikei$vehicle)

```

-   (mean-median) measures skew but we can standardise it in 3 ways

    -   D1 = \|mean-median\| / std.dev.
    -   D2 = \|mean-median\| / F-spread
    -   D3 = \|mid_F-median\| / F-spread

-   D3 - sensitive to skewness in the middle 50% of data.\

-   D1 & D2 - sensitive to skewness in whole data

-   Smaller the D value, the better the transformation for symmetry

```{r}
D1 = function(x) {(mean(x) - median(x))/sd(x)}
D2 = function(x) {(mean(x) - median(x))/(fivenum(x)[4]-fivenum(x)[2])}
D3 = function(x) {((fivenum(x)[4]+fivenum(x)[2])/2 - median(x))/(fivenum(x)[4]-fivenum(x)[2])}
c(D1=D1(rnorm(30)),D2=D2(rnorm(30)),D3=D3(rnorm(30)))
```

## Box-Cox transformation

-   This is a normalising transformation (i.e more than just symmetry)
    but we may not always find a suitable Box-Cox power $\lambda$.
-   R gives a point estimate of power & the CI.

```{r}
# library(MASS)
# boxcox(rangitikei$vehicle ~ 1)
# title("Log-likelihood curve of boxcox parameter")
library(lindia)
gg_boxcox(lm(rangitikei$vehicle ~ 1))
```

-   Focus on the confidence interval for the estimated $\lambda$ and it
    may be wider

## Statistical Inference Based on Transformed data

-   Confidence intervals found as `estimate` $\pm$ `margin of error`
    require symmetry.

-   Obtain the confidence interval using transformed data and then back
    transform the limits (to keep the original scale)

    -   The confidence limits of log transformed data can be
        exponentiated back (ie. $e^{\text{confidence limit}}$)
    -   The confidence limits of square-root transformed data can be
        squared back (ie. ${\text{confidence limit}^2}$)

-   For hypothesis test, apply the same transformation on the value
    hypothesised under the null

-   Explore
    https://shiny.massey.ac.nz/anhsmith/demos/explore.transformations/
    app (not currently working)

-   Example: Brain weight data is extremely skewed to the right. So rely
    on the back-transformed CI.

```{r}
load("../data/brainweight.RData")
attach(brainweight)
t.test(BrainWt)$conf.int[1:2]
t.test(log(BrainWt))$conf.int[1:2]
exp(t.test(log(BrainWt))$conf.int)[1:2]
```

## A Caution on the transformation technique

-   Perform EDA in addition to computing coefficients of skewness or
    D-Statistics etc
-   Small datasets may reveal skewness (So ignore)
-   Avoid a transformation if marginal improvement happens.
-   Transformed data may be difficult to interpret
-   Try other options such as subgrouping etc.
-   Normalising transformations are different from transformations for
    symmetry
-   Read the section from your SG

## Variance stabilisation

-   Two or more batches of data may not have equal variance
-   If each batch is skewed in the same direction, then a common
    transformation can be used.
-   If batches are skewed in different directions, the transformation
    technique fails
-   Explore LOCATION vs SPREAD plot of batches.
-   If there exists a relationship between spreads and averages, a
    single transformation can be applied for all the batches.

## Example

-   Common shrinking transformation can be found in the following case

<!-- ```{r} -->

<!-- library(tidyverse) -->

<!-- hospital <- read.table("https://www.massey.ac.nz/~anhsmith/data/hospital.txt", header=TRUE, sep=",") -->

<!-- dat <- hospital %>% group_by(YEAR) %>%  -->

<!--   pivot_longer(cols =3:8, names_to = "Region", values_to = "Admissions") -->

<!-- dat %>% group_by(interaction(YEAR, Region)) %>%  -->

<!--   summarise(medians=median(Admissions), ranges=max(Admissions)-min(Admissions)) ->dat -->

<!-- p1 <- ggplot(dat, aes(x=medians, y=ranges))+geom_point() -->

<!-- p1 <- p1 +geom_smooth(method="lm", se=FALSE) -->

<!-- p1 <- p1 +labs(title = "Range vs Median Plot") -->

<!-- p1 -->

<!-- ``` -->

![](img/hospital_rangevmedian.png)

## Shiny apps

<https://shiny.massey.ac.nz/anhsmith/demos/explore.transformations/>

<https://shiny.massey.ac.nz/anhsmith/demos/perform.transformations/>

## Non-parametric tests

An alternative to using power transformations

Relies on replacing the actual observed data by their ranks

**Spearman's Rank Correlation**

-   Rank the $X$ and $Y$ variables, and then obtain usual Pearson
    correlation coefficient

-   The following plot shows both (Spearman correlation in the upper
    triangle)

```{r spear, echo=FALSE, fig.cap="Comparison of Pearsonian and Spearman's rank correlations"}
library(GGally)
ggpairs(trees, upper = list(continuous = wrap('cor', method = "spearman")), 
  lower = list(continuous = 'cor'))
```

## Wilcoxon signed rank test

A non-parametric alternative to the one-sample t-test

-   $H_0: \eta=\eta_0$ where $\eta$ (Greek letter 'eta') is the
    population median

-   Based on based on ranking $(|Y-\eta_0|)$, where the ranks for data
    with $Y<\eta_0$ are compared to the ranks for data with $Y>\eta_0$

```{r}
wilcox.test(tv$TELETIME, mu=1680, conf.int=T)
```

```{r}
t.test(tv$TELETIME, mu=1680)
```

## Mann-Whitney test

For two group comparison, pool the two group responses and then rank the
pooled data

Ranks for the first group are compared to the ranks for the second group

-   The null hypothesis is that the two group medians are the same:
    $H_0: \eta_1=\eta_2$.

```{r}
wilcox.test(rangitikei$people~rangitikei$time, conf.int=T)
```

```{r}
t.test(rangitikei$people~rangitikei$time)
```

## Another form of test

```{r, echo=TRUE}
kruskal.test(rangitikei$people~rangitikei$time)
```

```{r, echo=TRUE}
wilcox.test(rangitikei$people~rangitikei$time)
```

## Permutation tests

A permutation (or randomisation) test is based on the idea of randomly
permuting the observed data and then answering whether a hypothesis is
negated or not.

One sample hypothesis test example follows:

```{r, echo=TRUE}
library(exactRankTests)
perm.test(tv$TELETIME, null.value=1500)
```

For small samples, this test is not powerful.

## Two group comparison

```{r, echo=TRUE}
perm.test(TELETIME~SEX, distribution ='exact', data=tv)
```

Also using a linear model fit (cover later)

```{r, echo=TRUE}
library(lmPerm)
summary(lmp(TELETIME~SEX, data=tv))
```

Read the study guide example for bootstrap tests (not examined)

## Summary

Inference is less complicated for normal populations

-   Assessment of normality is particularly important for small sample
    sizes
-   Student t-tests are generally robust and can be used for non-normal
    populations (as long as there are no subgrouping or sample sizes are
    large)

Power transformations aim to achieve symmetry

-   Box-Cox transformations aim to normalise the data
-   Improved Inference can be made
-   Subgrouping effect can be dampened

Permutation tests can be done for a second opinion

<!-- ## Exercises -->

<!-- download.file("<https://www.massey.ac.nz/~kgovinda/220exer/Chap3moreexamples.R>", destfile="Chap3moreexamples.R") -->

<!-- download.file("<https://www.massey.ac.nz/~kgovinda/220exer/chapter-3-exercises.html>", destfile="chapter-3-exercises.html") -->

<!-- install.packages("remotes") -->

<!-- remotes::install_github("ricompute/ricomisc") -->

<!-- ricomisc::rstudio_viewer("chapter-3.html", file_path = NULL) -->
